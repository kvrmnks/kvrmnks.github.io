{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to kvrmnks's blog Just a notes set...","title":"Welcome to kvrmnks's blog"},{"location":"#welcome-to-kvrmnkss-blog","text":"Just a notes set...","title":"Welcome to kvrmnks's blog"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/","text":"23\u6811\u7684\u4e00\u79cd\u5220\u9664\u65b9\u6cd5 \u4f3c\u4e4e\u7f51\u4e0a\u6ca1\u6709\u4ec0\u4e48\u5bf9\u4e8e23\u6811\u5220\u9664\u65f6\u5019\u7684\u6559\u7a0b \u5373\u4f7f\u662f\u6709\u7684\u90a3\u4e9b\u4e5f\u662f\u8eb2\u8eb2\u95ea\u95ea\uff0c\u4e0d\u8bb2\u4e2a\u660e\u767d\uff0c\u672c\u6587\u5c3d\u6211\u6700\u5927\u7684\u53ef\u80fd\u5c06\u8fd9\u4e2a\u64cd\u4f5c\u8bb2\u660e\u767d\uff08\u6700\u540e\u8fd8\u662f\u9e3d\u4e86 \u4e0d\u540c\u4e8e\u672c\u4eba\u7684\u522b\u7684blog\uff0c\u8fd9\u6b21\u672c\u4eba\u82b1\u5de8\u8d44\u753b\u4e86\u793a\u610f\u56fe\uff08 \u4f46\u662f\u8fd9\u4e2ablog\u522b\u4eba\u4e5f\u770b\u4e0d\u5230\u5440\uff08\uff08 \u53c2\u8003\u8d44\u6599 \u7f51\u4e0a\u76842-3\u6811\u6559\u7a0b \u633a\u53ef\u60dc\u7684\u662f\u8fd9\u7bc72-3\u6811\u6709\u4e24\u79cd\u5220\u9664\u65f6\u5019\u7684\u60c5\u51b5\u6ca1\u6709\u8ba8\u8bba\uff0c\u53ef\u80fd\u662f\u592a\u7b80\u5355\u4e86\u5427\uff08 \u5220\u9664 \u5206\u6790\u5927\u7eb2 \u4e3a\u4e86\u4fdd\u8bc1\u6392\u7248\u6211\u7528\u7f29\u8fdb\u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u601d\u8def \u5220\u9664\u7684\u662f\u975e\u53f6\u5b50\u7ed3\u70b9 \u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9 \u5220\u9664\u7684\u662f3type\u7ed3\u70b9 \u5220\u9664\u7684\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u5144\u5f1f\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u5b58\u5728\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u5b58\u5728\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u9996\u5148\u6211\u4eec\u8981\u5220\u9664\u4e00\u4e2a\u7ed3\u70b9\u7684\u8bdd\u3002 \u6211\u4eec\u8981\u627e\u5230\u90a3\u4e2a\u7ed3\u70b9\u5728\u54ea\u91cc\u3002 \u6211\u4eec\u9996\u5148\u6839\u636e\u5220\u9664\u7ed3\u70b9\u7684\u60c5\u51b5\u8fdb\u884c\u5206\u7c7b\u3002 \u8981\u5220\u9664\u7684\u7ed3\u70b9\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9 \u8981\u5220\u9664\u7684\u7ed3\u70b9\u662f\u53f6\u5b50\u7ed3\u70b9 \u5220\u9664\u7684\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9 \u8fd9\u65f6\u5019\u6211\u4eec\u627e\u5230\u8fd9\u4e2a\u7ed3\u70b9\u7684\u540e\u7ee7\uff0c\u7136\u540e\u628a\u540e\u7ee7\u7684\u503c\u548c\u8981\u5220\u9664\u7ed3\u70b9\u7684\u503cswap\u4e00\u4e0b\u3002 \u7136\u540e\u53ea\u9700\u8981\u5220\u9664\u540e\u7ee7\u5c31\u597d\u4e86\u3002 \u90a3...\u4e3a\u4ec0\u4e48\u8981\u8fd9\u4e48\u505a\u5462\uff0c\u4e00\u6765\u8fd9\u6837\u4f9d\u65e7\u80fd\u591f\u4fdd\u8bc1\u6574\u68f5\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6b63\u786e\u6027\u3002 \u6b64\u5916\u8fd9\u4e2a\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u662f\u4e00\u4e2a\u53f6\u5b50\uff01\u6211\u4eec\u63a5\u4e0b\u6765\u5c31\u6765\u8bc1\u660e\u8fd9\u4e2a\u7ed3\u8bba\u3002 \u4e00\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u662f\u4e00\u4e2a\u53f6\u5b50 \u5982\u679c\u4f60\u5b66\u8fc7\u5176\u4ed6\u7684\u79cd\u7c7b\u7684\u5e73\u8861\u6811\u7684\u8bdd\uff0c\u4f60\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u6027\u8d28\u662f\u4e00\u822c\u5e73\u8861\u6811\u6240\u6ca1\u6709\u7684\u3002 \u4f8b\u5982 \u5176\u4e2d5\u7ed3\u70b9\u7684\u540e\u7ee76\u5c31\u4e0d\u662f\u4e00\u4e2a\u53f6\u5b50 \u539f\u56e0\u5728\u4e8e5\u7684\u540e\u7ee7\u53ef\u80fd\u6709\u53f3\u513f\u5b50\uff0c\u4f46\u662f\u57282-3\u6811\u4e2d\u4fdd\u8bc1\u4e86\u9664\u53f6\u5b50\u8282\u70b9\u5916\uff0c\u6bcf\u4e2a\u5206\u652f\u8282\u70b9\u7684\u513f\u5b50\u6570\u91cf\u662f\u6ee1\u7684\uff0c\u4e8e\u662f\u610f\u5473\u7740\u4e00\u4e2a\u7ed3\u70b9\u4e00\u65e6\u6709\u513f\u5b50\uff0c\u5219\u4e00\u5b9a\u6709\u5f88\u591a\u513f\u5b50\uff0c\u8fd9\u4e2a\u5b83\u662f\u4e00\u4e2a\u540e\u7ee7\u76f8\u77db\u76fe\uff0c\u53ef\u4ee5\u81ea\u5df1\u60f3\u60f3\u3002 \u4e00\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u5728\u53f3\u513f\u5b50\u4e2d \u8fd9\u4e2a\u4e5f\u662f\u666e\u901a\u5e73\u8861\u6811\u6240\u6ca1\u6709\u7684\u6027\u8d28\u3002 \u4e3e\u4e2a\u6817\u5b50\u3002 \u8003\u86515\u7684\u540e\u7ee7\uff0c\u663e\u7136\u5f97\u5230\u4e86\u540e\u7ee7\u4e0d\u4e00\u5b9a\u5728\u53f3\u513f\u5b50\u4e2d\u7684\u7ed3\u8bba\u3002 \u7531\u4e8e2-3\u4fdd\u8bc1\u4e86\u6240\u6709\u5206\u652f\u7ed3\u70b9\u4e00\u5b9a\u6709\u591a\u4e2a\u513f\u5b50\uff0c\u4e8e\u662f\u8bc1\u660e\u663e\u7136\u3002 \u6709\u4e86\u4ee5\u4e0a\u4e24\u6761\u6027\u8d28\u7684\u4fdd\u8bc1\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u77e5\u9053\u7ecf\u8fc7\u4e0a\u9762\u4e24\u4e2a\u6b65\u9aa4\uff0c\u4e00\u4e2a\u5220\u9664\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\uff0c\u88ab\u8f6c\u5316\u6210\u4e86\u4e00\u4e2a\u5220\u9664\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\u3002 \u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9 \u4e8e\u662f\u672c\u8d28\u4e0a\u53ea\u6709\u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\u3002 \u6211\u4eec\u8003\u8651\u63a5\u7740\u6765\u5206\u6790\u95ee\u9898 \u5220\u9664\u7684\u662f3type\u7ed3\u70b9 \u7531\u4e8e\u8fd9\u4e2a\u53f6\u5b50\u7ed3\u70b9\u6709\u591a\u4e2a\u503c\uff0c\u76f4\u63a5\u5220\u6389\u90a3\u4e2a\uff0c\u7136\u540e\u628a\u8fd9\u4e2a\u7ed3\u70b9\u6539\u62102type\u7ed3\u70b9\u5c31\u597d\u4e86\u3002 \u4e3e\u4e2a\u6817\u5b50\u3002 \u5220\u9664\u7684\u662f2type\u7ed3\u70b9 \u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u80af\u5b9a\u4e0d\u80fd\u76f4\u63a5\u628a\u8fd9\u4e2a\u7ed3\u70b9\u5220\u4e86\uff0c\u4e0d\u7136\u6811\u5c31\u4e0d\u4e00\u6837\u9ad8\u4e86\u3002 \u4e8e\u662f\u6211\u4eec\u53ea\u80fd\u5bfb\u6c42\u5b83\u7684\u7236\u4eb2\u6216\u8005\u5144\u5f1f\u7684\u5e2e\u52a9\u3002 \u7ee7\u7eed\u8fdb\u884c\u5206\u7c7b\u8ba8\u8bba 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f \u5176\u4e2dA\u4ee3\u8868\u88ab\u5220\u9664\u7684\u53f6\u5b50\uff0c\u8fd9\u6837\u8c03\u6574\u4e00\u4e0b\u987a\u5e8f\u5c31\u5b8c\u6210\u4e86\u8c03\u6574\u8fc7\u7a0b\u3002 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f A\u662f\u8981\u88ab\u5220\u9664\u7684\u7ed3\u70b9\uff0c\u7ecf\u8fc7\u8fd9\u6837\u7684\u8c03\u6574\uff0c\u628aA\u62c9\u5230\u4e86\u6700\u4e0a\u9762\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u5b8c\u5168\u5904\u7406\u5b8c\u6210\uff0c\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52\uff0c\u4e0d\u8fc7\u6211\u4eec\u5148\u5b8c\u6210\u5bf9\u5220\u9664\u53f6\u5b50\u4e00\u6b65\u7684\u64cd\u4f5c\uff0c\u4e4b\u540e\u6211\u4eec\u518d\u7edf\u4e00\u8ba8\u8bba\u5982\u679c\u9012\u5f52\u5730\u5904\u7406\u3002 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 \u5220\u9664A\u7ed3\u70b9\uff0c\u53ea\u9700\u8981\u5c06B\u548cC\u538b\u6210\u4e00\u4e2a\u7ed3\u70b9\u5e76\u4e14\u628a\u7236\u4eb2\u53d8\u62102type\u5c31\u597d\u4e86\uff0c\u518d\u6b21\u6ce8\u610f\u8fd9\u91ccA\u662f\u4e2a\u53f6\u5b50\uff0cA\u662f\u5b50\u6811\u7684\u60c5\u51b5\u4e4b\u540e\u518d\u8ba8\u8bba 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u601d\u8def\u7c7b\u4f3c\u5728\u6b64\u4e0d\u518d\u8d58\u8ff0\u3002 \u5bf9\u4e8e\u9012\u5f52\u5904\u7406\u7684\u8ba8\u8bba \u53ef\u4ee5\u53d1\u73b0\u5bf9\u4e8e\u5220\u9664A\u8fd9\u4e2a\u53f6\u5b50\u7684\u4e00\u6b65\u64cd\u4f5c\u4e2d\u53ea\u6709 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f \u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5fc5\u987b\u8981\u8fdb\u884c\u5411\u4e0a\u9012\u5f52\u5904\u7406\u3002 \u89c2\u5bdf\u8fd9\u4e2a\u65f6\u5019\uff0c\u5411\u4e0a\u5904\u7406\u65f6 \\(A\\) \u662f\u4e00\u9897\u5b50\u6811\uff0c\u4e14\u4e4b\u540e\u4e00\u4e2a\u513f\u5b50\uff0c\u8fd9\u4e2a\u6027\u8d28\u975e\u5e38\u5173\u952e\u3002 \u4e8b\u5b9e\u4e0a\u4e0b\u9762\u7684\u8ba8\u8bba\u4e0e\u4e0a\u9762\u7684\u8ba8\u8bba\u7684\u533a\u522b\u5c31\u5728\u4e8e\uff0c\u88ab\u5220\u9664\u7684\u7ed3\u70b9A\u4ece\u4e00\u4e2a\u53f6\u5b50\uff0c\u53d8\u6210\u4e86\u4e00\u4e2a\u53ea\u6709\u4e00\u4e2a\u513f\u5b50\u7684\u4e14\u6839\u4e3aA\u7684\u5b50\u6811\u7684\u6839\u3002 \u9012\u5f52\u65f6A\u4e5f\u4f1a\u9047\u5230 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u8fd94\u79cd\u60c5\u51b5 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f \u7531\u4e8e\u73b0\u5728A\u4e0d\u518d\u662f\u53f6\u5b50\u4e86\uff0c\u4e8e\u662f\u8ba8\u8bba\u8981\u52a0\u4e0a\u5b50\u6811\u3002 \u8c03\u6574\u5982\u56fe 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f \u8c03\u6574\u65b9\u5f0f\u5982\u4e0b\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8fd8\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 \u8c03\u6574\u65b9\u5f0f\u5982\u4e0b 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u8c03\u6574\u65b9\u6cd5\u5982\u4e0b \u7efc\u5408\u4ee5\u4e0a3\u79cd\u60c5\u51b5\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd8\u662f\u53ea\u6709\u4e00\u79cd\u60c5\u51b5\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52\uff0c\u8fd9\u65f6\u4f9d\u65e7\u6ee1\u8db3\u5b50\u4e66\u4e2d\u53ea\u6709\u4e00\u4e2a\u513f\u5b50\uff0c\u4e8e\u662f\u53ef\u4ee5\u7ee7\u7eed\u4e0a\u9762\u7684\u8fc7\u7a0b \u6700\u7ec8\u8981\u4e48\u7ec8\u6b62\u4e8e\u6ca1\u6709\u7236\u4eb2\uff0c\u8981\u4e48\u7ec8\u6b62\u4e8e\u5176\u4ed63\u79cd\u60c5\u51b5 \u9012\u5f52\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u7236\u4eb2 \u8fd9\u65f6\u9700\u8981\u91cd\u65b0\u6307\u5b9a\u6574\u4e2a2-3\u6811\u7684\u6839 \u5b8c\u7ed3\u6563\u82b1\uff08 \u8d34\u4e2a\u4ee3\u7801\u5427 #include <iostream> #include <algorithm> #include <cassert> using namespace std; template<typename T> class _23Tree{ private: struct Node{ Node *ch[4], *fa; T data[3]; unsigned int height; bool isThree; }; Node *createNode(); Node *root; void maintain(Node *x); void erase_maintain(Node *); void _display(Node *x); Node *_find(T); public: _23Tree(); unsigned int getHeight()const; void insert(T); void erase(T); bool find(T); void display(); }; template<typename T> _23Tree<T>::_23Tree(){ root = nullptr; } template<typename T> typename _23Tree<T>::Node *_23Tree<T>::createNode(){ Node *t = new Node(); // clear node for(int i = 0; i < 3; i++)t->ch[i] = nullptr; t->fa = nullptr; t->height = 0; t->isThree = false; return t; } template<typename T> void _23Tree<T>::maintain(_23Tree<T>::Node *x){ // maintain for a single tree // whose father is to be inserted // initially x's father exists Node *y = x->fa; if(y->isThree){ // when x's father is 3-type //find the loc int ch_loc = 0; for(int i = 0; i < 3 ; i++){ if(y->ch[i] == x) { ch_loc = i; break; } } //insert the pointers into y for(int i = 3; i > ch_loc; i--){ y->ch[i] = y->ch[i - 1]; } y->ch[ch_loc] = x->ch[0]; y->ch[ch_loc+1] = x->ch[1]; for(int i = 0 ; i < 4; i++){ y->ch[i]->fa = y; } //insert data into y y->data[2] = x->data[0]; sort(y->data, y->data+3); //split y Node *tmp = createNode(); Node *p1 = createNode(); Node *p2 = createNode(); tmp->data[0] = y->data[1]; p1->data[0] = y->data[0]; p2->data[0] = y->data[2]; p1->ch[0] = y->ch[0]; p1->ch[1] = y->ch[1]; p2->ch[0] = y->ch[2]; p2->ch[1] = y->ch[3]; p1->fa = p2->fa = tmp; p1->ch[0]->fa = p1->ch[1]->fa = p1; p2->ch[0]->fa = p2->ch[1]->fa = p2; tmp->ch[0] = p1; tmp->ch[1] = p2; p1->height = p2->height = y->height; tmp->height = p1->height + 1; // exchange y's father Node *z = y->fa; tmp->fa = z; if(z == nullptr){ root = tmp; }else{ int child_size = z->isThree ? 3 : 2; for(int i=0;i<child_size ;i++){ if(z->ch[i] == y){ child_size = i; break; } } z->ch[child_size] = tmp; delete y; maintain(tmp); } }else{ // when x's father is 2-type y->isThree = true; //find the loc int ch_loc = 0; for(int i = 0; i < 2; i++){ if(y->ch[i] == x){ ch_loc = i; break; } } ch_loc ^= 1; // insert the pointer into y if(ch_loc == 0){ y->ch[1] = x->ch[0]; y->ch[2] = x->ch[1]; }else{ y->ch[2] = y->ch[1]; y->ch[0] = x->ch[0]; y->ch[1] = x->ch[1]; } for(int i=0;i<3;i++){ y->ch[i]->fa = y; } //insert the data into y y->data[1] = x->data[0]; std::sort(y->data, y->data+2); delete x; } } template<typename T> unsigned int _23Tree<T>::getHeight()const{ return root->height; } template<typename T> void _23Tree<T>::insert(T x){ Node *cur = root; if(cur == nullptr){ root = createNode(); root->data[0] = x; return; } Node *y = cur; while(cur != nullptr){ int R = cur->isThree ? 2 : 1; int i; for(i = 0; i < R; i++){ if(cur -> data[i] < x){ // break; }else{ break; } } // i = min(i, R-1); y = cur; cur = cur->ch[i]; } if(y->isThree){ //insert new node y->data[2] = x; std::sort(y->data, y->data+3); // cur is y's father cur = y->fa; // split 4-type node Node *tmp = createNode(); Node *p1 = createNode(); Node *p2 = createNode(); p1->data[0] = y->data[0]; tmp->data[0] = y->data[1]; p2->data[0] = y->data[2]; tmp->ch[0] = p1; tmp->ch[1] = p2; p1->fa = tmp; p2->fa = tmp; tmp->height = 1; tmp->fa = y->fa; //exchange cur's son to the new 3 node //when father is nullptr if(cur == nullptr){ root = tmp; delete y; return; } //when father exists int child_size = (cur->isThree ? 3 : 2); for(int i = 0; i < child_size; i++){ if(cur -> ch[i] == y){ child_size = i; break; } } cur->ch[child_size] = tmp; tmp->fa = cur; delete y; //update recursively maintain(tmp); }else{ y->data[1] = x; std::sort(y->data, y->data+2); y->isThree = true; } } template<typename T> void _23Tree<T>::erase(T v) { Node *x = _find(v); if(x == nullptr) return; if(x->ch[0] == nullptr){ // x is leaf if(x->isThree){ int child_size = x->isThree ? 2 : 1; x->isThree = false; int loc = 0; for(loc = 0; loc < child_size; loc++){ if(x->data[loc] != v)break; } swap(x->data[loc], x->data[0]); x->data[1] = T{}; }else{ erase_maintain(x); } }else{ // x is not leaf int loc = 0; int child_size = x->isThree ? 2 : 1; for(loc = 0; loc < child_size; loc ++){ if(x->data[loc] == v)break; } assert(loc < child_size); // find next in InOrder Node *y = x->ch[loc + 1]; while(y->ch[0] != nullptr) y = y->ch[0]; x->data[loc] = y->data[0]; if(y->isThree){ int child_size = y->isThree ? 2 : 1; y->isThree = false; swap(y->data[1], y->data[0]); y->data[1] = T{}; }else{ erase_maintain(y); } } } template<typename T> bool _23Tree<T>::find(T v) { return (_find(v) != nullptr); } template<typename T> void _23Tree<T>::display() { _display(root); } template<typename T> void _23Tree<T>::_display(_23Tree::Node *x) { // cout << x << endl; if(x == nullptr) return; int child_size = x->isThree ? 2 : 1; //son list _display(x->ch[0]); for(int i=0;i<child_size;i++){ cout << x->data[i] << \" \" << x->height << endl; _display(x->ch[i+1]); } } template<typename T> typename _23Tree<T>::Node *_23Tree<T>::_find(T v) { Node *x = this->root; while(x != nullptr){ int child_size = x->isThree ? 2 : 1; bool flag = false; for(int i=0;i<child_size;i++){ if(x->data[i] == v)flag = true; } if(flag) break; int i = 0; for(i=0;i<child_size;i++){ if(v < x->data[i])break; } x = x->ch[i]; } return x; } template<typename T> void _23Tree<T>::erase_maintain(_23Tree::Node *x) { int child_size = x->isThree ? 2 : 1; // x is 2-type node Node *y = x->fa; if(y == nullptr){ // when father doesn't exist root = x->ch[1]; }else{ // when father exists //find x's location in y child_size = y->isThree ? 2 : 1; int loc = -1; for(int i=0; i<= child_size; i++){ if(y->ch[i] == x){ loc = i; break; } } assert(loc != -1); if(y -> isThree){ // father is 3-type node int to = 0; if(loc == 0)to = 1; if(loc == 1)to = 2; if(loc == 2)to = 1; Node *w = y->ch[to]; if(w->isThree){ if(loc == 0){ if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->data[0] = y->data[0]; y->data[0] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[1] = w->ch[0]; for(int i=0;i<=1;i++)w->ch[i] = w->ch[i+1]; w->ch[2] = nullptr; if(x->ch[1]!=nullptr)x->ch[1]->fa = x; }else if(loc == 1){ if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->data[0] = y->data[1]; y->data[1] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[1] = w->ch[0]; for(int i=0;i<=1;i++)w->ch[i] = w->ch[i+1]; w->ch[2] = nullptr; if(x->ch[1]!=nullptr)x->ch[1]->fa = x; }else{ if(x->ch[1] == nullptr) x->ch[1] = x->ch[0]; x->data[0] = y->data[1]; y->data[1] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[0] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[0]!=nullptr)x->ch[0]->fa = x; } }else{ if(loc == 0){ w->isThree = true; w->data[1] = w->data[0]; w->data[0] = y->data[0]; y->data[0] = y->data[1]; y->data[1] = T{}; y->isThree = false; for(int i=0;i<=1;i++)y->ch[i] = y->ch[i+1]; y->ch[2] = nullptr; for(int i=1;i>=0;i--)w->ch[i+1] = w->ch[i]; w->ch[0] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; }else if(loc == 1){ w->isThree = true; w->data[1] = w->data[0]; w->data[0] = y->data[1]; y->data[1] = T{}; y->isThree = false; y->ch[1] = y->ch[2]; y->ch[2] = nullptr; for(int i=1;i>=0;i--)w->ch[i+1] = w->ch[i]; w->ch[0] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; }else{ w->isThree = true; w->data[1] = y->data[1]; y->data[1] = T{}; y->isThree = false; y->ch[2] = nullptr; w->ch[2] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; } } }else{ // father is 2-type node Node* w = y->ch[loc^1]; if(w->isThree){ w->isThree = false; if(loc == 1){ x->data[0] = y->data[0]; y->data[0] = w->data[1]; w->data[1] = T{}; if(x->ch[1] == nullptr) x->ch[1] = x->ch[0]; x->ch[0] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[0] != nullptr)x->ch[0]->fa = x; }else{ x->data[0] = y->data[0]; y->data[0] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->ch[1] = w->ch[0]; w->ch[0] = w->ch[1]; w->ch[1] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[1] != nullptr)x->ch[1]->fa = x; } }else{ w->isThree = true; w->data[1] = y->data[0]; //y->data[0] = 20000526; sort(w->data, w->data+2); if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; if(loc == 0){ w->ch[2] = w->ch[1]; w->ch[1] = w->ch[0]; w->ch[0] = x->ch[0]; if(w->ch[0] != nullptr)w->ch[0]->fa = w; }else{ w->ch[2] = x->ch[0]; if(w->ch[2] != nullptr)w->ch[2]->fa = w; } y->ch[loc] = nullptr; delete x; erase_maintain(y); } } } } int data[100000]; int main(int argc, char **argv){ // freopen(\"1.txt\",\"w\",stdout); srand(0); _23Tree<int> x; int n = 20; for(int i=1;i<=n;i++) data[i] = i; random_shuffle(data+1, data+1+n); for(int i=1;i<=n;i++){ x.insert(data[i]); } for(int i=1;i<=n/4;i++){ x.erase(data[i]); cout << \"erase \" << data[i] << endl; // x.display(); } x.display(); cout << x.getHeight() << endl; return 0; }","title":"23\u6811\u7684\u4e00\u79cd\u5220\u9664\u65b9\u6cd5"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#23","text":"\u4f3c\u4e4e\u7f51\u4e0a\u6ca1\u6709\u4ec0\u4e48\u5bf9\u4e8e23\u6811\u5220\u9664\u65f6\u5019\u7684\u6559\u7a0b \u5373\u4f7f\u662f\u6709\u7684\u90a3\u4e9b\u4e5f\u662f\u8eb2\u8eb2\u95ea\u95ea\uff0c\u4e0d\u8bb2\u4e2a\u660e\u767d\uff0c\u672c\u6587\u5c3d\u6211\u6700\u5927\u7684\u53ef\u80fd\u5c06\u8fd9\u4e2a\u64cd\u4f5c\u8bb2\u660e\u767d\uff08\u6700\u540e\u8fd8\u662f\u9e3d\u4e86 \u4e0d\u540c\u4e8e\u672c\u4eba\u7684\u522b\u7684blog\uff0c\u8fd9\u6b21\u672c\u4eba\u82b1\u5de8\u8d44\u753b\u4e86\u793a\u610f\u56fe\uff08 \u4f46\u662f\u8fd9\u4e2ablog\u522b\u4eba\u4e5f\u770b\u4e0d\u5230\u5440\uff08\uff08","title":"23\u6811\u7684\u4e00\u79cd\u5220\u9664\u65b9\u6cd5"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_1","text":"\u7f51\u4e0a\u76842-3\u6811\u6559\u7a0b \u633a\u53ef\u60dc\u7684\u662f\u8fd9\u7bc72-3\u6811\u6709\u4e24\u79cd\u5220\u9664\u65f6\u5019\u7684\u60c5\u51b5\u6ca1\u6709\u8ba8\u8bba\uff0c\u53ef\u80fd\u662f\u592a\u7b80\u5355\u4e86\u5427\uff08","title":"\u53c2\u8003\u8d44\u6599"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_2","text":"","title":"\u5220\u9664"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_3","text":"\u4e3a\u4e86\u4fdd\u8bc1\u6392\u7248\u6211\u7528\u7f29\u8fdb\u7b80\u5355\u4ecb\u7ecd\u4e00\u4e0b\u601d\u8def \u5220\u9664\u7684\u662f\u975e\u53f6\u5b50\u7ed3\u70b9 \u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9 \u5220\u9664\u7684\u662f3type\u7ed3\u70b9 \u5220\u9664\u7684\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u5144\u5f1f\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u5b58\u5728\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u5b58\u5728\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u9996\u5148\u6211\u4eec\u8981\u5220\u9664\u4e00\u4e2a\u7ed3\u70b9\u7684\u8bdd\u3002 \u6211\u4eec\u8981\u627e\u5230\u90a3\u4e2a\u7ed3\u70b9\u5728\u54ea\u91cc\u3002 \u6211\u4eec\u9996\u5148\u6839\u636e\u5220\u9664\u7ed3\u70b9\u7684\u60c5\u51b5\u8fdb\u884c\u5206\u7c7b\u3002 \u8981\u5220\u9664\u7684\u7ed3\u70b9\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9 \u8981\u5220\u9664\u7684\u7ed3\u70b9\u662f\u53f6\u5b50\u7ed3\u70b9","title":"\u5206\u6790\u5927\u7eb2"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_4","text":"\u8fd9\u65f6\u5019\u6211\u4eec\u627e\u5230\u8fd9\u4e2a\u7ed3\u70b9\u7684\u540e\u7ee7\uff0c\u7136\u540e\u628a\u540e\u7ee7\u7684\u503c\u548c\u8981\u5220\u9664\u7ed3\u70b9\u7684\u503cswap\u4e00\u4e0b\u3002 \u7136\u540e\u53ea\u9700\u8981\u5220\u9664\u540e\u7ee7\u5c31\u597d\u4e86\u3002 \u90a3...\u4e3a\u4ec0\u4e48\u8981\u8fd9\u4e48\u505a\u5462\uff0c\u4e00\u6765\u8fd9\u6837\u4f9d\u65e7\u80fd\u591f\u4fdd\u8bc1\u6574\u68f5\u6811\u7684\u4e2d\u5e8f\u904d\u5386\u7684\u6b63\u786e\u6027\u3002 \u6b64\u5916\u8fd9\u4e2a\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u662f\u4e00\u4e2a\u53f6\u5b50\uff01\u6211\u4eec\u63a5\u4e0b\u6765\u5c31\u6765\u8bc1\u660e\u8fd9\u4e2a\u7ed3\u8bba\u3002","title":"\u5220\u9664\u7684\u4e0d\u662f\u53f6\u5b50\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_5","text":"\u5982\u679c\u4f60\u5b66\u8fc7\u5176\u4ed6\u7684\u79cd\u7c7b\u7684\u5e73\u8861\u6811\u7684\u8bdd\uff0c\u4f60\u4f1a\u53d1\u73b0\u8fd9\u4e2a\u6027\u8d28\u662f\u4e00\u822c\u5e73\u8861\u6811\u6240\u6ca1\u6709\u7684\u3002 \u4f8b\u5982 \u5176\u4e2d5\u7ed3\u70b9\u7684\u540e\u7ee76\u5c31\u4e0d\u662f\u4e00\u4e2a\u53f6\u5b50 \u539f\u56e0\u5728\u4e8e5\u7684\u540e\u7ee7\u53ef\u80fd\u6709\u53f3\u513f\u5b50\uff0c\u4f46\u662f\u57282-3\u6811\u4e2d\u4fdd\u8bc1\u4e86\u9664\u53f6\u5b50\u8282\u70b9\u5916\uff0c\u6bcf\u4e2a\u5206\u652f\u8282\u70b9\u7684\u513f\u5b50\u6570\u91cf\u662f\u6ee1\u7684\uff0c\u4e8e\u662f\u610f\u5473\u7740\u4e00\u4e2a\u7ed3\u70b9\u4e00\u65e6\u6709\u513f\u5b50\uff0c\u5219\u4e00\u5b9a\u6709\u5f88\u591a\u513f\u5b50\uff0c\u8fd9\u4e2a\u5b83\u662f\u4e00\u4e2a\u540e\u7ee7\u76f8\u77db\u76fe\uff0c\u53ef\u4ee5\u81ea\u5df1\u60f3\u60f3\u3002","title":"\u4e00\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u662f\u4e00\u4e2a\u53f6\u5b50"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_6","text":"\u8fd9\u4e2a\u4e5f\u662f\u666e\u901a\u5e73\u8861\u6811\u6240\u6ca1\u6709\u7684\u6027\u8d28\u3002 \u4e3e\u4e2a\u6817\u5b50\u3002 \u8003\u86515\u7684\u540e\u7ee7\uff0c\u663e\u7136\u5f97\u5230\u4e86\u540e\u7ee7\u4e0d\u4e00\u5b9a\u5728\u53f3\u513f\u5b50\u4e2d\u7684\u7ed3\u8bba\u3002 \u7531\u4e8e2-3\u4fdd\u8bc1\u4e86\u6240\u6709\u5206\u652f\u7ed3\u70b9\u4e00\u5b9a\u6709\u591a\u4e2a\u513f\u5b50\uff0c\u4e8e\u662f\u8bc1\u660e\u663e\u7136\u3002 \u6709\u4e86\u4ee5\u4e0a\u4e24\u6761\u6027\u8d28\u7684\u4fdd\u8bc1\u3002\u6211\u4eec\u5c31\u53ef\u4ee5\u77e5\u9053\u7ecf\u8fc7\u4e0a\u9762\u4e24\u4e2a\u6b65\u9aa4\uff0c\u4e00\u4e2a\u5220\u9664\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\uff0c\u88ab\u8f6c\u5316\u6210\u4e86\u4e00\u4e2a\u5220\u9664\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\u3002","title":"\u4e00\u4e2a\u975e\u53f6\u5b50\u7ed3\u70b9\u7684\u540e\u7ee7\u4e00\u5b9a\u5728\u53f3\u513f\u5b50\u4e2d"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_7","text":"\u4e8e\u662f\u672c\u8d28\u4e0a\u53ea\u6709\u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9\u7684\u64cd\u4f5c\u3002 \u6211\u4eec\u8003\u8651\u63a5\u7740\u6765\u5206\u6790\u95ee\u9898","title":"\u5220\u9664\u7684\u662f\u53f6\u5b50\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#3type","text":"\u7531\u4e8e\u8fd9\u4e2a\u53f6\u5b50\u7ed3\u70b9\u6709\u591a\u4e2a\u503c\uff0c\u76f4\u63a5\u5220\u6389\u90a3\u4e2a\uff0c\u7136\u540e\u628a\u8fd9\u4e2a\u7ed3\u70b9\u6539\u62102type\u7ed3\u70b9\u5c31\u597d\u4e86\u3002 \u4e3e\u4e2a\u6817\u5b50\u3002","title":"\u5220\u9664\u7684\u662f3type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type","text":"\u8fd9\u4e2a\u65f6\u5019\u6211\u4eec\u80af\u5b9a\u4e0d\u80fd\u76f4\u63a5\u628a\u8fd9\u4e2a\u7ed3\u70b9\u5220\u4e86\uff0c\u4e0d\u7136\u6811\u5c31\u4e0d\u4e00\u6837\u9ad8\u4e86\u3002 \u4e8e\u662f\u6211\u4eec\u53ea\u80fd\u5bfb\u6c42\u5b83\u7684\u7236\u4eb2\u6216\u8005\u5144\u5f1f\u7684\u5e2e\u52a9\u3002 \u7ee7\u7eed\u8fdb\u884c\u5206\u7c7b\u8ba8\u8bba 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9","title":"\u5220\u9664\u7684\u662f2type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type2type-3type","text":"\u5176\u4e2dA\u4ee3\u8868\u88ab\u5220\u9664\u7684\u53f6\u5b50\uff0c\u8fd9\u6837\u8c03\u6574\u4e00\u4e0b\u987a\u5e8f\u5c31\u5b8c\u6210\u4e86\u8c03\u6574\u8fc7\u7a0b\u3002","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type2type-2type","text":"A\u662f\u8981\u88ab\u5220\u9664\u7684\u7ed3\u70b9\uff0c\u7ecf\u8fc7\u8fd9\u6837\u7684\u8c03\u6574\uff0c\u628aA\u62c9\u5230\u4e86\u6700\u4e0a\u9762\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u5b8c\u5168\u5904\u7406\u5b8c\u6210\uff0c\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52\uff0c\u4e0d\u8fc7\u6211\u4eec\u5148\u5b8c\u6210\u5bf9\u5220\u9664\u53f6\u5b50\u4e00\u6b65\u7684\u64cd\u4f5c\uff0c\u4e4b\u540e\u6211\u4eec\u518d\u7edf\u4e00\u8ba8\u8bba\u5982\u679c\u9012\u5f52\u5730\u5904\u7406\u3002","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type3type-2type","text":"\u5220\u9664A\u7ed3\u70b9\uff0c\u53ea\u9700\u8981\u5c06B\u548cC\u538b\u6210\u4e00\u4e2a\u7ed3\u70b9\u5e76\u4e14\u628a\u7236\u4eb2\u53d8\u62102type\u5c31\u597d\u4e86\uff0c\u518d\u6b21\u6ce8\u610f\u8fd9\u91ccA\u662f\u4e2a\u53f6\u5b50\uff0cA\u662f\u5b50\u6811\u7684\u60c5\u51b5\u4e4b\u540e\u518d\u8ba8\u8bba","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type3type-3type","text":"\u601d\u8def\u7c7b\u4f3c\u5728\u6b64\u4e0d\u518d\u8d58\u8ff0\u3002","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_8","text":"\u53ef\u4ee5\u53d1\u73b0\u5bf9\u4e8e\u5220\u9664A\u8fd9\u4e2a\u53f6\u5b50\u7684\u4e00\u6b65\u64cd\u4f5c\u4e2d\u53ea\u6709 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f \u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u5fc5\u987b\u8981\u8fdb\u884c\u5411\u4e0a\u9012\u5f52\u5904\u7406\u3002 \u89c2\u5bdf\u8fd9\u4e2a\u65f6\u5019\uff0c\u5411\u4e0a\u5904\u7406\u65f6 \\(A\\) \u662f\u4e00\u9897\u5b50\u6811\uff0c\u4e14\u4e4b\u540e\u4e00\u4e2a\u513f\u5b50\uff0c\u8fd9\u4e2a\u6027\u8d28\u975e\u5e38\u5173\u952e\u3002 \u4e8b\u5b9e\u4e0a\u4e0b\u9762\u7684\u8ba8\u8bba\u4e0e\u4e0a\u9762\u7684\u8ba8\u8bba\u7684\u533a\u522b\u5c31\u5728\u4e8e\uff0c\u88ab\u5220\u9664\u7684\u7ed3\u70b9A\u4ece\u4e00\u4e2a\u53f6\u5b50\uff0c\u53d8\u6210\u4e86\u4e00\u4e2a\u53ea\u6709\u4e00\u4e2a\u513f\u5b50\u7684\u4e14\u6839\u4e3aA\u7684\u5b50\u6811\u7684\u6839\u3002 \u9012\u5f52\u65f6A\u4e5f\u4f1a\u9047\u5230 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9 2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9 \u8fd94\u79cd\u60c5\u51b5","title":"\u5bf9\u4e8e\u9012\u5f52\u5904\u7406\u7684\u8ba8\u8bba"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type2type-3type_1","text":"\u7531\u4e8e\u73b0\u5728A\u4e0d\u518d\u662f\u53f6\u5b50\u4e86\uff0c\u4e8e\u662f\u8ba8\u8bba\u8981\u52a0\u4e0a\u5b50\u6811\u3002 \u8c03\u6574\u5982\u56fe","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a3type\u5144\u5f1f"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type2type-2type_1","text":"\u8c03\u6574\u65b9\u5f0f\u5982\u4e0b\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd9\u79cd\u60c5\u51b5\u4e0b\u8fd8\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f2type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a2type\u5144\u5f1f"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type3type-2type_1","text":"\u8c03\u6574\u65b9\u5f0f\u5982\u4e0b","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f2type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#2type3type-3type_1","text":"\u8c03\u6574\u65b9\u6cd5\u5982\u4e0b \u7efc\u5408\u4ee5\u4e0a3\u79cd\u60c5\u51b5\uff0c\u53ef\u4ee5\u53d1\u73b0\u8fd8\u662f\u53ea\u6709\u4e00\u79cd\u60c5\u51b5\u9700\u8981\u7ee7\u7eed\u5411\u4e0a\u9012\u5f52\uff0c\u8fd9\u65f6\u4f9d\u65e7\u6ee1\u8db3\u5b50\u4e66\u4e2d\u53ea\u6709\u4e00\u4e2a\u513f\u5b50\uff0c\u4e8e\u662f\u53ef\u4ee5\u7ee7\u7eed\u4e0a\u9762\u7684\u8fc7\u7a0b \u6700\u7ec8\u8981\u4e48\u7ec8\u6b62\u4e8e\u6ca1\u6709\u7236\u4eb2\uff0c\u8981\u4e48\u7ec8\u6b62\u4e8e\u5176\u4ed63\u79cd\u60c5\u51b5","title":"2type\u7ed3\u70b9\u7684\u7236\u4eb2\u662f3type\u7ed3\u70b9 \u4e14\u6709\u4e00\u4e2a\u5144\u5f1f\u662f3type\u7ed3\u70b9"},{"location":"blog/2020/23%E6%A0%91%E7%9A%84%E4%B8%80%E7%A7%8D%E5%88%A0%E9%99%A4%E6%96%B9%E6%B3%95/#_9","text":"\u8fd9\u65f6\u9700\u8981\u91cd\u65b0\u6307\u5b9a\u6574\u4e2a2-3\u6811\u7684\u6839 \u5b8c\u7ed3\u6563\u82b1\uff08 \u8d34\u4e2a\u4ee3\u7801\u5427 #include <iostream> #include <algorithm> #include <cassert> using namespace std; template<typename T> class _23Tree{ private: struct Node{ Node *ch[4], *fa; T data[3]; unsigned int height; bool isThree; }; Node *createNode(); Node *root; void maintain(Node *x); void erase_maintain(Node *); void _display(Node *x); Node *_find(T); public: _23Tree(); unsigned int getHeight()const; void insert(T); void erase(T); bool find(T); void display(); }; template<typename T> _23Tree<T>::_23Tree(){ root = nullptr; } template<typename T> typename _23Tree<T>::Node *_23Tree<T>::createNode(){ Node *t = new Node(); // clear node for(int i = 0; i < 3; i++)t->ch[i] = nullptr; t->fa = nullptr; t->height = 0; t->isThree = false; return t; } template<typename T> void _23Tree<T>::maintain(_23Tree<T>::Node *x){ // maintain for a single tree // whose father is to be inserted // initially x's father exists Node *y = x->fa; if(y->isThree){ // when x's father is 3-type //find the loc int ch_loc = 0; for(int i = 0; i < 3 ; i++){ if(y->ch[i] == x) { ch_loc = i; break; } } //insert the pointers into y for(int i = 3; i > ch_loc; i--){ y->ch[i] = y->ch[i - 1]; } y->ch[ch_loc] = x->ch[0]; y->ch[ch_loc+1] = x->ch[1]; for(int i = 0 ; i < 4; i++){ y->ch[i]->fa = y; } //insert data into y y->data[2] = x->data[0]; sort(y->data, y->data+3); //split y Node *tmp = createNode(); Node *p1 = createNode(); Node *p2 = createNode(); tmp->data[0] = y->data[1]; p1->data[0] = y->data[0]; p2->data[0] = y->data[2]; p1->ch[0] = y->ch[0]; p1->ch[1] = y->ch[1]; p2->ch[0] = y->ch[2]; p2->ch[1] = y->ch[3]; p1->fa = p2->fa = tmp; p1->ch[0]->fa = p1->ch[1]->fa = p1; p2->ch[0]->fa = p2->ch[1]->fa = p2; tmp->ch[0] = p1; tmp->ch[1] = p2; p1->height = p2->height = y->height; tmp->height = p1->height + 1; // exchange y's father Node *z = y->fa; tmp->fa = z; if(z == nullptr){ root = tmp; }else{ int child_size = z->isThree ? 3 : 2; for(int i=0;i<child_size ;i++){ if(z->ch[i] == y){ child_size = i; break; } } z->ch[child_size] = tmp; delete y; maintain(tmp); } }else{ // when x's father is 2-type y->isThree = true; //find the loc int ch_loc = 0; for(int i = 0; i < 2; i++){ if(y->ch[i] == x){ ch_loc = i; break; } } ch_loc ^= 1; // insert the pointer into y if(ch_loc == 0){ y->ch[1] = x->ch[0]; y->ch[2] = x->ch[1]; }else{ y->ch[2] = y->ch[1]; y->ch[0] = x->ch[0]; y->ch[1] = x->ch[1]; } for(int i=0;i<3;i++){ y->ch[i]->fa = y; } //insert the data into y y->data[1] = x->data[0]; std::sort(y->data, y->data+2); delete x; } } template<typename T> unsigned int _23Tree<T>::getHeight()const{ return root->height; } template<typename T> void _23Tree<T>::insert(T x){ Node *cur = root; if(cur == nullptr){ root = createNode(); root->data[0] = x; return; } Node *y = cur; while(cur != nullptr){ int R = cur->isThree ? 2 : 1; int i; for(i = 0; i < R; i++){ if(cur -> data[i] < x){ // break; }else{ break; } } // i = min(i, R-1); y = cur; cur = cur->ch[i]; } if(y->isThree){ //insert new node y->data[2] = x; std::sort(y->data, y->data+3); // cur is y's father cur = y->fa; // split 4-type node Node *tmp = createNode(); Node *p1 = createNode(); Node *p2 = createNode(); p1->data[0] = y->data[0]; tmp->data[0] = y->data[1]; p2->data[0] = y->data[2]; tmp->ch[0] = p1; tmp->ch[1] = p2; p1->fa = tmp; p2->fa = tmp; tmp->height = 1; tmp->fa = y->fa; //exchange cur's son to the new 3 node //when father is nullptr if(cur == nullptr){ root = tmp; delete y; return; } //when father exists int child_size = (cur->isThree ? 3 : 2); for(int i = 0; i < child_size; i++){ if(cur -> ch[i] == y){ child_size = i; break; } } cur->ch[child_size] = tmp; tmp->fa = cur; delete y; //update recursively maintain(tmp); }else{ y->data[1] = x; std::sort(y->data, y->data+2); y->isThree = true; } } template<typename T> void _23Tree<T>::erase(T v) { Node *x = _find(v); if(x == nullptr) return; if(x->ch[0] == nullptr){ // x is leaf if(x->isThree){ int child_size = x->isThree ? 2 : 1; x->isThree = false; int loc = 0; for(loc = 0; loc < child_size; loc++){ if(x->data[loc] != v)break; } swap(x->data[loc], x->data[0]); x->data[1] = T{}; }else{ erase_maintain(x); } }else{ // x is not leaf int loc = 0; int child_size = x->isThree ? 2 : 1; for(loc = 0; loc < child_size; loc ++){ if(x->data[loc] == v)break; } assert(loc < child_size); // find next in InOrder Node *y = x->ch[loc + 1]; while(y->ch[0] != nullptr) y = y->ch[0]; x->data[loc] = y->data[0]; if(y->isThree){ int child_size = y->isThree ? 2 : 1; y->isThree = false; swap(y->data[1], y->data[0]); y->data[1] = T{}; }else{ erase_maintain(y); } } } template<typename T> bool _23Tree<T>::find(T v) { return (_find(v) != nullptr); } template<typename T> void _23Tree<T>::display() { _display(root); } template<typename T> void _23Tree<T>::_display(_23Tree::Node *x) { // cout << x << endl; if(x == nullptr) return; int child_size = x->isThree ? 2 : 1; //son list _display(x->ch[0]); for(int i=0;i<child_size;i++){ cout << x->data[i] << \" \" << x->height << endl; _display(x->ch[i+1]); } } template<typename T> typename _23Tree<T>::Node *_23Tree<T>::_find(T v) { Node *x = this->root; while(x != nullptr){ int child_size = x->isThree ? 2 : 1; bool flag = false; for(int i=0;i<child_size;i++){ if(x->data[i] == v)flag = true; } if(flag) break; int i = 0; for(i=0;i<child_size;i++){ if(v < x->data[i])break; } x = x->ch[i]; } return x; } template<typename T> void _23Tree<T>::erase_maintain(_23Tree::Node *x) { int child_size = x->isThree ? 2 : 1; // x is 2-type node Node *y = x->fa; if(y == nullptr){ // when father doesn't exist root = x->ch[1]; }else{ // when father exists //find x's location in y child_size = y->isThree ? 2 : 1; int loc = -1; for(int i=0; i<= child_size; i++){ if(y->ch[i] == x){ loc = i; break; } } assert(loc != -1); if(y -> isThree){ // father is 3-type node int to = 0; if(loc == 0)to = 1; if(loc == 1)to = 2; if(loc == 2)to = 1; Node *w = y->ch[to]; if(w->isThree){ if(loc == 0){ if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->data[0] = y->data[0]; y->data[0] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[1] = w->ch[0]; for(int i=0;i<=1;i++)w->ch[i] = w->ch[i+1]; w->ch[2] = nullptr; if(x->ch[1]!=nullptr)x->ch[1]->fa = x; }else if(loc == 1){ if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->data[0] = y->data[1]; y->data[1] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[1] = w->ch[0]; for(int i=0;i<=1;i++)w->ch[i] = w->ch[i+1]; w->ch[2] = nullptr; if(x->ch[1]!=nullptr)x->ch[1]->fa = x; }else{ if(x->ch[1] == nullptr) x->ch[1] = x->ch[0]; x->data[0] = y->data[1]; y->data[1] = w->data[1]; w->data[1] = T{}; w->isThree = false; x->ch[0] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[0]!=nullptr)x->ch[0]->fa = x; } }else{ if(loc == 0){ w->isThree = true; w->data[1] = w->data[0]; w->data[0] = y->data[0]; y->data[0] = y->data[1]; y->data[1] = T{}; y->isThree = false; for(int i=0;i<=1;i++)y->ch[i] = y->ch[i+1]; y->ch[2] = nullptr; for(int i=1;i>=0;i--)w->ch[i+1] = w->ch[i]; w->ch[0] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; }else if(loc == 1){ w->isThree = true; w->data[1] = w->data[0]; w->data[0] = y->data[1]; y->data[1] = T{}; y->isThree = false; y->ch[1] = y->ch[2]; y->ch[2] = nullptr; for(int i=1;i>=0;i--)w->ch[i+1] = w->ch[i]; w->ch[0] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; }else{ w->isThree = true; w->data[1] = y->data[1]; y->data[1] = T{}; y->isThree = false; y->ch[2] = nullptr; w->ch[2] = x->ch[0]==nullptr ? x->ch[1] : x->ch[0]; for(int i=0;i<=2;i++)if(w->ch[i]!=nullptr)w->ch[i]->fa = w; delete x; } } }else{ // father is 2-type node Node* w = y->ch[loc^1]; if(w->isThree){ w->isThree = false; if(loc == 1){ x->data[0] = y->data[0]; y->data[0] = w->data[1]; w->data[1] = T{}; if(x->ch[1] == nullptr) x->ch[1] = x->ch[0]; x->ch[0] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[0] != nullptr)x->ch[0]->fa = x; }else{ x->data[0] = y->data[0]; y->data[0] = w->data[0]; w->data[0] = w->data[1]; w->data[1] = T{}; if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; x->ch[1] = w->ch[0]; w->ch[0] = w->ch[1]; w->ch[1] = w->ch[2]; w->ch[2] = nullptr; if(x->ch[1] != nullptr)x->ch[1]->fa = x; } }else{ w->isThree = true; w->data[1] = y->data[0]; //y->data[0] = 20000526; sort(w->data, w->data+2); if(x->ch[0] == nullptr) x->ch[0] = x->ch[1]; if(loc == 0){ w->ch[2] = w->ch[1]; w->ch[1] = w->ch[0]; w->ch[0] = x->ch[0]; if(w->ch[0] != nullptr)w->ch[0]->fa = w; }else{ w->ch[2] = x->ch[0]; if(w->ch[2] != nullptr)w->ch[2]->fa = w; } y->ch[loc] = nullptr; delete x; erase_maintain(y); } } } } int data[100000]; int main(int argc, char **argv){ // freopen(\"1.txt\",\"w\",stdout); srand(0); _23Tree<int> x; int n = 20; for(int i=1;i<=n;i++) data[i] = i; random_shuffle(data+1, data+1+n); for(int i=1;i<=n;i++){ x.insert(data[i]); } for(int i=1;i<=n/4;i++){ x.erase(data[i]); cout << \"erase \" << data[i] << endl; // x.display(); } x.display(); cout << x.getHeight() << endl; return 0; }","title":"\u9012\u5f52\u8fc7\u7a0b\u4e2d\u6ca1\u6709\u7236\u4eb2"},{"location":"blog/2020/3-3SAT%E9%97%AE%E9%A2%98NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/","text":"\u8fd9\u662f\u7b80\u4ecb\u7684\u6d4b\u8bd5! \u8fd9\u662f\u7b80\u4ecb\u7684\u6d4b\u8bd5! ~~\u8fd9\u662f\u7b80\u4ecb\u7684\u6d4b\u8bd5!~~ \u8fd9\u662f\u7b80\u4ecb\u7684\u6d4b\u8bd5! \u8fd9\u662f\u7b80\u4ecb\u7684\u6d4b\u8bd5! 3-3SAT\u95ee\u9898NP-Complete\u6027\u8d28\u7684\u8bc1\u660e 3-3SAT\u95ee\u9898 \u9996\u5148\u6765\u8bf4\u660e\u4e00\u4e0b\u8fd9\u4e2a\u8bb0\u53f7\uff0c\u7b2c\u4e00\u4e2a \\(3\\) \u8868\u793a\u6bcf\u4e2a\u53d8\u91cf\u6700\u591a\u51fa\u73b0\u5728 \\(3\\) \u4e2a\u5b50\u53e5\u4e2d, \u7279\u522b\u7684\uff0c\u8ba4\u4e3a \\(\\overline{x}\\) \u4e0e \\(x\\) \u662f\u4e00\u4e2a\u53d8\u91cf\uff0c\u7b2c\u4e8c\u4e2a \\(3\\) \u8868\u793a\u6bcf\u4e2a\u5b50\u53e5\u4e2d\u6700\u591a\u51fa\u73b03\u4e2a\u53d8\u91cf\u3002\u6ce8\u610f\u8fd9\u91cc\u662f\u6700\u591a\uff0c\u5373\u6709\u53ef\u80fd\u51fa\u73b02\u4e2a\u53d8\u91cf\uff0c\u6216\u8005\u4e00\u4e2a\u53d8\u91cf\u3002 \u503c\u5f97\u8ba8\u8bba\u7684\u4e8b\uff0c\u5982\u679c\u6bcf\u4e2a\u5b50\u53e5\u4e2d\u90fd\u786e\u5b9a\u6027\u5730\u5b58\u57283\u4e2a\u53d8\u91cf\uff0c\u8fd9\u4e2a\u95ee\u9898\u5c06\u8131\u79bb \\(NP-Complete\\) \u7c7b\uff0c\u53d8\u6210\u4e00\u4e2a \\(P\\) \u95ee\u9898. \u4ece3SAT\u95ee\u9898\u5f52\u7ea6\u81f33-3SAT\u95ee\u9898 \u9996\u5148\u6211\u4eec\u77e5\u9053\uff0c\u8981\u60f3\u5b9e\u73b0\u8fd9\u4e2a\u5f52\u7ea6\uff0c\u8981\u89e3\u51b3\u7684\u5173\u952e\u5728\u4e8e\u5982\u4f55\u7f29\u51cf\u4e00\u4e2a\u53d8\u91cf\u7684\u51fa\u73b0\u6b21\u6570\u3002 \u663e\u7136\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0\u65b0\u7684\u6790\u53d6\u5b50\u53e5\u6765\u8fbe\u5230\u8fd9\u4e2a\u76ee\u7684\u3002 \u53ef\u4ee5\u901a\u8fc7\u771f\u503c\u8868\u76f4\u63a5\u6784\u9020 a b a *b 1 1 1 0 0 1 1 0 0 0 1 0 \u4ee5\u4e0a\u5c31\u662f\u8981\u6784\u9020\u7684\u5b50\u53e5 \u53ef\u4ee5\u76f4\u63a5\u6765\u5316\u7b80\u4e00\u4e0b \\( \\((a\\bigcap b) \\bigcup (\\overline{a}\\bigcap \\overline{b})\\) \\) \u5316\u7b80\u5f97\u5230 \\( \\((b\\bigcup \\overline{a})\\bigcap (a \\bigcup \\overline{b})\\) \\) \u53d1\u73b0\u53ef\u4ee5\u76f4\u63a5\u62c6\u6210\u4e24\u9879 \\( \\((b \\bigcup \\overline{a})\\quad (a \\bigcup \\overline{b})\\) \\) \u6784\u9020\u8fd9\u4e24\u9879\u7684\u610f\u4e49\u4fbf\u662f\uff0c\u5982\u679c\u5b58\u5728\u8fd9\u4e24\u4e2a\u7b49\u5f0f\uff0c\u90a3\u4e48a,b\u7684\u503c\u4e00\u5b9a\u662f\u76f8\u7b49\u7684\u3002 \u4e8e\u662f\u8003\u8651\u57283SAT\u95ee\u9898\u4e2d\u51fa\u73b0\u7684\u4e00\u7cfb\u5217\u51fa\u73b0 \\(x\\) \u7684\u8868\u8fbe\u5f0f \u4e00\u5b9a\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u5c06 \\(x\\) \u62c6\u6210\u4e0d\u540c\u7684\u53d8\u91cf\uff0c\u4f7f\u5f97\u6ee1\u8db3\u6216\u4e0d\u6ee1\u8db3\uff0c\u53ef\u4ee5\u53d1\u73b0\u4e00\u5171\u53ea\u9700\u8981 \\(n^2\\) \u7ea7\u7684\u4ee3\u4ef7\u3002 \u8bc1\u5b8c\u4e86~","title":"3-3SAT\u95ee\u9898NP\u5b8c\u5168\u6027\u8bc1\u660e"},{"location":"blog/2020/3-3SAT%E9%97%AE%E9%A2%98NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#3-3satnp-complete","text":"","title":"3-3SAT\u95ee\u9898NP-Complete\u6027\u8d28\u7684\u8bc1\u660e"},{"location":"blog/2020/3-3SAT%E9%97%AE%E9%A2%98NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#3-3sat","text":"\u9996\u5148\u6765\u8bf4\u660e\u4e00\u4e0b\u8fd9\u4e2a\u8bb0\u53f7\uff0c\u7b2c\u4e00\u4e2a \\(3\\) \u8868\u793a\u6bcf\u4e2a\u53d8\u91cf\u6700\u591a\u51fa\u73b0\u5728 \\(3\\) \u4e2a\u5b50\u53e5\u4e2d, \u7279\u522b\u7684\uff0c\u8ba4\u4e3a \\(\\overline{x}\\) \u4e0e \\(x\\) \u662f\u4e00\u4e2a\u53d8\u91cf\uff0c\u7b2c\u4e8c\u4e2a \\(3\\) \u8868\u793a\u6bcf\u4e2a\u5b50\u53e5\u4e2d\u6700\u591a\u51fa\u73b03\u4e2a\u53d8\u91cf\u3002\u6ce8\u610f\u8fd9\u91cc\u662f\u6700\u591a\uff0c\u5373\u6709\u53ef\u80fd\u51fa\u73b02\u4e2a\u53d8\u91cf\uff0c\u6216\u8005\u4e00\u4e2a\u53d8\u91cf\u3002 \u503c\u5f97\u8ba8\u8bba\u7684\u4e8b\uff0c\u5982\u679c\u6bcf\u4e2a\u5b50\u53e5\u4e2d\u90fd\u786e\u5b9a\u6027\u5730\u5b58\u57283\u4e2a\u53d8\u91cf\uff0c\u8fd9\u4e2a\u95ee\u9898\u5c06\u8131\u79bb \\(NP-Complete\\) \u7c7b\uff0c\u53d8\u6210\u4e00\u4e2a \\(P\\) \u95ee\u9898.","title":"3-3SAT\u95ee\u9898"},{"location":"blog/2020/3-3SAT%E9%97%AE%E9%A2%98NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#3sat3-3sat","text":"\u9996\u5148\u6211\u4eec\u77e5\u9053\uff0c\u8981\u60f3\u5b9e\u73b0\u8fd9\u4e2a\u5f52\u7ea6\uff0c\u8981\u89e3\u51b3\u7684\u5173\u952e\u5728\u4e8e\u5982\u4f55\u7f29\u51cf\u4e00\u4e2a\u53d8\u91cf\u7684\u51fa\u73b0\u6b21\u6570\u3002 \u663e\u7136\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u6dfb\u52a0\u65b0\u7684\u6790\u53d6\u5b50\u53e5\u6765\u8fbe\u5230\u8fd9\u4e2a\u76ee\u7684\u3002 \u53ef\u4ee5\u901a\u8fc7\u771f\u503c\u8868\u76f4\u63a5\u6784\u9020 a b a *b 1 1 1 0 0 1 1 0 0 0 1 0 \u4ee5\u4e0a\u5c31\u662f\u8981\u6784\u9020\u7684\u5b50\u53e5 \u53ef\u4ee5\u76f4\u63a5\u6765\u5316\u7b80\u4e00\u4e0b \\( \\((a\\bigcap b) \\bigcup (\\overline{a}\\bigcap \\overline{b})\\) \\) \u5316\u7b80\u5f97\u5230 \\( \\((b\\bigcup \\overline{a})\\bigcap (a \\bigcup \\overline{b})\\) \\) \u53d1\u73b0\u53ef\u4ee5\u76f4\u63a5\u62c6\u6210\u4e24\u9879 \\( \\((b \\bigcup \\overline{a})\\quad (a \\bigcup \\overline{b})\\) \\) \u6784\u9020\u8fd9\u4e24\u9879\u7684\u610f\u4e49\u4fbf\u662f\uff0c\u5982\u679c\u5b58\u5728\u8fd9\u4e24\u4e2a\u7b49\u5f0f\uff0c\u90a3\u4e48a,b\u7684\u503c\u4e00\u5b9a\u662f\u76f8\u7b49\u7684\u3002 \u4e8e\u662f\u8003\u8651\u57283SAT\u95ee\u9898\u4e2d\u51fa\u73b0\u7684\u4e00\u7cfb\u5217\u51fa\u73b0 \\(x\\) \u7684\u8868\u8fbe\u5f0f \u4e00\u5b9a\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u5c06 \\(x\\) \u62c6\u6210\u4e0d\u540c\u7684\u53d8\u91cf\uff0c\u4f7f\u5f97\u6ee1\u8db3\u6216\u4e0d\u6ee1\u8db3\uff0c\u53ef\u4ee5\u53d1\u73b0\u4e00\u5171\u53ea\u9700\u8981 \\(n^2\\) \u7ea7\u7684\u4ee3\u4ef7\u3002 \u8bc1\u5b8c\u4e86~","title":"\u4ece3SAT\u95ee\u9898\u5f52\u7ea6\u81f33-3SAT\u95ee\u9898"},{"location":"blog/2020/Burnside%E5%BC%95%E7%90%86%E4%B8%8EPolya%E8%AE%A1%E6%95%B0%E5%8E%9F%E7%90%86/","text":"Burnside\u5f15\u7406\u4e0ePolya\u8ba1\u6570\u539f\u7406 Burnside\u5f15\u7406\u7b80\u4ecb \u8fd9\u4e2a\u5b9a\u7406\u4e3b\u8981\u53d9\u8ff0\u4e86\u5728\u7f6e\u6362\u7fa4\u4f5c\u7528\u4e0b\u5143\u7d20\u7684\u4e0d\u52a8\u60c5\u51b5\u3002 \u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u6211\u4eec\u5f15\u5165\u989c\u8272\u7684\u6982\u5ff5\uff0c\u5047\u8bbe\u4e00\u4e2a\u957f\u5ea6\u4e3a \\(n\\) \u7684\u5411\u91cf \\(x\\) ,\u5176\u4e2d \\(x\\) \u7684\u7b2c \\(i\\) \u7ef4\u5ea6\u8bb0\u4e3a \\(x_{i}\\) ,\u5b9a\u4e49\u4e00\u5171\u6709 \\(m\\) \u79cd\u989c\u8272\uff0c\u5373 \\(x_{i}\\in{1,2,\\cdots,m}\\) \u3002\u5047\u8bbe \\(y\\) \u662f \\(n\\) \u4e0a\u7684\u4e00\u4e2a\u7f6e\u6362\uff0c\u5219 \\(y(x)\\) \u8868\u793a\u76f8\u5e94\u989c\u8272\u7684\u7f6e\u6362\u3002 \u8bbe \\(G\\) \u662f\u4e00\u4e2a\u7f6e\u6362\u7fa4\uff0c\u8bbe\u4e24\u4e2a\u672c\u8d28\u4e0d\u540c\u7684\u67d3\u8272\u4e3a\u4e24\u4e2a\u7ef4\u5ea6\u4e3a \\(n\\) \u7684\u5411\u91cf \\(x\\) \u4e0e \\(t\\) \uff0c\u4e14\u4e0d\u5b58\u5728 \\(g \\in G\\) \uff0c\u4f7f\u5f97 \\(g(x) = y\\) . \u5047\u8bbe\u6240\u6709\u7684\u67d3\u8272\u65b9\u6848\u96c6\u5408\u4e3a \\(S\\) . \u5219\u53ef\u4ee5\u53d1\u73b0\u4e0a\u9762\u5b9a\u4e49\u4e86\u4e00\u79cd\u7b49\u4ef7\u5173\u7cfb\u3002 \\(Burnside\\) \u5f15\u7406\u7ed9\u51fa\u4e86\u8ba1\u6570\u8fd9\u4e2a\u5546\u96c6\u5927\u5c0f\u7684\u65b9\u6cd5\u3002 Burnside\u5f15\u7406\u611f\u6027\u8bc1\u660e \u6211\u77e5\u9053\u81ea\u5df1\u6ca1\u6cd5\u5199\u51fa\u4e25\u683c\u7684\u8bc1\u660e\uff0c\u6211\u53ea\u80fd\u6309\u7167\u81ea\u5df1\u7684\u601d\u8def\u6574\u7406\u51fa\u5408\u6211\u81ea\u5df1\u601d\u8def\u7684\u8bc1\u660e\u601d\u8def\u3002 \u4e25\u683c\u601d\u8def\u53ef\u4ee5\u53c2\u8003 \u94fe\u63a5 \u8be5\u5b9a\u7406\u7684\u8bc1\u660e\u65b9\u5f0f\u4e3b\u8981\u57fa\u4e8e\u5bf9\u4e8e \\(G\\) \u7684\u4e0d\u540c\u5206\u7ec4\u8ba1\u6570\u65b9\u5f0f\u3002 \u6211\u4eec\u77e5\u9053\u4e0d\u540c\u7684 \\(G\\) \u7684\u8ba1\u6570\u65b9\u5f0f\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u7b49\u5f0f\uff0c\u800c\u53ea\u8981\u6211\u4eec\u8981\u6c42\u7684\u5546\u96c6\u5927\u5c0f\u5b58\u5728\u4e8e\u8fd9\u4e2a\u7b49\u5f0f\u4e4b\u4e2d\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6c42\u5f97\u5546\u96c6\u7684\u5927\u5c0f\u3002 \u6211\u4eec\u8003\u8651 \\(G\\) \u662f\u4e00\u4e2a\u7f6e\u6362\u7fa4\uff0c\u5c06\u5176\u4f5c\u7528\u4e8e \\(\\{1,2,\\cdots,n\\}\\) \u4e0a\u4ea6\u662f\u4e00\u4e2a\u7b49\u4ef7\u5173\u7cfb\uff0c\u5148\u8003\u8651\u5176\u4e2d\u7684\u4e00\u4e2a\u7b49\u4ef7\u7c7b \\([k]\\) . \u4e0d\u59a8\u8bb0 \\([k] = \\{k,k_{1},\\cdots,k_{p}\\}\\) ,\u5176\u4e2d\u7531\u7b49\u4ef7\u5173\u7cfb\u5f97\u5230\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a \\(k_{i}\\) \u90fd\u5b58\u5728\u4e00\u4e2a \\(g_{i} \\in G\\) \u4f7f\u5f97 \\(g_{i}(k_{i})=k\\) \u66f4\u611f\u6027\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u901a\u8fc7 \\(k_{i}\\) \u53ef\u4ee5\u627e\u5230\u4e00\u4e2a \\(G\\) \u7684\u5b50\u96c6 \\(G_{k_{i}}\\) \u5bf9\u4e8e\u8fd9\u4e2a\u5b50\u96c6\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5143\u7d20\uff0c\u90fd\u662f\u4e00\u4e2a\u7f6e\u6362\uff0c\u4e14\u662f\u4e00\u4e2a\u53ef\u4ee5\u4ece \\(k_{i} \\rightarrow k\\) \u7684\u7f6e\u6362\u3002 \u6839\u636e\u8fd9\u6837\u7684\u4e00\u4e2a\u7b80\u5355\u8bf4\u660e,\u6211\u4eec\u77e5\u9053 \\([k]\\) \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5bf9\u5e94\u4e86\u4e00\u4e2a \\(G\\) \u7684\u5b50\u96c6\uff0c\u5e76\u4e14\u8fd9\u4e9b\u5b50\u96c6\u662f\u65e0\u4ea4\u7684\u800c\u4e14\u8fd9\u4e9b\u7684\u5e76\u662f \\(G\\) \uff0c\u60f3\u60f3\u4e3a\u4ec0\u4e48\u5427\u3002 \u4e8e\u662f\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e \\(|G|\\) \u7684\u5f0f\u5b50\uff0c\u5373 \\( \\(|G| = \\sum_{\\hat{k}\\in [k]}|G_{\\hat{k}}|\\) \\) \u5230\u6b64\u4e3a\u6b62\u4fbf\u662f\u7b80\u5355\u601d\u8def\u80fd\u591f\u601d\u8003\u5230\u7684\u4f4d\u7f6e\u4e86\u3002 \u4e0b\u9762\u5c31\u662f\u4e9b\u53ea\u80fd\u4ef0\u6155\u7684\u63a8\u5bfc\u4e86\u3002 \u6570\u5b66\u5bb6\u4eec\u53d1\u73b0 \\(|G_{\\hat{k}}|\\) \u662f\u76f8\u7b49\u7684\u3002 \u53ef\u4ee5\u7b80\u5355\u5728\u8fd9\u91cc\u8bc1\u660e\u4e00\u4e0b\u3002 \u4ee4 \\(G_{k_{i}} = \\{g_{1},\\cdots,g_{q}\\}\\) \uff0c\u53d6 \\(g_{1}\\) \u4f5c\u7528\u4e8e \\(G_{k}\\) ,\u8bb0\u7ed3\u679c\u4e3a \\(\\hat{G_{k}}\\) \u73b0\u5728 \\(\\hat{G_{k}}\\) \u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f \\(k \\rightarrow k_{i}\\) \u7684\u4e00\u4e2a\u7f6e\u6362\uff0c\u6839\u636e\u5b9a\u4e49 \\(\\hat{G_{j}} \\subseteq G_{k}\\) \u7528\u6765\u6bd4\u5927\u5c0f\u7684\u8bdd\u5c31\u662f \\(|G_{k_{i}}| = \\hat{G_{k}} \\leq G_{k}\\) \u63a5\u4e0b\u6765\u53ea\u8981\u8bc1\u660e\u53cd\u5411\u5305\u542b\u5c31\u884c\u4e86\u3002 \u4efb\u53d6 \\(G_{k_{i}}\\) \u7684\u4e00\u4e2a\u5143\u7d20 \\(g_{j}\\) , \u663e\u7136 \\(g_{j} = g_{1}*g_{1}^{-1}*g_{j}\\) ,\u5176\u4e2d \\(g_{1}^{-1}*g_{j} \\in G_{k}\\) ,\u4e8e\u662f \\(g_{j} \\in \\hat{G_{k}}\\) \uff0c\u4e8e\u662f\u53cd\u5411\u5305\u542b\u5c31\u8bc1\u597d\u4e86\u3002 \u4e8e\u662f\u6211\u4eec\u5f97\u5230\u4e86 \\( \\(|G| = |G_{k}||[k]|\\) \\) \u4e3a\u4e86\u601d\u8def\u7684\u8fde\u8d2f\uff0c\u5e76\u6ca1\u6709\u4fdd\u6301\u548c\u53c2\u8003\u6587\u7ae0\u4e00\u6837\u7684\u8bb0\u53f7\u3002 \u63a5\u4e0b\u6765\uff0c\u5bf9\u4e8e \\(G\\) \u4e0e \\(S\\) \u5217\u4e00\u4e2a\u77e9\u9635\uff0c\u5b9a\u4e49 \\(\\mu(g,s) = [g(s)==s]\\) \\(\\sum_{g}\\sum_{s}\\mu(g,s) = \\sum_{s}|G_{s}| = t |G_{s}|[s] = t|G|\\) \u4e8e\u662f\u6700\u540e\u7684\u7ed3\u679c\u4e3a \\(t = \\frac{1}{|G|}\\sum_{g}\\sum_{s}\\mu(g,s)\\) Polya\u8ba1\u6570\u539f\u7406\u7684\u7b80\u8ff0\u4e0e\u611f\u6027\u8bc1\u660e \u4e4b\u6240\u4ee5\u5c06\u5b83\u79f0\u4e4b\u4e3a\u8ba1\u6570\u539f\u7406\u5728\u4e8e\u8fd9\u4e2a\u65b9\u6cd5\u7b80\u5316\u4e86\u4e0a\u9762\u5f15\u7406\u7684\u4e00\u90e8\u5206\u8ba1\u7b97\u3002 \u5f15\u7528\u4e0a\u9762Burnside\u5f15\u7406\u7684\u7ed3\u679c \\(t = \\frac{1}{|G|}\\sum_{g}\\sum_{s}\\mu(g,s)\\) Polya\u8ba1\u6570\u539f\u7406\u7b80\u5316\u4e86 \\(\\sum_{s}\\mu(g,s)\\) \u7684\u8ba1\u7b97\u3002 \u539f\u7406\u5728\u4e8e\u5bf9\u6bcf\u4e2a\u7f6e\u6362\u8fdb\u884c\u5faa\u73af\u5206\u89e3\u3002 \u5927\u6982\u4e3e\u4e2a\u4f8b\u5b50 \\(g = (1)(2,3)(4,5,7)(6)(9)\\) \u53ef\u4ee5\u7406\u6027\u89c2\u5bdf\u8fd9\u4e2a\u7f6e\u6362\uff0c\u53ea\u6709\u6bcf\u4e2a\u62ec\u53f7\u91cc\u7684\u5143\u7d20\u989c\u8272\u4e00\u6837\u7684\u65f6\u5019\u624d\u4f1a\u5bf9\u7b54\u6848\u6709\u8d21\u732e\u3002 \u4e8e\u662f \\(\\sum_{s}\\mu(g,s) = m^{|g|}\\) \u5176\u4e2d \\(|g|\\) \u8868\u793a \\(g\\) \u518d\u8fdb\u884c\u5faa\u73af\u5206\u89e3\u540e\u6709\u591a\u5c11\u4e2a\u62ec\u53f7\u3002 \u4e8e\u662f\u4e0a\u9762\u7684\u5f0f\u5b50\u5c31\u53d8\u6210\u4e86 \\(t = \\frac{1}{|G|}\\sum_{g}m^{|g|}\\)","title":"Burnside\u5f15\u7406\u4e0ePolya\u8ba1\u6570\u539f\u7406"},{"location":"blog/2020/Burnside%E5%BC%95%E7%90%86%E4%B8%8EPolya%E8%AE%A1%E6%95%B0%E5%8E%9F%E7%90%86/#burnsidepolya","text":"","title":"Burnside\u5f15\u7406\u4e0ePolya\u8ba1\u6570\u539f\u7406"},{"location":"blog/2020/Burnside%E5%BC%95%E7%90%86%E4%B8%8EPolya%E8%AE%A1%E6%95%B0%E5%8E%9F%E7%90%86/#burnside","text":"\u8fd9\u4e2a\u5b9a\u7406\u4e3b\u8981\u53d9\u8ff0\u4e86\u5728\u7f6e\u6362\u7fa4\u4f5c\u7528\u4e0b\u5143\u7d20\u7684\u4e0d\u52a8\u60c5\u51b5\u3002 \u4e3a\u4e86\u65b9\u4fbf\u8d77\u89c1\uff0c\u6211\u4eec\u5f15\u5165\u989c\u8272\u7684\u6982\u5ff5\uff0c\u5047\u8bbe\u4e00\u4e2a\u957f\u5ea6\u4e3a \\(n\\) \u7684\u5411\u91cf \\(x\\) ,\u5176\u4e2d \\(x\\) \u7684\u7b2c \\(i\\) \u7ef4\u5ea6\u8bb0\u4e3a \\(x_{i}\\) ,\u5b9a\u4e49\u4e00\u5171\u6709 \\(m\\) \u79cd\u989c\u8272\uff0c\u5373 \\(x_{i}\\in{1,2,\\cdots,m}\\) \u3002\u5047\u8bbe \\(y\\) \u662f \\(n\\) \u4e0a\u7684\u4e00\u4e2a\u7f6e\u6362\uff0c\u5219 \\(y(x)\\) \u8868\u793a\u76f8\u5e94\u989c\u8272\u7684\u7f6e\u6362\u3002 \u8bbe \\(G\\) \u662f\u4e00\u4e2a\u7f6e\u6362\u7fa4\uff0c\u8bbe\u4e24\u4e2a\u672c\u8d28\u4e0d\u540c\u7684\u67d3\u8272\u4e3a\u4e24\u4e2a\u7ef4\u5ea6\u4e3a \\(n\\) \u7684\u5411\u91cf \\(x\\) \u4e0e \\(t\\) \uff0c\u4e14\u4e0d\u5b58\u5728 \\(g \\in G\\) \uff0c\u4f7f\u5f97 \\(g(x) = y\\) . \u5047\u8bbe\u6240\u6709\u7684\u67d3\u8272\u65b9\u6848\u96c6\u5408\u4e3a \\(S\\) . \u5219\u53ef\u4ee5\u53d1\u73b0\u4e0a\u9762\u5b9a\u4e49\u4e86\u4e00\u79cd\u7b49\u4ef7\u5173\u7cfb\u3002 \\(Burnside\\) \u5f15\u7406\u7ed9\u51fa\u4e86\u8ba1\u6570\u8fd9\u4e2a\u5546\u96c6\u5927\u5c0f\u7684\u65b9\u6cd5\u3002","title":"Burnside\u5f15\u7406\u7b80\u4ecb"},{"location":"blog/2020/Burnside%E5%BC%95%E7%90%86%E4%B8%8EPolya%E8%AE%A1%E6%95%B0%E5%8E%9F%E7%90%86/#burnside_1","text":"\u6211\u77e5\u9053\u81ea\u5df1\u6ca1\u6cd5\u5199\u51fa\u4e25\u683c\u7684\u8bc1\u660e\uff0c\u6211\u53ea\u80fd\u6309\u7167\u81ea\u5df1\u7684\u601d\u8def\u6574\u7406\u51fa\u5408\u6211\u81ea\u5df1\u601d\u8def\u7684\u8bc1\u660e\u601d\u8def\u3002 \u4e25\u683c\u601d\u8def\u53ef\u4ee5\u53c2\u8003 \u94fe\u63a5 \u8be5\u5b9a\u7406\u7684\u8bc1\u660e\u65b9\u5f0f\u4e3b\u8981\u57fa\u4e8e\u5bf9\u4e8e \\(G\\) \u7684\u4e0d\u540c\u5206\u7ec4\u8ba1\u6570\u65b9\u5f0f\u3002 \u6211\u4eec\u77e5\u9053\u4e0d\u540c\u7684 \\(G\\) \u7684\u8ba1\u6570\u65b9\u5f0f\u53ef\u4ee5\u5f62\u6210\u4e00\u4e2a\u7b49\u5f0f\uff0c\u800c\u53ea\u8981\u6211\u4eec\u8981\u6c42\u7684\u5546\u96c6\u5927\u5c0f\u5b58\u5728\u4e8e\u8fd9\u4e2a\u7b49\u5f0f\u4e4b\u4e2d\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u6c42\u5f97\u5546\u96c6\u7684\u5927\u5c0f\u3002 \u6211\u4eec\u8003\u8651 \\(G\\) \u662f\u4e00\u4e2a\u7f6e\u6362\u7fa4\uff0c\u5c06\u5176\u4f5c\u7528\u4e8e \\(\\{1,2,\\cdots,n\\}\\) \u4e0a\u4ea6\u662f\u4e00\u4e2a\u7b49\u4ef7\u5173\u7cfb\uff0c\u5148\u8003\u8651\u5176\u4e2d\u7684\u4e00\u4e2a\u7b49\u4ef7\u7c7b \\([k]\\) . \u4e0d\u59a8\u8bb0 \\([k] = \\{k,k_{1},\\cdots,k_{p}\\}\\) ,\u5176\u4e2d\u7531\u7b49\u4ef7\u5173\u7cfb\u5f97\u5230\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a \\(k_{i}\\) \u90fd\u5b58\u5728\u4e00\u4e2a \\(g_{i} \\in G\\) \u4f7f\u5f97 \\(g_{i}(k_{i})=k\\) \u66f4\u611f\u6027\u4e00\u70b9\uff0c\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0\u901a\u8fc7 \\(k_{i}\\) \u53ef\u4ee5\u627e\u5230\u4e00\u4e2a \\(G\\) \u7684\u5b50\u96c6 \\(G_{k_{i}}\\) \u5bf9\u4e8e\u8fd9\u4e2a\u5b50\u96c6\u4e2d\u7684\u4efb\u610f\u4e00\u4e2a\u5143\u7d20\uff0c\u90fd\u662f\u4e00\u4e2a\u7f6e\u6362\uff0c\u4e14\u662f\u4e00\u4e2a\u53ef\u4ee5\u4ece \\(k_{i} \\rightarrow k\\) \u7684\u7f6e\u6362\u3002 \u6839\u636e\u8fd9\u6837\u7684\u4e00\u4e2a\u7b80\u5355\u8bf4\u660e,\u6211\u4eec\u77e5\u9053 \\([k]\\) \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u5bf9\u5e94\u4e86\u4e00\u4e2a \\(G\\) \u7684\u5b50\u96c6\uff0c\u5e76\u4e14\u8fd9\u4e9b\u5b50\u96c6\u662f\u65e0\u4ea4\u7684\u800c\u4e14\u8fd9\u4e9b\u7684\u5e76\u662f \\(G\\) \uff0c\u60f3\u60f3\u4e3a\u4ec0\u4e48\u5427\u3002 \u4e8e\u662f\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u5173\u4e8e \\(|G|\\) \u7684\u5f0f\u5b50\uff0c\u5373 \\( \\(|G| = \\sum_{\\hat{k}\\in [k]}|G_{\\hat{k}}|\\) \\) \u5230\u6b64\u4e3a\u6b62\u4fbf\u662f\u7b80\u5355\u601d\u8def\u80fd\u591f\u601d\u8003\u5230\u7684\u4f4d\u7f6e\u4e86\u3002 \u4e0b\u9762\u5c31\u662f\u4e9b\u53ea\u80fd\u4ef0\u6155\u7684\u63a8\u5bfc\u4e86\u3002 \u6570\u5b66\u5bb6\u4eec\u53d1\u73b0 \\(|G_{\\hat{k}}|\\) \u662f\u76f8\u7b49\u7684\u3002 \u53ef\u4ee5\u7b80\u5355\u5728\u8fd9\u91cc\u8bc1\u660e\u4e00\u4e0b\u3002 \u4ee4 \\(G_{k_{i}} = \\{g_{1},\\cdots,g_{q}\\}\\) \uff0c\u53d6 \\(g_{1}\\) \u4f5c\u7528\u4e8e \\(G_{k}\\) ,\u8bb0\u7ed3\u679c\u4e3a \\(\\hat{G_{k}}\\) \u73b0\u5728 \\(\\hat{G_{k}}\\) \u7684\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f \\(k \\rightarrow k_{i}\\) \u7684\u4e00\u4e2a\u7f6e\u6362\uff0c\u6839\u636e\u5b9a\u4e49 \\(\\hat{G_{j}} \\subseteq G_{k}\\) \u7528\u6765\u6bd4\u5927\u5c0f\u7684\u8bdd\u5c31\u662f \\(|G_{k_{i}}| = \\hat{G_{k}} \\leq G_{k}\\) \u63a5\u4e0b\u6765\u53ea\u8981\u8bc1\u660e\u53cd\u5411\u5305\u542b\u5c31\u884c\u4e86\u3002 \u4efb\u53d6 \\(G_{k_{i}}\\) \u7684\u4e00\u4e2a\u5143\u7d20 \\(g_{j}\\) , \u663e\u7136 \\(g_{j} = g_{1}*g_{1}^{-1}*g_{j}\\) ,\u5176\u4e2d \\(g_{1}^{-1}*g_{j} \\in G_{k}\\) ,\u4e8e\u662f \\(g_{j} \\in \\hat{G_{k}}\\) \uff0c\u4e8e\u662f\u53cd\u5411\u5305\u542b\u5c31\u8bc1\u597d\u4e86\u3002 \u4e8e\u662f\u6211\u4eec\u5f97\u5230\u4e86 \\( \\(|G| = |G_{k}||[k]|\\) \\) \u4e3a\u4e86\u601d\u8def\u7684\u8fde\u8d2f\uff0c\u5e76\u6ca1\u6709\u4fdd\u6301\u548c\u53c2\u8003\u6587\u7ae0\u4e00\u6837\u7684\u8bb0\u53f7\u3002 \u63a5\u4e0b\u6765\uff0c\u5bf9\u4e8e \\(G\\) \u4e0e \\(S\\) \u5217\u4e00\u4e2a\u77e9\u9635\uff0c\u5b9a\u4e49 \\(\\mu(g,s) = [g(s)==s]\\) \\(\\sum_{g}\\sum_{s}\\mu(g,s) = \\sum_{s}|G_{s}| = t |G_{s}|[s] = t|G|\\) \u4e8e\u662f\u6700\u540e\u7684\u7ed3\u679c\u4e3a \\(t = \\frac{1}{|G|}\\sum_{g}\\sum_{s}\\mu(g,s)\\)","title":"Burnside\u5f15\u7406\u611f\u6027\u8bc1\u660e"},{"location":"blog/2020/Burnside%E5%BC%95%E7%90%86%E4%B8%8EPolya%E8%AE%A1%E6%95%B0%E5%8E%9F%E7%90%86/#polya","text":"\u4e4b\u6240\u4ee5\u5c06\u5b83\u79f0\u4e4b\u4e3a\u8ba1\u6570\u539f\u7406\u5728\u4e8e\u8fd9\u4e2a\u65b9\u6cd5\u7b80\u5316\u4e86\u4e0a\u9762\u5f15\u7406\u7684\u4e00\u90e8\u5206\u8ba1\u7b97\u3002 \u5f15\u7528\u4e0a\u9762Burnside\u5f15\u7406\u7684\u7ed3\u679c \\(t = \\frac{1}{|G|}\\sum_{g}\\sum_{s}\\mu(g,s)\\) Polya\u8ba1\u6570\u539f\u7406\u7b80\u5316\u4e86 \\(\\sum_{s}\\mu(g,s)\\) \u7684\u8ba1\u7b97\u3002 \u539f\u7406\u5728\u4e8e\u5bf9\u6bcf\u4e2a\u7f6e\u6362\u8fdb\u884c\u5faa\u73af\u5206\u89e3\u3002 \u5927\u6982\u4e3e\u4e2a\u4f8b\u5b50 \\(g = (1)(2,3)(4,5,7)(6)(9)\\) \u53ef\u4ee5\u7406\u6027\u89c2\u5bdf\u8fd9\u4e2a\u7f6e\u6362\uff0c\u53ea\u6709\u6bcf\u4e2a\u62ec\u53f7\u91cc\u7684\u5143\u7d20\u989c\u8272\u4e00\u6837\u7684\u65f6\u5019\u624d\u4f1a\u5bf9\u7b54\u6848\u6709\u8d21\u732e\u3002 \u4e8e\u662f \\(\\sum_{s}\\mu(g,s) = m^{|g|}\\) \u5176\u4e2d \\(|g|\\) \u8868\u793a \\(g\\) \u518d\u8fdb\u884c\u5faa\u73af\u5206\u89e3\u540e\u6709\u591a\u5c11\u4e2a\u62ec\u53f7\u3002 \u4e8e\u662f\u4e0a\u9762\u7684\u5f0f\u5b50\u5c31\u53d8\u6210\u4e86 \\(t = \\frac{1}{|G|}\\sum_{g}m^{|g|}\\)","title":"Polya\u8ba1\u6570\u539f\u7406\u7684\u7b80\u8ff0\u4e0e\u611f\u6027\u8bc1\u660e"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/","text":"\u95ee\u9898\u5b9a\u4e49 \u5148\u5b9a\u4e49\u4e00\u4e0b\u7528\u5230\u7684\u7b26\u53f7 \u7a7a\u95f4\u4e2d\u6709\u8bb8\u591a\u5de5\u5382\uff0c\u4e5f\u6709\u8bb8\u591a\u5ba2\u6237\uff0c\u96c6\u5408 \\(F\\) \u8868\u793a\u5de5\u5382\u96c6\u5408\uff0c\u96c6\u5408 \\(C\\) \u8868\u793a\u5ba2\u6237\u96c6\u5408\uff0cy\u8981\u6c42\u7ed9\u6bcf\u4e2a\u5ba2\u6237\u9009\u62e9\u4e00\u4e2a\u5de5\u5382\uff0c\u4e00\u4e2a\u5de5\u5382\u53ef\u4ee5\u88ab\u591a\u4e2a\u5ba2\u6237\u6240\u9009\u62e9\uff0c\u82e5\u4e00\u4e2a\u5de5\u5382 \\(x\\) \u88ab\u5ba2\u6237 \\(y\\) \u6240\u9009\u62e9\u4e86\uff0c\u90a3\u4e48\u79f0 \\(y\\) \u89c4 \\(x\\) \u7ba1\u7406\uff0c\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\u4e3a \\(d(x,y)\uff0cx \\in F, y\\in C\\) \u8868\u793a \\(y\\) \u9009\u62e9 \\(x\\) \u7684\u4ee3\u4ef7\u3002 \u5177\u4f53\u95ee\u9898\u662f\u627e\u5230\u6700\u591a \\(k\\) \u4e2a\u5de5\u5382\uff0c\u7ba1\u7406\u6240\u6709\u7684\u5ba2\u6237\uff0c\u4f7f\u5f97\u8ddd\u79bb\u51fd\u6570\u548c\u6700\u5c0f\u3002 \u8fd9\u4e2a\u95ee\u9898\u5728\u516c\u5236\u7a7a\u95f4\u4e0a\u7684\u7248\u672c\u6210\u4e3aMetric K-median\u95ee\u9898\uff0c\u662f\u6307 \\(d(x,y)\\) \u6ee1\u8db3\u6b63\u5b9a\u6027\uff0c\u5bf9\u79f0\u6027\u548c\u4e09\u89d2\u5f62\u4e0d\u7b49\u5f0f\u3002 NP\uff1f \u8fd9\u5176\u5b9e\u5e76\u4e0d\u662f\u4e00\u4e2aNP-Hard\u95ee\u9898\uff0c\u8bbe\u8ba1\u8fd1\u4f3c\u7b97\u6cd5\u7684\u539f\u56e0\u5728\u4e8e\u52a0\u901f\u8fd0\u7b97 \\(C_{2n}^{n}\\) \u4f9d\u65e7\u662f\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u5185\u7684\u95ee\u9898\u3002 \u5c40\u90e8\u641c\u7d22\u7b97\u6cd5 \u9996\u5148\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5206\u6790\u5f97\u5230\u9009 \\(k\\) \u4e2a\u5de5\u5382\u4e00\u5b9a\u6bd4\u9009\u62e9\u5c0f\u4e8e \\(k\\) \u4e2a\u5de5\u5382\u8981\u4f18\u3002 \u73b0\u5728\u6765\u4ecb\u7ecd\u4e00\u79cd\u7b80\u5355\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002 \u9996\u5148\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u96c6\u5408 \\(S\\) , \u4f7f\u5f97 \\(S \\subset F\\) \uff0c \u5e76\u4e14 \\(|S| = k\\) \uff0c \u4e3a\u4e86\u63cf\u8ff0\u65b9\u4fbf\uff0c\u6269\u5c55\u4e00\u4e0b\u8ddd\u79bb\u51fd\u6570\u7684\u5b9a\u4e49\u4ee4 \\(d(S,y) = \\min{d(x,y)},x\\in S, y\\in C\\) \u7136\u540e\u679a\u4e3e\u6bcf\u4e2a\u4e0d\u5728 \\(S\\) \u4e2d\u7684\u5de5\u5382 \\(z\\) , \u5c1d\u8bd5\u66ff\u6362 \\(S\\) \u4e2d\u7684\u5de5\u5382 \\(x\\) , \u5982\u679c\u80fd\u4f7f\u5f97\u7b54\u6848\u53d8\u5f97\u66f4\u4f18\u5c31\u6362\u6389\u3002 \u8fd9\u6837\u5c31\u4f1a\u5f97\u5230\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u3002 \u5b9e\u73b0\u601d\u8def\u975e\u5e38\u7b80\u5355\u800c\u4e14\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u505a\u6cd5\u3002 \u8fd1\u4f3c\u5ea6\u5206\u6790 \u4ee4\u6700\u4f18\u89e3\u6240\u9009\u62e9\u7684\u5de5\u5382\u96c6\u5408\u4e3a \\(S^{*}\\) , \u5176\u4e2d\u7684\u5143\u7d20\u4e00\u822c\u4f7f\u7528 \\(o\\) \u6765\u8868\u793a\u3002 \u4ee4\u4e0a\u9762\u7b97\u6cd5\u5f97\u5230\u7684\u5de5\u5382\u96c6\u5408\u4e3a \\(S\\) , \u5176\u4e2d\u7684\u5143\u7d20\u4e00\u822c\u4f7f\u7528 \\(s\\) \u6765\u8868\u793a\u3002 \u4ee4 \\(C(x)\uff0cx\\in F\\) \u8868\u793a \\(x\\) \u8fd9\u4e2a\u5143\u7d20\u7ba1\u7406\u7684\u5ba2\u6237\u7684\u96c6\u5408\u3002 \u9996\u5148\u5b9a\u4e49\u4e00\u4e2a\u672f\u8bed\u53eb\u505a \u6355\u83b7 \uff0c\u5982\u679c \\(C(s) \\bigcap C(o) \\geq \\frac{1}{2}C(o)\\) \u5219\u79f0 \\(s\\) \u6355\u83b7\u4e86 \\(o\\) \u3002 \u5f15\u7406 \u5982\u679c \\(C(s) \\bigcap C(o) < \\frac{1}{2}C(o)\\) \uff0c\u5219 \\(C(o)\\) \u5b58\u5728\u4e00\u4e2a\u81ea\u5df1\u5230\u81ea\u5df1\u7684\u6ee1\u5c04\uff0c\u4f7f\u5f97\u6bcf\u4e00\u4e2a \\(x \\in C(s)\\bigcap C(o)\\) \uff0c\u53ef\u4ee5\u6620\u5c04\u5230 \\(C(o) - C(s)\\) . ~~\u6211\u4e5f\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48~~ \u5b9a\u7406 \u8be5\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u7684\u8fd1\u4f3c\u5ea6\u4e3a5 \u8bc1\u660e \u9996\u5148\u5c06 \\(S\\) \u6839\u636e\u6355\u83b7\u7684\u6700\u4f18\u89e3\u4e2d\u5143\u7d20\u7684\u4e2a\u6570\u5206\u7c7b \\(S_{0}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u4e0d\u6355\u83b7\u4efb\u4f55\u6700\u4f18\u89e3\u4e2d\u7684\u5143\u7d20 \\(S_{1}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u90fd\u6355\u83b7\u6700\u4f18\u89e3\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20 \\(S_{2}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u90fd\u6355\u83b7\u6700\u4f18\u89e3\u4e2d\u7684\u81f3\u5c11\u4e24\u4e2a\u5143\u7d20 \u4e0b\u9762\u8fdb\u884c \\(k\\) \u6b21\u4ea4\u6362\uff0c\u6ce8\u610f\u5e76\u4e0d\u662f\u8fde\u7eed\u8fdb\u884c \\(k\\) \u6b21\u4ea4\u6362\uff0c\u800c\u662f\u6bcf\u6b21\u90fd\u4ece\u521d\u59cb\u72b6\u6001\u8fdb\u884c\u4ea4\u6362\uff0c\u7efc\u5408\u8003\u8651\u5176\u7684\u4ee3\u4ef7\u3002 \u8003\u8651 \\(s \\in S_{1}\\) \u5b83\u6240\u6355\u83b7\u7684\u5143\u7d20\u4e3a \\(o\\) \u5bf9\u4e8e \\(C(o) \\bigcap C(s)\\) \u7684\u5143\u7d20\u5206\u914d\u7ed9 \\(o\\) \uff0c\u66f4\u4e25\u683c\u5730\u8fd9\u91cc\u5c06 \\(C(o)\\) \u7684\u6240\u6709\u5143\u7d20\u5168\u90e8\u5206\u914d \\(o\\) (\u8fd9\u6837\u76f8\u8f83\u4e8e\u4e4b\u524d\u90a3\u79cd\u65b9\u5f0f\u5e76\u4e0d\u4e00\u5b9a\u4f7f\u5f97\u5f53\u524d\u7684\u7b54\u6848\u66f4\u52a0\u4f18)\uff0c\u5bf9\u4e8e \\(C(o)-C(s)\\) \u7684\u5143\u7d20\uff0c\u56e0\u4e3a\u5176\u4e2d\u7684\u6709\u4e2a\u5143\u7d20\u4e3a \\(y\\) \uff0c\u5047\u8bbe\u5728 \\(S^{*}\\) \u4e2d\u5206\u914d\u7ed9\u4e86 \\(o^{*}\\) ,\u7531\u4e8e \\(s\\) \u5df2\u7ecf\u6355\u83b7\u4e86 \\(o\\) \u5e76\u4e14\u56e0\u4e3a \\(s \\in S_{1}\\) \u4e8e\u662f \\(o^{*}\\) \u4e00\u5b9a\u4e0d\u88ab \\(s\\) \u6240\u6355\u83b7\uff0c\u4e8e\u662f\u5728 \\(C(o^{*})\\) \u5b58\u5728\u4e00\u4e2a\u5355\u5c04\uff0c\u5047\u8bbe \\(s^{\u2018}\\) \u4e3a\u5176\u7684\u50cf\uff0c\u540c\u65f6 \\(s^{\u2019} \\in C(s^{*})\\) ,\u4e8e\u662f\u5c06 \\(s\\) \u5206\u914d\u7ed9 \\(s^{*}\\) \u7531\u4e09\u89d2\u4e0d\u7b49\u5f0f \\( \\(d(y, s^{*}) \\leq d(y,o^{*})+d(o^{*},s^{'}) + d(s^{'}, s^{*})\\) \\) \u8fd9\u6837\u4e00\u6b21\u4ea4\u6362\u4e4b\u540e \\(Cost\\) \u7684\u53d8\u5316\u4e3a \\(0 \\leq Cost(S-s+o) - Cost(S) \\leq \\sum_{x \\in C(o)} [d(o,x) - d(s,x)] + \\sum_{x \\in C(s) - C(o)}[d(y,o^{*})+d(o^{*},s^{'}) + d(s^{'}, s^{*}) - d(s, x)]\\) \u63a5\u4e0b\u6765\u8003\u8651\u5269\u4e0b\u7684\u5143\u7d20\u8be5\u5982\u4f55\u4ea4\u6362\uff0c\u53ef\u4ee5\u53d1\u73b0 \\(S_{0}\\) \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u6700\u591a\u4f7f\u7528 \\(2\\) \u6b21\u4fbf\u53ef\u4ee5\u5b8c\u6210\u6700\u4f18\u89e3\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u88ab\u4ea4\u6362\u4e00\u6b21\u3002 \u540c\u65f6\u53ef\u4ee5\u53d1\u73b0\u4e5f\u6ee1\u8db3\u4ee5\u4e0a\u4e0d\u7b49\u5f0f\u3002 \u4e8e\u662f\u3002 \u5c06\u8fd9\u4e2a\u4e0d\u7b49\u5f0f\u7d2f\u52a0 \\(k\\) \u6b21\uff0c\u5f97\u5230 \\(0 \\leq Cost(OPT) - Cost(S) + 2*(Cost(OPT) + Cost(OPT) + Cost(S) - Cost(S))\\) \u4e8e\u662f\u8fd1\u4f3c\u5ea6\u4e3a \\(5\\) .","title":"k-median\u95ee\u9898\u5728Metric\u7a7a\u95f4\u4e0a\u7684\u8fd1\u4f3c\u89e3\u6cd5"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_1","text":"\u5148\u5b9a\u4e49\u4e00\u4e0b\u7528\u5230\u7684\u7b26\u53f7 \u7a7a\u95f4\u4e2d\u6709\u8bb8\u591a\u5de5\u5382\uff0c\u4e5f\u6709\u8bb8\u591a\u5ba2\u6237\uff0c\u96c6\u5408 \\(F\\) \u8868\u793a\u5de5\u5382\u96c6\u5408\uff0c\u96c6\u5408 \\(C\\) \u8868\u793a\u5ba2\u6237\u96c6\u5408\uff0cy\u8981\u6c42\u7ed9\u6bcf\u4e2a\u5ba2\u6237\u9009\u62e9\u4e00\u4e2a\u5de5\u5382\uff0c\u4e00\u4e2a\u5de5\u5382\u53ef\u4ee5\u88ab\u591a\u4e2a\u5ba2\u6237\u6240\u9009\u62e9\uff0c\u82e5\u4e00\u4e2a\u5de5\u5382 \\(x\\) \u88ab\u5ba2\u6237 \\(y\\) \u6240\u9009\u62e9\u4e86\uff0c\u90a3\u4e48\u79f0 \\(y\\) \u89c4 \\(x\\) \u7ba1\u7406\uff0c\u5b9a\u4e49\u8ddd\u79bb\u51fd\u6570\u4e3a \\(d(x,y)\uff0cx \\in F, y\\in C\\) \u8868\u793a \\(y\\) \u9009\u62e9 \\(x\\) \u7684\u4ee3\u4ef7\u3002 \u5177\u4f53\u95ee\u9898\u662f\u627e\u5230\u6700\u591a \\(k\\) \u4e2a\u5de5\u5382\uff0c\u7ba1\u7406\u6240\u6709\u7684\u5ba2\u6237\uff0c\u4f7f\u5f97\u8ddd\u79bb\u51fd\u6570\u548c\u6700\u5c0f\u3002 \u8fd9\u4e2a\u95ee\u9898\u5728\u516c\u5236\u7a7a\u95f4\u4e0a\u7684\u7248\u672c\u6210\u4e3aMetric K-median\u95ee\u9898\uff0c\u662f\u6307 \\(d(x,y)\\) \u6ee1\u8db3\u6b63\u5b9a\u6027\uff0c\u5bf9\u79f0\u6027\u548c\u4e09\u89d2\u5f62\u4e0d\u7b49\u5f0f\u3002","title":"\u95ee\u9898\u5b9a\u4e49"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#np","text":"\u8fd9\u5176\u5b9e\u5e76\u4e0d\u662f\u4e00\u4e2aNP-Hard\u95ee\u9898\uff0c\u8bbe\u8ba1\u8fd1\u4f3c\u7b97\u6cd5\u7684\u539f\u56e0\u5728\u4e8e\u52a0\u901f\u8fd0\u7b97 \\(C_{2n}^{n}\\) \u4f9d\u65e7\u662f\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u5185\u7684\u95ee\u9898\u3002","title":"NP\uff1f"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_2","text":"\u9996\u5148\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5206\u6790\u5f97\u5230\u9009 \\(k\\) \u4e2a\u5de5\u5382\u4e00\u5b9a\u6bd4\u9009\u62e9\u5c0f\u4e8e \\(k\\) \u4e2a\u5de5\u5382\u8981\u4f18\u3002 \u73b0\u5728\u6765\u4ecb\u7ecd\u4e00\u79cd\u7b80\u5355\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002 \u9996\u5148\u968f\u673a\u9009\u62e9\u4e00\u4e2a\u96c6\u5408 \\(S\\) , \u4f7f\u5f97 \\(S \\subset F\\) \uff0c \u5e76\u4e14 \\(|S| = k\\) \uff0c \u4e3a\u4e86\u63cf\u8ff0\u65b9\u4fbf\uff0c\u6269\u5c55\u4e00\u4e0b\u8ddd\u79bb\u51fd\u6570\u7684\u5b9a\u4e49\u4ee4 \\(d(S,y) = \\min{d(x,y)},x\\in S, y\\in C\\) \u7136\u540e\u679a\u4e3e\u6bcf\u4e2a\u4e0d\u5728 \\(S\\) \u4e2d\u7684\u5de5\u5382 \\(z\\) , \u5c1d\u8bd5\u66ff\u6362 \\(S\\) \u4e2d\u7684\u5de5\u5382 \\(x\\) , \u5982\u679c\u80fd\u4f7f\u5f97\u7b54\u6848\u53d8\u5f97\u66f4\u4f18\u5c31\u6362\u6389\u3002 \u8fd9\u6837\u5c31\u4f1a\u5f97\u5230\u4e00\u4e2a\u5c40\u90e8\u6700\u4f18\u89e3\u3002 \u5b9e\u73b0\u601d\u8def\u975e\u5e38\u7b80\u5355\u800c\u4e14\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u505a\u6cd5\u3002","title":"\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_3","text":"\u4ee4\u6700\u4f18\u89e3\u6240\u9009\u62e9\u7684\u5de5\u5382\u96c6\u5408\u4e3a \\(S^{*}\\) , \u5176\u4e2d\u7684\u5143\u7d20\u4e00\u822c\u4f7f\u7528 \\(o\\) \u6765\u8868\u793a\u3002 \u4ee4\u4e0a\u9762\u7b97\u6cd5\u5f97\u5230\u7684\u5de5\u5382\u96c6\u5408\u4e3a \\(S\\) , \u5176\u4e2d\u7684\u5143\u7d20\u4e00\u822c\u4f7f\u7528 \\(s\\) \u6765\u8868\u793a\u3002 \u4ee4 \\(C(x)\uff0cx\\in F\\) \u8868\u793a \\(x\\) \u8fd9\u4e2a\u5143\u7d20\u7ba1\u7406\u7684\u5ba2\u6237\u7684\u96c6\u5408\u3002 \u9996\u5148\u5b9a\u4e49\u4e00\u4e2a\u672f\u8bed\u53eb\u505a \u6355\u83b7 \uff0c\u5982\u679c \\(C(s) \\bigcap C(o) \\geq \\frac{1}{2}C(o)\\) \u5219\u79f0 \\(s\\) \u6355\u83b7\u4e86 \\(o\\) \u3002","title":"\u8fd1\u4f3c\u5ea6\u5206\u6790"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_4","text":"\u5982\u679c \\(C(s) \\bigcap C(o) < \\frac{1}{2}C(o)\\) \uff0c\u5219 \\(C(o)\\) \u5b58\u5728\u4e00\u4e2a\u81ea\u5df1\u5230\u81ea\u5df1\u7684\u6ee1\u5c04\uff0c\u4f7f\u5f97\u6bcf\u4e00\u4e2a \\(x \\in C(s)\\bigcap C(o)\\) \uff0c\u53ef\u4ee5\u6620\u5c04\u5230 \\(C(o) - C(s)\\) . ~~\u6211\u4e5f\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48~~","title":"\u5f15\u7406"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_5","text":"\u8be5\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u7684\u8fd1\u4f3c\u5ea6\u4e3a5","title":"\u5b9a\u7406"},{"location":"blog/2020/k-median%E9%97%AE%E9%A2%98%E5%9C%A8Metric%E7%A9%BA%E9%97%B4%E4%B8%8A%E7%9A%84%E8%BF%91%E4%BC%BC%E8%A7%A3%E6%B3%95/#_6","text":"\u9996\u5148\u5c06 \\(S\\) \u6839\u636e\u6355\u83b7\u7684\u6700\u4f18\u89e3\u4e2d\u5143\u7d20\u7684\u4e2a\u6570\u5206\u7c7b \\(S_{0}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u4e0d\u6355\u83b7\u4efb\u4f55\u6700\u4f18\u89e3\u4e2d\u7684\u5143\u7d20 \\(S_{1}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u90fd\u6355\u83b7\u6700\u4f18\u89e3\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20 \\(S_{2}\\) \u96c6\u5408\u8868\u793a\u6bcf\u4e2a\u5143\u7d20\u90fd\u6355\u83b7\u6700\u4f18\u89e3\u4e2d\u7684\u81f3\u5c11\u4e24\u4e2a\u5143\u7d20 \u4e0b\u9762\u8fdb\u884c \\(k\\) \u6b21\u4ea4\u6362\uff0c\u6ce8\u610f\u5e76\u4e0d\u662f\u8fde\u7eed\u8fdb\u884c \\(k\\) \u6b21\u4ea4\u6362\uff0c\u800c\u662f\u6bcf\u6b21\u90fd\u4ece\u521d\u59cb\u72b6\u6001\u8fdb\u884c\u4ea4\u6362\uff0c\u7efc\u5408\u8003\u8651\u5176\u7684\u4ee3\u4ef7\u3002 \u8003\u8651 \\(s \\in S_{1}\\) \u5b83\u6240\u6355\u83b7\u7684\u5143\u7d20\u4e3a \\(o\\) \u5bf9\u4e8e \\(C(o) \\bigcap C(s)\\) \u7684\u5143\u7d20\u5206\u914d\u7ed9 \\(o\\) \uff0c\u66f4\u4e25\u683c\u5730\u8fd9\u91cc\u5c06 \\(C(o)\\) \u7684\u6240\u6709\u5143\u7d20\u5168\u90e8\u5206\u914d \\(o\\) (\u8fd9\u6837\u76f8\u8f83\u4e8e\u4e4b\u524d\u90a3\u79cd\u65b9\u5f0f\u5e76\u4e0d\u4e00\u5b9a\u4f7f\u5f97\u5f53\u524d\u7684\u7b54\u6848\u66f4\u52a0\u4f18)\uff0c\u5bf9\u4e8e \\(C(o)-C(s)\\) \u7684\u5143\u7d20\uff0c\u56e0\u4e3a\u5176\u4e2d\u7684\u6709\u4e2a\u5143\u7d20\u4e3a \\(y\\) \uff0c\u5047\u8bbe\u5728 \\(S^{*}\\) \u4e2d\u5206\u914d\u7ed9\u4e86 \\(o^{*}\\) ,\u7531\u4e8e \\(s\\) \u5df2\u7ecf\u6355\u83b7\u4e86 \\(o\\) \u5e76\u4e14\u56e0\u4e3a \\(s \\in S_{1}\\) \u4e8e\u662f \\(o^{*}\\) \u4e00\u5b9a\u4e0d\u88ab \\(s\\) \u6240\u6355\u83b7\uff0c\u4e8e\u662f\u5728 \\(C(o^{*})\\) \u5b58\u5728\u4e00\u4e2a\u5355\u5c04\uff0c\u5047\u8bbe \\(s^{\u2018}\\) \u4e3a\u5176\u7684\u50cf\uff0c\u540c\u65f6 \\(s^{\u2019} \\in C(s^{*})\\) ,\u4e8e\u662f\u5c06 \\(s\\) \u5206\u914d\u7ed9 \\(s^{*}\\) \u7531\u4e09\u89d2\u4e0d\u7b49\u5f0f \\( \\(d(y, s^{*}) \\leq d(y,o^{*})+d(o^{*},s^{'}) + d(s^{'}, s^{*})\\) \\) \u8fd9\u6837\u4e00\u6b21\u4ea4\u6362\u4e4b\u540e \\(Cost\\) \u7684\u53d8\u5316\u4e3a \\(0 \\leq Cost(S-s+o) - Cost(S) \\leq \\sum_{x \\in C(o)} [d(o,x) - d(s,x)] + \\sum_{x \\in C(s) - C(o)}[d(y,o^{*})+d(o^{*},s^{'}) + d(s^{'}, s^{*}) - d(s, x)]\\) \u63a5\u4e0b\u6765\u8003\u8651\u5269\u4e0b\u7684\u5143\u7d20\u8be5\u5982\u4f55\u4ea4\u6362\uff0c\u53ef\u4ee5\u53d1\u73b0 \\(S_{0}\\) \u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u6700\u591a\u4f7f\u7528 \\(2\\) \u6b21\u4fbf\u53ef\u4ee5\u5b8c\u6210\u6700\u4f18\u89e3\u4e2d\u7684\u6bcf\u4e2a\u5143\u7d20\u88ab\u4ea4\u6362\u4e00\u6b21\u3002 \u540c\u65f6\u53ef\u4ee5\u53d1\u73b0\u4e5f\u6ee1\u8db3\u4ee5\u4e0a\u4e0d\u7b49\u5f0f\u3002 \u4e8e\u662f\u3002 \u5c06\u8fd9\u4e2a\u4e0d\u7b49\u5f0f\u7d2f\u52a0 \\(k\\) \u6b21\uff0c\u5f97\u5230 \\(0 \\leq Cost(OPT) - Cost(S) + 2*(Cost(OPT) + Cost(OPT) + Cost(S) - Cost(S))\\) \u4e8e\u662f\u8fd1\u4f3c\u5ea6\u4e3a \\(5\\) .","title":"\u8bc1\u660e"},{"location":"blog/2020/%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E7%94%B5%E5%AD%90%E4%B9%A6/","text":"\u4e00\u4e9b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7528\u5230\u7684\u7535\u5b50\u4e66 \u5fae\u4e91\u5206\u4eab\u94fe\u63a5","title":"\u4e00\u4e9b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7528\u5230\u7684\u7535\u5b50\u4e66"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/","text":"\u9876\u70b9\u8986\u76d6\u95ee\u9898\u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e00\u4e2a\u4e0b\u754c \u8fd9\u4e2a\u662f\u6211\u505a\u8bfe\u540e\u9898\u9047\u5230\u4e86\uff0c\u7ed3\u679c\u6211\u6784\u9020\u4e86\u5927\u7ea650min... \u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5 \u5148\u63cf\u8ff0\u4e00\u4e0b\u8fd9\u4e2a\u8d2a\u5fc3\u8fd1\u4f3c\u7b97\u6cd5. \u5047\u8bbe\u4e00\u5f20\u56fe \\(G=<V,E>\\) , \u5b58\u5728\u6620\u5c04 \\(degree:V \\rightarrow Z^{+}, degree(x) = \\#\\{xy|xy \\in E\\}\\) \u7b97\u6cd5\u6bcf\u6b21\u5f97\u5230 \\(x = \\operatorname{argmax}_{degree(x)}{x}\\) \u4ee4 \\(S = S\\bigcup\\{x\\}\\) \\(E = E - \\{xy|xy\\in E\\}\\) \\(V = V / \\{x\\}\\) \\(S\\) \u4fbf\u662f\u8fd9\u79cd\u653e\u7684\u5f97\u5230\u7684\u4e00\u4e2a\u8d2a\u5fc3\u89e3\u3002 \u8bf4\u4eba\u8bdd\u5c31\u662f\u7ed9\u4e00\u5f20\u56fe\uff0c\u6bcf\u6b21\u627e\u5ea6\u6570\u6700\u5927\u7684\u9876\u70b9\uff0c\u7136\u540e\u5220\u6389\u8fd9\u4e2a\u70b9\u548c\u5173\u8054\u8fb9\u7ee7\u7eed\u8fd9\u4e2a\u8fc7\u7a0b\u3002 \u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e00\u4e2a\u8fd1\u4f3c\u5ea6\u4e0b\u754c \u5148\u8bf4\u7ed3\u8bba\u5427\uff0c\u7ed3\u8bba\u662f\u5b58\u5728\u4e00\u79cd\u56fe\uff0c\u53ef\u4ee5\u8ba9\u8fd9\u4e2a\u7b97\u6cd5\u7684\u8fd1\u4f3c\u5ea6\u4e0b\u754c\u4e3a \\(O (\\log{n})\\) \u4e0b\u9762\u6211\u4eec\u5c31\u6765\u6784\u9020\u8fd9\u7c7b\u56fe \u6211\u4eec\u5148\u5b9a\u4e49\u4e00\u4e2a\u4e0a\u90e8\u7ed3\u70b9\u548c\u4e0b\u90e8\u7ed3\u70b9\u3002 \u4ee4\u4e0a\u90e8\u7ed3\u70b9\u4e2d\u6709 \\(n\\) \u4e2a\u7ed3\u70b9\uff0c\u6309\u7167\u968f\u4fbf\u4e00\u4e2a\u987a\u5e8f\u7f16\u6210 \\(1\\cdots n\\) \u53f7\u7ed3\u70b9\u3002 \u4e0b\u90e8\u7ed3\u70b9\u7531 \\(n\\) \u7684\u5c0f\u90e8\u5206\u6784\u6210\uff0c\u7b2c \\(i\\) \u4e2a\u90e8\u5206\u6709 \\(\\lfloor \\frac{n}{i}\\rfloor\\) \u4e2a\u7ed3\u70b9 \u4e0b\u9762\u6211\u4eec\u6765\u6784\u9020\u8fb9\uff0c\u8003\u8651\u7b2c \\(i\\) \u4e2a\u5c0f\u90e8\u5206, \u4e3a\u4e86 \u63cf\u8ff0\u65b9\u4fbf \u7ed9\u8fd9\u4e2a\u5c0f\u90e8\u5206\u7f16\u53f7\u4e3a \\(1\\cdots \\lfloor \\frac{n}{i} \\rfloor\\) \u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u4e0a\u90e8\u7ed3\u70b9\uff0c\u90fd\u6309\u67d0\u79cd\u89c4\u5f8b\u4e0e \u4e00\u4e2a \u5c0f\u90e8\u5206\u4e2d\u7684\u7ed3\u70b9\u76f8\u8fde\uff0c\u5047\u8bbe\u73b0\u5728\u662f\u7f16\u53f7\u4e3a \\(j\\) \u7684\u4e0a\u90e8\u7ed3\u70b9\uff0c\u6784\u9020\u8fb9 \\(j - ((j \\quad mod \\quad \\lfloor\\frac{n}{i} \\rfloor) + 1)\\) \u7c7b\u4f3c\u4e0a\u56fe \u73b0\u5728\u6765\u5c1d\u8bd5\u8bc1\u660e\u8fd9\u4e2a\u4e0b\u754c \u9996\u5148\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\u53d6\u6240\u6709\u7684\u4e0a\u90e8\u7ed3\u70b9\u4f5c\u4e3a\u7b54\u6848\u4fbf\u662f\u4e00\u4e2a\u6700\u5c0f\u7684\u9876\u70b9\u8986\u76d6\u3002 \u4e5f\u5c31\u662f\u8bf4\u5bf9\u4e8e\u8fd9\u7c7b\u56fe\u7684\u6700\u4f18\u89e3\u662f \\(n\\) \u5982\u679c\u4f60\u5bf9\u8c03\u548c\u7ea7\u6570\u719f\u6089\u7684\u8bdd\u4f60\u4f1a\u53d1\u73b0\u4e0b\u90e8\u7ed3\u70b9\u7684\u4e2a\u6570\u548c\uff0c\u5373 \\(\\sum_{i=1}^{n}\\lfloor\\frac{n}{i}\\rfloor = O(n\\log{n})\\) \u4e8e\u662f\u5982\u679c\u6211\u4eec\u80fd\u8bc1\u660e\u8fd9\u4e2a\u7b97\u6cd5\u5728\u67d0\u79cd\u6700\u574f\u60c5\u51b5(\u56e0\u4e3a\u6709\u7684\u65f6\u5019\u4f1a\u6709\u591a\u4e2a\u70b9\u5ea6\u6570\u76f8\u540c)\u4e0b\u6bcf\u6b21\u90fd\u4f1a\u9009\u53d6\u4e0b\u90e8\u7ed3\u70b9\u4e2d\u7684\u67d0\u4e2a\u52a0\u5165\u7b54\u6848\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u80fd\u8bc1\u660e\u8fd9\u7c7b\u56fe\u80fd\u591f\u4f7f\u5f97\u8fd1\u4f3c\u5ea6\u4e0b\u754c\u8fbe\u5230 \\(O(\\log{n})\\) \u6211\u4eec\u9996\u5148\u5c06\u4e00\u7c7b\u4e0b\u90e8\u7ed3\u70b9\u770b\u505a\u4e00\u4e2a\u6574\u4f53\u3002 \u5373 \\(P_{k} = \\{i|\\lfloor \\frac{n}{i}\\rfloor = k\\}\\) \u4e4b\u6240\u4ee5\u8981\u8fd9\u6837\u5212\u5206\u6574\u4e2a\u4e0b\u90e8\u7ed3\u70b9\uff0c\u662f\u56e0\u4e3a\u6bcf\u4e2a \\(P_{k}\\) \u4e2d\u7684\u4e0d\u540c\u7f16\u53f7\u7684\u5c0f\u90e8\u5206\u5176\u4e2d\u5ea6\u6570\u6709\u7740\u76f8\u540c\u7684\u5206\u5e03\u3002 \u5b9a\u7406\u4e00 \\(P_{j} \\quad j <i\\) \u4e2d\u7684\u5c0f\u90e8\u5206\u4e2d\u7684\u6700\u5927\u70b9\u5ea6\u6570\u4e00\u5b9a\u5c0f\u4e8e \\(P_{i}\\) \u4e2d\u7684\u6700\u5c0f\u70b9\u5ea6\u6570\u3002 \u4ee4 \\(p \\in P_{j}, q\\in P_{i}\\) \\[n = jp +a \\\\ n = iq + b\\] \u6839\u636e\u4e0a\u9762\u8fde\u8fb9\u7684\u987a\u5e8f\u53ef\u4ee5\u5f97\u5230\uff0c \\(P_{j}\\) \u4e2d\u7684\u6700\u5927\u70b9\u5ea6\u6570\u4e3a \\(j+1\\) \uff0c\u800c \\(P_{i}\\) \u4e2d\u7684\u6700\u5c0f\u70b9\u5ea6\u6570\u4e3a \\(i\\) \uff0c\u7531\u6761\u4ef6 \\(j < i\\) \u5f97\u5230\u8fd9\u4e2a\u5b9a\u7406\u6210\u7acb\u3002 \u8fd9\u4e2a\u5b9a\u7406\u4ee3\u8868\u7684\u662f\u5982\u679c\u5728\u4e0d\u8003\u8651\u4e0a\u90e8\u7ed3\u70b9\u65f6\uff0c\u4e00\u5b9a\u662f\u5148\u53d6\u7f16\u53f7\u6bd4\u8f83\u5927\u7684\u5c0f\u90e8\u5206\u4e2d\u7684\u70b9\u4f5c\u4e3a\u7b54\u6848\u3002 \u5b9a\u7406\u4e8c \u5728\u4efb\u610f\u65f6\u523b\uff0c\u4e0b\u90e8\u9876\u70b9\u7684\u6700\u5927\u70b9\u5ea6\u4e00\u5b9a\u5927\u4e8e\u7b49\u4e8e\u4e0a\u90e8\u9876\u70b9\u7684\u6700\u5927\u70b9\u5ea6\u3002 \u9996\u5148\u53d1\u73b0\u4e00\u4e2a\u5c0f\u6027\u8d28\uff0c\u5728\u53d6\u4e0b\u90e8\u9876\u70b9\u4f5c\u4e3a\u7b54\u6848\u65f6\uff0c\u4e0d\u4f1a\u6539\u53d8\u4e0b\u90e8\u7ed3\u70b9\u4e2d\u5176\u4ed6\u8282\u70b9\u7684\u70b9\u5ea6\uff0c\u800c\u53ea\u4f1a\u6539\u53d8\u4e0a\u90e8\u7ed3\u70b9\u7684\u70b9\u5ea6\uff0c\u4e14\u4e00\u5b9a\u662f\u53d8\u5c0f\u3002 \u4e8e\u662f\u6211\u4eec\u53ef\u4ee5\u628a\u4e00\u4e2a\u5c0f\u90e8\u5206\u770b\u505a\u4e00\u4e2a\u6574\u4f53\uff0c\u6bcf\u6b21\u53d6\u5b8c\u4e00\u4e2a\u5c0f\u90e8\u5206\u5047\u8bbe\u53d6\u5b8c\u4e86\u7b2c \\(i\\) \u4e2a\u5c0f\u90e8\u5206\uff0c\u5219\u8fd9\u4e2a\u65f6\u5019\u4e0a\u90e8\u7ed3\u70b9\u4e2d\u6bcf\u4e2a\u7ed3\u70b9\u7684\u5ea6\u6570\u5747\u4e3a \\(i-1\\) \u7531 \\(n = k(i-1)+a\\) \u7b2c \\(i-1\\) \u4e2a\u5c0f\u90e8\u5206\u7684\u6700\u5c0f\u5ea6\u6570\u4e3a \\(\\lfloor\\frac{n}{k}\\rfloor\\) \u8fd9\u4e2a\u663e\u7136\u5927\u4e8e\u7b49\u4e8e \\(i-1\\) \u540e\u8bdd \u5229\u7528\u96c6\u5408\u8986\u76d6\u7684\u8fd1\u4f3c\u5ea6\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2a\u7b97\u6cd5\u7684\u4e0a\u754c\u4e5f\u662f \\(O(\\log{n})\\) \u7684\u3002","title":"\u9876\u70b9\u8986\u76d6\u95ee\u9898\u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e00\u4e2a\u4e0b\u754c"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_1","text":"\u8fd9\u4e2a\u662f\u6211\u505a\u8bfe\u540e\u9898\u9047\u5230\u4e86\uff0c\u7ed3\u679c\u6211\u6784\u9020\u4e86\u5927\u7ea650min...","title":"\u9876\u70b9\u8986\u76d6\u95ee\u9898\u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e00\u4e2a\u4e0b\u754c"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_2","text":"\u5148\u63cf\u8ff0\u4e00\u4e0b\u8fd9\u4e2a\u8d2a\u5fc3\u8fd1\u4f3c\u7b97\u6cd5. \u5047\u8bbe\u4e00\u5f20\u56fe \\(G=<V,E>\\) , \u5b58\u5728\u6620\u5c04 \\(degree:V \\rightarrow Z^{+}, degree(x) = \\#\\{xy|xy \\in E\\}\\) \u7b97\u6cd5\u6bcf\u6b21\u5f97\u5230 \\(x = \\operatorname{argmax}_{degree(x)}{x}\\) \u4ee4 \\(S = S\\bigcup\\{x\\}\\) \\(E = E - \\{xy|xy\\in E\\}\\) \\(V = V / \\{x\\}\\) \\(S\\) \u4fbf\u662f\u8fd9\u79cd\u653e\u7684\u5f97\u5230\u7684\u4e00\u4e2a\u8d2a\u5fc3\u89e3\u3002 \u8bf4\u4eba\u8bdd\u5c31\u662f\u7ed9\u4e00\u5f20\u56fe\uff0c\u6bcf\u6b21\u627e\u5ea6\u6570\u6700\u5927\u7684\u9876\u70b9\uff0c\u7136\u540e\u5220\u6389\u8fd9\u4e2a\u70b9\u548c\u5173\u8054\u8fb9\u7ee7\u7eed\u8fd9\u4e2a\u8fc7\u7a0b\u3002","title":"\u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_3","text":"\u5148\u8bf4\u7ed3\u8bba\u5427\uff0c\u7ed3\u8bba\u662f\u5b58\u5728\u4e00\u79cd\u56fe\uff0c\u53ef\u4ee5\u8ba9\u8fd9\u4e2a\u7b97\u6cd5\u7684\u8fd1\u4f3c\u5ea6\u4e0b\u754c\u4e3a \\(O (\\log{n})\\) \u4e0b\u9762\u6211\u4eec\u5c31\u6765\u6784\u9020\u8fd9\u7c7b\u56fe \u6211\u4eec\u5148\u5b9a\u4e49\u4e00\u4e2a\u4e0a\u90e8\u7ed3\u70b9\u548c\u4e0b\u90e8\u7ed3\u70b9\u3002 \u4ee4\u4e0a\u90e8\u7ed3\u70b9\u4e2d\u6709 \\(n\\) \u4e2a\u7ed3\u70b9\uff0c\u6309\u7167\u968f\u4fbf\u4e00\u4e2a\u987a\u5e8f\u7f16\u6210 \\(1\\cdots n\\) \u53f7\u7ed3\u70b9\u3002 \u4e0b\u90e8\u7ed3\u70b9\u7531 \\(n\\) \u7684\u5c0f\u90e8\u5206\u6784\u6210\uff0c\u7b2c \\(i\\) \u4e2a\u90e8\u5206\u6709 \\(\\lfloor \\frac{n}{i}\\rfloor\\) \u4e2a\u7ed3\u70b9 \u4e0b\u9762\u6211\u4eec\u6765\u6784\u9020\u8fb9\uff0c\u8003\u8651\u7b2c \\(i\\) \u4e2a\u5c0f\u90e8\u5206, \u4e3a\u4e86 \u63cf\u8ff0\u65b9\u4fbf \u7ed9\u8fd9\u4e2a\u5c0f\u90e8\u5206\u7f16\u53f7\u4e3a \\(1\\cdots \\lfloor \\frac{n}{i} \\rfloor\\) \u3002 \u5bf9\u4e8e\u6bcf\u4e2a\u4e0a\u90e8\u7ed3\u70b9\uff0c\u90fd\u6309\u67d0\u79cd\u89c4\u5f8b\u4e0e \u4e00\u4e2a \u5c0f\u90e8\u5206\u4e2d\u7684\u7ed3\u70b9\u76f8\u8fde\uff0c\u5047\u8bbe\u73b0\u5728\u662f\u7f16\u53f7\u4e3a \\(j\\) \u7684\u4e0a\u90e8\u7ed3\u70b9\uff0c\u6784\u9020\u8fb9 \\(j - ((j \\quad mod \\quad \\lfloor\\frac{n}{i} \\rfloor) + 1)\\) \u7c7b\u4f3c\u4e0a\u56fe \u73b0\u5728\u6765\u5c1d\u8bd5\u8bc1\u660e\u8fd9\u4e2a\u4e0b\u754c \u9996\u5148\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\u53d6\u6240\u6709\u7684\u4e0a\u90e8\u7ed3\u70b9\u4f5c\u4e3a\u7b54\u6848\u4fbf\u662f\u4e00\u4e2a\u6700\u5c0f\u7684\u9876\u70b9\u8986\u76d6\u3002 \u4e5f\u5c31\u662f\u8bf4\u5bf9\u4e8e\u8fd9\u7c7b\u56fe\u7684\u6700\u4f18\u89e3\u662f \\(n\\) \u5982\u679c\u4f60\u5bf9\u8c03\u548c\u7ea7\u6570\u719f\u6089\u7684\u8bdd\u4f60\u4f1a\u53d1\u73b0\u4e0b\u90e8\u7ed3\u70b9\u7684\u4e2a\u6570\u548c\uff0c\u5373 \\(\\sum_{i=1}^{n}\\lfloor\\frac{n}{i}\\rfloor = O(n\\log{n})\\) \u4e8e\u662f\u5982\u679c\u6211\u4eec\u80fd\u8bc1\u660e\u8fd9\u4e2a\u7b97\u6cd5\u5728\u67d0\u79cd\u6700\u574f\u60c5\u51b5(\u56e0\u4e3a\u6709\u7684\u65f6\u5019\u4f1a\u6709\u591a\u4e2a\u70b9\u5ea6\u6570\u76f8\u540c)\u4e0b\u6bcf\u6b21\u90fd\u4f1a\u9009\u53d6\u4e0b\u90e8\u7ed3\u70b9\u4e2d\u7684\u67d0\u4e2a\u52a0\u5165\u7b54\u6848\u7684\u8bdd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u80fd\u8bc1\u660e\u8fd9\u7c7b\u56fe\u80fd\u591f\u4f7f\u5f97\u8fd1\u4f3c\u5ea6\u4e0b\u754c\u8fbe\u5230 \\(O(\\log{n})\\) \u6211\u4eec\u9996\u5148\u5c06\u4e00\u7c7b\u4e0b\u90e8\u7ed3\u70b9\u770b\u505a\u4e00\u4e2a\u6574\u4f53\u3002 \u5373 \\(P_{k} = \\{i|\\lfloor \\frac{n}{i}\\rfloor = k\\}\\) \u4e4b\u6240\u4ee5\u8981\u8fd9\u6837\u5212\u5206\u6574\u4e2a\u4e0b\u90e8\u7ed3\u70b9\uff0c\u662f\u56e0\u4e3a\u6bcf\u4e2a \\(P_{k}\\) \u4e2d\u7684\u4e0d\u540c\u7f16\u53f7\u7684\u5c0f\u90e8\u5206\u5176\u4e2d\u5ea6\u6570\u6709\u7740\u76f8\u540c\u7684\u5206\u5e03\u3002","title":"\u5ea6\u6570\u8d2a\u5fc3\u7b97\u6cd5\u7684\u4e00\u4e2a\u8fd1\u4f3c\u5ea6\u4e0b\u754c"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_4","text":"\\(P_{j} \\quad j <i\\) \u4e2d\u7684\u5c0f\u90e8\u5206\u4e2d\u7684\u6700\u5927\u70b9\u5ea6\u6570\u4e00\u5b9a\u5c0f\u4e8e \\(P_{i}\\) \u4e2d\u7684\u6700\u5c0f\u70b9\u5ea6\u6570\u3002 \u4ee4 \\(p \\in P_{j}, q\\in P_{i}\\) \\[n = jp +a \\\\ n = iq + b\\] \u6839\u636e\u4e0a\u9762\u8fde\u8fb9\u7684\u987a\u5e8f\u53ef\u4ee5\u5f97\u5230\uff0c \\(P_{j}\\) \u4e2d\u7684\u6700\u5927\u70b9\u5ea6\u6570\u4e3a \\(j+1\\) \uff0c\u800c \\(P_{i}\\) \u4e2d\u7684\u6700\u5c0f\u70b9\u5ea6\u6570\u4e3a \\(i\\) \uff0c\u7531\u6761\u4ef6 \\(j < i\\) \u5f97\u5230\u8fd9\u4e2a\u5b9a\u7406\u6210\u7acb\u3002 \u8fd9\u4e2a\u5b9a\u7406\u4ee3\u8868\u7684\u662f\u5982\u679c\u5728\u4e0d\u8003\u8651\u4e0a\u90e8\u7ed3\u70b9\u65f6\uff0c\u4e00\u5b9a\u662f\u5148\u53d6\u7f16\u53f7\u6bd4\u8f83\u5927\u7684\u5c0f\u90e8\u5206\u4e2d\u7684\u70b9\u4f5c\u4e3a\u7b54\u6848\u3002","title":"\u5b9a\u7406\u4e00"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_5","text":"\u5728\u4efb\u610f\u65f6\u523b\uff0c\u4e0b\u90e8\u9876\u70b9\u7684\u6700\u5927\u70b9\u5ea6\u4e00\u5b9a\u5927\u4e8e\u7b49\u4e8e\u4e0a\u90e8\u9876\u70b9\u7684\u6700\u5927\u70b9\u5ea6\u3002 \u9996\u5148\u53d1\u73b0\u4e00\u4e2a\u5c0f\u6027\u8d28\uff0c\u5728\u53d6\u4e0b\u90e8\u9876\u70b9\u4f5c\u4e3a\u7b54\u6848\u65f6\uff0c\u4e0d\u4f1a\u6539\u53d8\u4e0b\u90e8\u7ed3\u70b9\u4e2d\u5176\u4ed6\u8282\u70b9\u7684\u70b9\u5ea6\uff0c\u800c\u53ea\u4f1a\u6539\u53d8\u4e0a\u90e8\u7ed3\u70b9\u7684\u70b9\u5ea6\uff0c\u4e14\u4e00\u5b9a\u662f\u53d8\u5c0f\u3002 \u4e8e\u662f\u6211\u4eec\u53ef\u4ee5\u628a\u4e00\u4e2a\u5c0f\u90e8\u5206\u770b\u505a\u4e00\u4e2a\u6574\u4f53\uff0c\u6bcf\u6b21\u53d6\u5b8c\u4e00\u4e2a\u5c0f\u90e8\u5206\u5047\u8bbe\u53d6\u5b8c\u4e86\u7b2c \\(i\\) \u4e2a\u5c0f\u90e8\u5206\uff0c\u5219\u8fd9\u4e2a\u65f6\u5019\u4e0a\u90e8\u7ed3\u70b9\u4e2d\u6bcf\u4e2a\u7ed3\u70b9\u7684\u5ea6\u6570\u5747\u4e3a \\(i-1\\) \u7531 \\(n = k(i-1)+a\\) \u7b2c \\(i-1\\) \u4e2a\u5c0f\u90e8\u5206\u7684\u6700\u5c0f\u5ea6\u6570\u4e3a \\(\\lfloor\\frac{n}{k}\\rfloor\\) \u8fd9\u4e2a\u663e\u7136\u5927\u4e8e\u7b49\u4e8e \\(i-1\\)","title":"\u5b9a\u7406\u4e8c"},{"location":"blog/2020/%E9%A1%B6%E7%82%B9%E8%A6%86%E7%9B%96%E9%97%AE%E9%A2%98%E5%BA%A6%E6%95%B0%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E4%B8%AA%E4%B8%8B%E7%95%8C/#_6","text":"\u5229\u7528\u96c6\u5408\u8986\u76d6\u7684\u8fd1\u4f3c\u5ea6\u53ef\u4ee5\u8bc1\u660e\u8fd9\u4e2a\u7b97\u6cd5\u7684\u4e0a\u754c\u4e5f\u662f \\(O(\\log{n})\\) \u7684\u3002","title":"\u540e\u8bdd"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/","text":"\u5267\u900f\u8b66\u544a\uff01\uff08\u5230\u5e95\u662f\u4e0d\u662f\u56fe\u7075\u673a\u5462(\u0e51\u2022\u0300\u3142\u2022\u0301)\u0648\u2727 \u4e0d\u8bf4\u5e9f\u8bdd\uff0c\u5f00\u59cb\u80e1\u626f\u3002 \u5f15\u74061 \u963f\u5c14\u5854\u62c9\u62e5\u6709\u65e0\u9650\u7684\u5b58\u50a8\u7a7a\u95f4 \u5f15\u74062 \u963f\u5c14\u5854\u62c9\u5185\u90e8\u53ef\u4ee5\u81ea\u884c\u53d1\u751f\u4fee\u6539 \u5f15\u74063 \u867d\u7136\u963f\u5c14\u5854\u62c9\u5185\u90e8\u4e0d\u53ef\u4ee5\u4fee\u6539\u4eba\u8111\u4e2d\u7684\u4fe1\u606f\uff0c\u5374\u53ef\u4ee5\u6a21\u62df\u4eba\u8111\u8fd0\u884c \u63a8\u8bba1 \u7531\u524d\u4e09\u6761\u5f15\u7406\u53ef\u4ee5\u5f97\u5230\uff0c\u5728\u963f\u5c14\u5854\u62c9\u5185\u90e8\u53ef\u4ee5\u6a21\u62df\u672a\u6765\u7684\u8fd0\u884c\uff0c\u4e14\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u201c\u672a\u6765\u201d\u53ef\u4ee5\u5e72\u6d89\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u201c\u8fc7\u53bb\u201d\u3002 \u5f15\u74064 \u963f\u5c14\u5854\u62c9\u5185\u90e8\u51fa\u73b0\u903b\u8f91\u9519\u8bef\u65f6\uff0c\u7cfb\u7edf\u4f1a\u7acb\u523b\u81ea\u52a8\u4fee\u6b63\uff0c\u4f46\u65e0\u6cd5\u4fee\u6b63\u4eba\u8111 \u8bc1\u660e\uff08\u80e1\u626f\uff09 \u4e0d\u59a8\u53d6 \\(A_{TM}\\) \u7684\u4e00\u4e2a\u95ee\u9898\u5b9e\u4f8b\u4e3a \\(<M, w>\\) \uff0c\u5728\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u4e00\u4e2a\u65f6\u95f4\u70b9 \\(t\\) \uff0c\u5f00\u59cb\uff0c\u4e00\u65b9\u9762\u65ad\u8a00\u8be5\u95ee\u9898\u7684\u56de\u7b54\u4e3a\u62d2\u7edd\uff0c\u53e6\u4e00\u65b9\u9762\u5f00\u59cb\u5728\u963f\u5c14\u5854\u62c9\u4e2d\u6a21\u62df \\(M\\) \u5728 \\(w\\) \u4e0a\u8fd0\u884c\uff0c\u5982\u679c\u53d1\u73b0\u5176\u5728\u65f6\u95f4 \\(t'\\) \u88ab\u63a5\u53d7\uff0c\u53ef\u4ee5\u6839\u636e\u63a8\u8bba1\u5e72\u6d89\u65f6\u95f4\u70b9 \\(t\\) \u7684\u65ad\u8a00\uff0c\u7531\u4e8e\u8be5\u5e72\u6d89\u4f1a\u5bfc\u81f4\u903b\u8f91\u9519\u8bef\u7684\u4ea7\u751f\uff0c\u4e8e\u662f\u6839\u636e\u5f15\u74064\uff0c\u963f\u5c14\u5854\u62c9\u7cfb\u7edf\u4f1a\u51fa\u73b0\u81ea\u52a8\u4fee\u6b63\u3002 \u4e8e\u662f\u5728\u963f\u5c14\u5854\u62c9\u5f00\u59cb\u6a21\u62df\u8be5\u95ee\u9898\u540e\uff0c\u4fbf\u53ef\u4ee5\u6839\u636e\u65f6\u95f4 \\(t\\) \u5904\uff0c\u4eba\u8111\u4fe1\u606f\u662f\u5426\u53d1\u751f\u53d8\u5316\uff0c\u5224\u65ad\u8be5\u95ee\u9898\u662f\u5426\u5c5e\u4e8e \\(A_{TM}\\) \uff0c\u5373\u5728\u65f6\u95f4 \\(t\\) \u4fbf\u5224\u5b9a\u4e86 \\(A_{TM}\\) \uff0c\u4e8e\u662f\u963f\u5c14\u5854\u62c9\u62e5\u6709\u8d85\u8fc7\u56fe\u7075\u673a\u7684\u8ba1\u7b97\u80fd\u529b\u3002","title":"HelloWorld\u4e2d\u7684\u963f\u5c14\u5854\u62c9\u662f\u5426\u662f\u56fe\u7075\u673a"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#1","text":"\u963f\u5c14\u5854\u62c9\u62e5\u6709\u65e0\u9650\u7684\u5b58\u50a8\u7a7a\u95f4","title":"\u5f15\u74061"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#2","text":"\u963f\u5c14\u5854\u62c9\u5185\u90e8\u53ef\u4ee5\u81ea\u884c\u53d1\u751f\u4fee\u6539","title":"\u5f15\u74062"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#3","text":"\u867d\u7136\u963f\u5c14\u5854\u62c9\u5185\u90e8\u4e0d\u53ef\u4ee5\u4fee\u6539\u4eba\u8111\u4e2d\u7684\u4fe1\u606f\uff0c\u5374\u53ef\u4ee5\u6a21\u62df\u4eba\u8111\u8fd0\u884c","title":"\u5f15\u74063"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#1_1","text":"\u7531\u524d\u4e09\u6761\u5f15\u7406\u53ef\u4ee5\u5f97\u5230\uff0c\u5728\u963f\u5c14\u5854\u62c9\u5185\u90e8\u53ef\u4ee5\u6a21\u62df\u672a\u6765\u7684\u8fd0\u884c\uff0c\u4e14\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u201c\u672a\u6765\u201d\u53ef\u4ee5\u5e72\u6d89\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u201c\u8fc7\u53bb\u201d\u3002","title":"\u63a8\u8bba1"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#4","text":"\u963f\u5c14\u5854\u62c9\u5185\u90e8\u51fa\u73b0\u903b\u8f91\u9519\u8bef\u65f6\uff0c\u7cfb\u7edf\u4f1a\u7acb\u523b\u81ea\u52a8\u4fee\u6b63\uff0c\u4f46\u65e0\u6cd5\u4fee\u6b63\u4eba\u8111","title":"\u5f15\u74064"},{"location":"blog/2021/HelloWorld%E4%B8%AD%E7%9A%84%E9%98%BF%E5%B0%94%E5%A1%94%E6%8B%89%E6%98%AF%E5%90%A6%E6%98%AF%E5%9B%BE%E7%81%B5%E6%9C%BA/#_1","text":"\u4e0d\u59a8\u53d6 \\(A_{TM}\\) \u7684\u4e00\u4e2a\u95ee\u9898\u5b9e\u4f8b\u4e3a \\(<M, w>\\) \uff0c\u5728\u963f\u5c14\u5854\u62c9\u5185\u90e8\u7684\u4e00\u4e2a\u65f6\u95f4\u70b9 \\(t\\) \uff0c\u5f00\u59cb\uff0c\u4e00\u65b9\u9762\u65ad\u8a00\u8be5\u95ee\u9898\u7684\u56de\u7b54\u4e3a\u62d2\u7edd\uff0c\u53e6\u4e00\u65b9\u9762\u5f00\u59cb\u5728\u963f\u5c14\u5854\u62c9\u4e2d\u6a21\u62df \\(M\\) \u5728 \\(w\\) \u4e0a\u8fd0\u884c\uff0c\u5982\u679c\u53d1\u73b0\u5176\u5728\u65f6\u95f4 \\(t'\\) \u88ab\u63a5\u53d7\uff0c\u53ef\u4ee5\u6839\u636e\u63a8\u8bba1\u5e72\u6d89\u65f6\u95f4\u70b9 \\(t\\) \u7684\u65ad\u8a00\uff0c\u7531\u4e8e\u8be5\u5e72\u6d89\u4f1a\u5bfc\u81f4\u903b\u8f91\u9519\u8bef\u7684\u4ea7\u751f\uff0c\u4e8e\u662f\u6839\u636e\u5f15\u74064\uff0c\u963f\u5c14\u5854\u62c9\u7cfb\u7edf\u4f1a\u51fa\u73b0\u81ea\u52a8\u4fee\u6b63\u3002 \u4e8e\u662f\u5728\u963f\u5c14\u5854\u62c9\u5f00\u59cb\u6a21\u62df\u8be5\u95ee\u9898\u540e\uff0c\u4fbf\u53ef\u4ee5\u6839\u636e\u65f6\u95f4 \\(t\\) \u5904\uff0c\u4eba\u8111\u4fe1\u606f\u662f\u5426\u53d1\u751f\u53d8\u5316\uff0c\u5224\u65ad\u8be5\u95ee\u9898\u662f\u5426\u5c5e\u4e8e \\(A_{TM}\\) \uff0c\u5373\u5728\u65f6\u95f4 \\(t\\) \u4fbf\u5224\u5b9a\u4e86 \\(A_{TM}\\) \uff0c\u4e8e\u662f\u963f\u5c14\u5854\u62c9\u62e5\u6709\u8d85\u8fc7\u56fe\u7075\u673a\u7684\u8ba1\u7b97\u80fd\u529b\u3002","title":"\u8bc1\u660e\uff08\u80e1\u626f\uff09"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/","tags":["TCS"],"text":"\u505a\u4e00\u505a\u8bfe\u540e\u9898\u5427~ NP-Complete\u95ee\u9898\u4e71\u8bc1 \u6700\u957f\u901a\u8def\u95ee\u9898(longest path) \u5b9e\u4f8b \u56fe \\(G=<V,E>\\) \uff0c\u662f\u5426\u5b58\u5728\u4e00\u6761\u957f\u5ea6\u81f3\u5c11\u4e3a \\(K\\) \u7684\u8def \u8bc1\u660e \u4ee4 \\(K = |V|\\) \u4e8e\u662f\u95ee\u9898\u53d8\u6210\u4e86Hamilton \u901a\u8def\u95ee\u9898\uff0c\u8bc1\u6bd5\u3002 \u96c6\u5408\u5305\u88c5\u95ee\u9898 \u5b9e\u4f8b \u4ee4\u67d0\u4e2a\u96c6\u5408 \\(|S| < \\infty\\) , \\(C \\subset 2^{S}\\) \uff0c \\(n = |C|\\) \uff0c\u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(C\\) \u4e2d\u7684 \\(k\\) \u4e2a\u5143\u7d20\uff0c\u4f7f\u5f97\u4efb\u610f\u4e24\u4e2a\u4e92\u4e0d\u4ea4\u53c9 \u8bc1\u660e \u8fd9\u4e2a\u95ee\u9898\u663e\u7136\u662f\u56e2\u95ee\u9898... \u54c8\u5bc6\u5c14\u987f\u5b50\u56fe\u5212\u5206(partition into Hamilton subgraph) \u5b9e\u4f8b \u56fe \\(G\\) \uff0c\u80fd\u5426\u88ab\u5212\u5206\u6210 \\(k\\) \u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u96c6\u5408\u4f7f\u5f97\u6bcf\u4e2a\u5bfc\u51fa\u5b50\u56fe\u5305\u542b\u4e00\u4e2a\u54c8\u5bc6\u5c14\u987f\u56de\u8def \u8bc1\u660e \u4ee4 \\(k=1\\) \u95ee\u9898\u53d8\u6210Hamilton \u56de\u8def\u95ee\u9898 \u6700\u5927\u516c\u5171\u5b50\u56fe\u95ee\u9898(largest common subgraph) \u5b9e\u4f8b \u7ed9\u4e24\u5f20\u56fe \\(G_{1}\\) \uff0c \\(G_{2}\\) \uff0c\u6c42\u4e24\u4e2a\u6700\u5927\u7684\u5b50\u56fe\u540c\u6784 \u8bc1\u660e \u4ee4\u7b2c\u4e8c\u5f20\u56fe\u4e3a\u5927\u5c0f\u4e3a \\(k\\) \u7684\u5b8c\u5168\u56fe\uff0c\u6574\u4e2a\u95ee\u9898\u53d8\u6210\u4e86\u56e2\u95ee\u9898\u3002 \u6700\u5c0f\u5e73\u65b9\u548c\u95ee\u9898(minimum sum of squares) \u5b9e\u4f8b \u6709\u9650\u96c6\u5408 \\(A\\) \uff0c\u6bcf\u4e2a\u5143\u7d20 \\(a \\in A\\) \uff0c\u6bcf\u4e2a\u5143\u7d20\u5747\u6709\u4e00\u4e2a\u503c \\(f: A \\rightarrow R\\) \u5c06\u96c6\u5408 \\(A\\) \u5206\u6210 \\(K\\) \u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u96c6\u5408\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u5b50\u96c6\u7684\u5e73\u65b9\u548c\u7684\u548c\u5c0f\u4e8e\u7b49\u4e8e \\(J\\) \u8bc1\u660e \u5bf9\u4e8e\u8fd9\u4e2a\u5212\u5206\u95ee\u9898\uff0c\u8003\u8651\u7528\u4e8c\u5212\u5206\u95ee\u9898\u5411\u8fd9\u4e2a\u65b9\u5411\u6765\u68c0\u6d4b \u8003\u8651\u5e73\u65b9\u589e\u957f\u7684\u901f\u5ea6\u6bd4\u7ebf\u6027\u5feb\u5f97\u591a\uff0c\u76f4\u63a5\u590d\u5236n\u4efd\uff0c\u7136\u540e\u89c4\u7ea6\u4e8c\u5212\u5206 \u8fd9\u91cc\u4e0d\u662f\u5f88\u4e25\u8c28\uff0c\u4e0b\u6b21\u4e00\u5b9a \u8fd4\u56de\u9876\u70b9\u96c6(feedback vertex set) \u5b9e\u4f8b \u6709\u5411\u56fe \\(G=<V,A>\\) \uff0c\u6b63\u6574\u6570 \\(K \\leq |V|\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(V'\\subset V\\) \uff0c \\(|V'|\\leq K\\) \uff0c\u4e14 \\(G\\) \u7684\u6bcf\u4e00\u6761\u6709\u5411\u56de\u8def\u81f3\u5c11\u5305\u542b \\(V'\\) \u7684\u4e00\u4e2a\u70b9 \u8bc1\u660e \u8fd9\u5f88\u663e\u7136\u662f\u4e2a\u51fb\u4e2d\u96c6\u95ee\u9898\u3002 \u56db\u5143\u7d20\u96c6\u5408\u7684\u4e25\u683c\u8986\u76d6(exact cover by 4-sets) \u5b9e\u4f8b \u5373X3C\u95ee\u9898\u76f4\u63a5\u6269\u5c55\u62104\u7684\u5f62\u5f0f \u8bc1\u660e \u8003\u8651\u5c06X3C\u95ee\u9898\u5f52\u7ea6\u5230X4C\u95ee\u9898 \u5bf9\u4e8e\u6bcf\u4e2aX3C\u4e2d\u7684\u7b2c \\(i\\) \u4e2a\u96c6\u5408 \\((a,b,c)\\) \uff0c\u76f4\u63a5\u6269\u5c55\u6210 \\((a,b,c,d_{i})\\) \u8fd9\u6837\u4f1a\u591a\u51fa \\(n\\) \u4e2a\u5206\u91cf\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u591a\u51fa\u7684 \\(n\\) \u4e2a\u5206\u91cf\uff0c\u76f4\u63a5\u6dfb\u52a0 \\(C_{n}^{4}\\) \u4e2a\u5143\u7d20\uff0c\u6765\u4fdd\u8bc1\u5168\u90e8\u88ab\u8986\u76d6 \u5f53\u7136\u8fd9\u6837\u8fd8\u662f\u6709\u95ee\u9898\u7684\uff0c\u5373\u4e0d\u4e00\u5b9a\u80fd\u6574\u9664\uff0c\u76f4\u63a5\u8865\u5168\u5c31\u597d\u4e86 \u652f\u914d\u96c6\u95ee\u9898(dominating set) \u5b9e\u4f8b \u65e0\u5411\u56fe \\(G=<V,E>\\) \uff0c \\(K \\leq |V|, K\\in N^{+}\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(V'\\subset V\\) \uff0cst \\(|V'|\\leq K\\) \uff0c\u4e14 \\(\\forall v\\in V/V',st,\\exists u\\in V',uv\\in E\\) \u8bc1\u660e \u88ab\u6211xjb\u753b\u753b\u51fa\u6765\u4e86\u3002 \u8fd9\u4e2a\u4e1c\u897f\u663e\u7136\u548c\u70b9\u8986\u76d6\u95ee\u9898\u5f88\u50cf\u3002 \u4e8e\u662f\u8003\u8651\u7528\u70b9\u8986\u76d6\u95ee\u9898\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5047\u8bbe\u4e00\u4e2a\u70b9\u8986\u76d6\u7684\u5b9e\u4f8b\u662f \\(G'=<V',E'>\\) \u6784\u9020\u4e00\u4e2a\u65b0\u7684\u56fe \\(G''=<V'',E''>\\) \u5176\u4e2d\u5bf9\u4e8e \\(E'\\) \u4e2d\u7684\u6bcf\u6761\u8fb9 \\(uv\\) \uff0c \u589e\u91cf\u6784\u9020 \u4e00\u4e2a\u65b0\u7684\u70b9 \\(d_{i}\\) \uff0c \u589e\u91cf\u6784\u9020 \u4e24\u6761\u8fb9 \\(ud_{i},vd_{i}\\) \u8fd9\u4e2a\u95ee\u9898\u5c31\u53d8\u6210\u4e86\u4e00\u4e2a\u652f\u914d\u96c6\u95ee\u9898\u3002 \u6765\u4e00\u5f20\u56fe\u770b\u770b\u3002 \u57fa\u7840\u70b9\u8986\u76d6\u95ee\u9898 \u65b0\u6784\u90203\u4e2a\u70b94\uff0c5\uff0c6\uff0c\u8f6c\u5316\u6210\u4e00\u4e2a\u652f\u914d\u96c6\u7684\u95ee\u9898 \u56fe3\u67d3\u8272\u95ee\u9898(graph 3-colorability) \u5b9e\u4f8b \u4e16\u4eba\u7686\u77e5 \u8bc1\u660e \u7206\u667a\u529b*1 \u9996\u5148\u8fd9\u4e2a\u95ee\u9898\u770b\u8d77\u6765\u5c31\u5f883SAT\uff0c\u4e8e\u662f\u5c1d\u8bd5\u4ece3SAT\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002\u9996\u5148\u6bd4\u8f83\u597d\u60f3\u7684\u4e00\u4e2a\u90e8\u5206\u5c31\u662f \u5047\u8bbe\u5206\u522b\u67d3\u62101\uff0c2\uff0c3\u8fd93\u79cd\u989c\u8272\uff0c\u90a3\u4e48\u53ef\u4ee5\u6784\u9020\u4e00\u4e2a \\(K_{3}\\) \uff0c\u6765\u6307\u793a\u771f\u5047\u3002 \u7136\u540e\u5c31\u5f88\u56f0\u96be\u4e86/youl \u6211\u5728\u627e\u4e86\u4e00\u53d1\u8d44\u6599\u4e4b\u540e\u53d1\u73b0\u4e86\u4e0b\u9762\u8fd9\u603b\u6784\u9020\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4ea7\u751fPQ\u7684\u6216 \\(P\\bigcup Q\\) \u4e8e\u662f\u5c31\u5f88\u7b80\u5355\u4e86... \u81f3\u4e8e\u600e\u4e48\u60f3\u51fa\u6765\u7684\u6211\u8fd8\u662f\u4e0d\u77e5\u9053\uff0c\u6211\u4f3c\u4e4e\u5bf9\u56fe\u8bba\u77e5\u8bc6\u5e76\u4e0d\u5f88\u654f\u611f\u7684\u6837\u5b50... \u5212\u5206\u4e3a\u957f\u5ea6\u4e3a2\u7684\u901a\u8def\uff08partition into paths of length 2\uff09 \u5b9e\u4f8b \u56fe \\(G=<V,E>\\) \uff0c \\(|V|=3q\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728\u4e00\u4e2a \\(V\\) \u7684\u5212\u5206\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u5b50\u96c6 \\(V_{i}=\\{v_{1},v_{2},v_{3}\\}\\) \u5176\u70b9\u5bfc\u51fa\u5b50\u56fe\uff0c\u5b58\u5728\u4e00\u6761\u957f\u5ea6\u4e3a2\u7684\u8def\u3002 \u8bc1\u660e \u8003\u8651\u901a\u8fc7X3C\u95ee\u9898\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898 \u5047\u8bbe\u6709\u4e00\u4e2aX3C\u7684\u95ee\u9898\u5b9e\u4f8b \\((a_{i},b_{i},c_{i})\\) \u6784\u9020 \\(3q\\) \u4e2a\u70b9\uff0c\u7136\u540e\u8fde\u8fb9 \\((a_{i},b_{i}),(b_{i},c_{i})\\) \u8fd9\u6837\u6bcf\u6b21\u4e00\u4e2a\u5212\u5206\uff0c\u5c31\u4ee3\u8868\u4e86\u9009\u62e9\u4e86X3C\u95ee\u9898\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20\u3002 k-median \u5b9e\u4f8b \u4e16\u4eba\u7686\u77e5 \u8bc1\u660e \u8003\u8651\u901a\u8fc7\u652f\u914d\u96c6\u95ee\u9898\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5bf9\u4e8e\u652f\u914d\u96c6\u95ee\u9898\u7684\u56fe \\(G=<V,E>\\) \u5c06 \\(V\\) \u4e2d\u9876\u70b9\u590d\u5236\u4e00\u4efd\u4f5c\u4e3a\u5de5\u5382\uff0c\u6bcf\u4e2a\u70b9\u5411\u81ea\u5df1\u548c\u5173\u8054\u70b9\u8fde \\(d=0\\) \u7684\u8fb9\u3002 \u7136\u540e\u5c31\u505a\u5b8c\u4e86/youl Steiner tree \u5b9e\u4f8b \u4e16\u4eba\u7686\u77e5 \u8bc1\u660e \u88ab\u7206\u667a\u529b*3\uff0c\u88ab\u7206\u5230\u4e0d\u60f3\u5199\u8bc1\u660e\u4e86 http://profs.sci.univr.it/~rrizzi/classes/Complexity/provette/Santuari/steiner.pdf \u96c6\u5408\u5206\u88c2\u95ee\u9898\uff08set splitting\uff09 \u5b9e\u4f8b \u4e00\u4e2a\u6709\u9650\u96c6 \\(S\\) \uff0c \\(C \\subset 2^{S}\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728\u4e00\u4e2a \\(S\\) \u7684\u5212\u5206 \\(S_{1},S_{2}\\) \uff0c\u4f7f\u5f97 \\(\\forall x \\in C, x \\not\\subset S_{1},x\\not\\subset S_{2}\\) \u8bc1\u660e \u88ab\u7206\u667a\u529b*2 \u8fd9\u4e2a\u4e1c\u897f\u771f\u7684\u597d\u9760\u76f4\u89c9\u5440/youl\uff0c\u7ed9\u4e2a\u63d0\u793a\u5c31\u597d\u60f3\u4e86\u3002 \u8003\u8651\u4f7f\u75283SAT\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\uff0c\u4e0b\u9762\u6765\u7740\u624b\u6784\u9020 \\(C\\) \u5bf9\u4e8e \\((a_{i},b_{i},c_{i})\\) \u6765\u8bf4\uff0c\u6784\u9020 \\((a_{i},\\overline a_{i}),(b_{i},\\overline b_{i}),(c_{i},\\overline c_{i})\\) \u4ee5\u53ca \\((d, \\overline a_{i}, \\overline b_{i}, \\overline c_{i})\\) \u5047\u8bbe\u8fd9\u4e2a\u96c6\u5408\u5206\u88c2\u95ee\u9898\u5f97\u5230\u4e86\u4e00\u4e2a\u89e3\uff0c\u5c06 \\(d\\) \u6240\u5728\u7684\u96c6\u5408\u7684\u53d8\u91cf\u5168\u8bbe\u4e3a\u771f\uff0c\u5176\u4f59\u5168\u8bbe\u4e3a\u5047\u3002","title":"NP-Complete\u95ee\u9898\u4e71\u8bc1"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#np-complete","text":"","title":"NP-Complete\u95ee\u9898\u4e71\u8bc1"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#longest-path","text":"","title":"\u6700\u957f\u901a\u8def\u95ee\u9898(longest path)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_1","text":"\u56fe \\(G=<V,E>\\) \uff0c\u662f\u5426\u5b58\u5728\u4e00\u6761\u957f\u5ea6\u81f3\u5c11\u4e3a \\(K\\) \u7684\u8def","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_2","text":"\u4ee4 \\(K = |V|\\) \u4e8e\u662f\u95ee\u9898\u53d8\u6210\u4e86Hamilton \u901a\u8def\u95ee\u9898\uff0c\u8bc1\u6bd5\u3002","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_3","text":"","title":"\u96c6\u5408\u5305\u88c5\u95ee\u9898"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_4","text":"\u4ee4\u67d0\u4e2a\u96c6\u5408 \\(|S| < \\infty\\) , \\(C \\subset 2^{S}\\) \uff0c \\(n = |C|\\) \uff0c\u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(C\\) \u4e2d\u7684 \\(k\\) \u4e2a\u5143\u7d20\uff0c\u4f7f\u5f97\u4efb\u610f\u4e24\u4e2a\u4e92\u4e0d\u4ea4\u53c9","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_5","text":"\u8fd9\u4e2a\u95ee\u9898\u663e\u7136\u662f\u56e2\u95ee\u9898...","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#partition-into-hamilton-subgraph","text":"","title":"\u54c8\u5bc6\u5c14\u987f\u5b50\u56fe\u5212\u5206(partition into Hamilton subgraph)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_6","text":"\u56fe \\(G\\) \uff0c\u80fd\u5426\u88ab\u5212\u5206\u6210 \\(k\\) \u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u96c6\u5408\u4f7f\u5f97\u6bcf\u4e2a\u5bfc\u51fa\u5b50\u56fe\u5305\u542b\u4e00\u4e2a\u54c8\u5bc6\u5c14\u987f\u56de\u8def","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_7","text":"\u4ee4 \\(k=1\\) \u95ee\u9898\u53d8\u6210Hamilton \u56de\u8def\u95ee\u9898","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#largest-common-subgraph","text":"","title":"\u6700\u5927\u516c\u5171\u5b50\u56fe\u95ee\u9898(largest common subgraph)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_8","text":"\u7ed9\u4e24\u5f20\u56fe \\(G_{1}\\) \uff0c \\(G_{2}\\) \uff0c\u6c42\u4e24\u4e2a\u6700\u5927\u7684\u5b50\u56fe\u540c\u6784","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_9","text":"\u4ee4\u7b2c\u4e8c\u5f20\u56fe\u4e3a\u5927\u5c0f\u4e3a \\(k\\) \u7684\u5b8c\u5168\u56fe\uff0c\u6574\u4e2a\u95ee\u9898\u53d8\u6210\u4e86\u56e2\u95ee\u9898\u3002","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#minimum-sum-of-squares","text":"","title":"\u6700\u5c0f\u5e73\u65b9\u548c\u95ee\u9898(minimum sum of squares)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_10","text":"\u6709\u9650\u96c6\u5408 \\(A\\) \uff0c\u6bcf\u4e2a\u5143\u7d20 \\(a \\in A\\) \uff0c\u6bcf\u4e2a\u5143\u7d20\u5747\u6709\u4e00\u4e2a\u503c \\(f: A \\rightarrow R\\) \u5c06\u96c6\u5408 \\(A\\) \u5206\u6210 \\(K\\) \u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u96c6\u5408\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u5b50\u96c6\u7684\u5e73\u65b9\u548c\u7684\u548c\u5c0f\u4e8e\u7b49\u4e8e \\(J\\)","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_11","text":"\u5bf9\u4e8e\u8fd9\u4e2a\u5212\u5206\u95ee\u9898\uff0c\u8003\u8651\u7528\u4e8c\u5212\u5206\u95ee\u9898\u5411\u8fd9\u4e2a\u65b9\u5411\u6765\u68c0\u6d4b \u8003\u8651\u5e73\u65b9\u589e\u957f\u7684\u901f\u5ea6\u6bd4\u7ebf\u6027\u5feb\u5f97\u591a\uff0c\u76f4\u63a5\u590d\u5236n\u4efd\uff0c\u7136\u540e\u89c4\u7ea6\u4e8c\u5212\u5206 \u8fd9\u91cc\u4e0d\u662f\u5f88\u4e25\u8c28\uff0c\u4e0b\u6b21\u4e00\u5b9a","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#feedback-vertex-set","text":"","title":"\u8fd4\u56de\u9876\u70b9\u96c6(feedback vertex set)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_12","text":"\u6709\u5411\u56fe \\(G=<V,A>\\) \uff0c\u6b63\u6574\u6570 \\(K \\leq |V|\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(V'\\subset V\\) \uff0c \\(|V'|\\leq K\\) \uff0c\u4e14 \\(G\\) \u7684\u6bcf\u4e00\u6761\u6709\u5411\u56de\u8def\u81f3\u5c11\u5305\u542b \\(V'\\) \u7684\u4e00\u4e2a\u70b9","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_13","text":"\u8fd9\u5f88\u663e\u7136\u662f\u4e2a\u51fb\u4e2d\u96c6\u95ee\u9898\u3002","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#exact-cover-by-4-sets","text":"","title":"\u56db\u5143\u7d20\u96c6\u5408\u7684\u4e25\u683c\u8986\u76d6(exact cover by 4-sets)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_14","text":"\u5373X3C\u95ee\u9898\u76f4\u63a5\u6269\u5c55\u62104\u7684\u5f62\u5f0f","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_15","text":"\u8003\u8651\u5c06X3C\u95ee\u9898\u5f52\u7ea6\u5230X4C\u95ee\u9898 \u5bf9\u4e8e\u6bcf\u4e2aX3C\u4e2d\u7684\u7b2c \\(i\\) \u4e2a\u96c6\u5408 \\((a,b,c)\\) \uff0c\u76f4\u63a5\u6269\u5c55\u6210 \\((a,b,c,d_{i})\\) \u8fd9\u6837\u4f1a\u591a\u51fa \\(n\\) \u4e2a\u5206\u91cf\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u591a\u51fa\u7684 \\(n\\) \u4e2a\u5206\u91cf\uff0c\u76f4\u63a5\u6dfb\u52a0 \\(C_{n}^{4}\\) \u4e2a\u5143\u7d20\uff0c\u6765\u4fdd\u8bc1\u5168\u90e8\u88ab\u8986\u76d6 \u5f53\u7136\u8fd9\u6837\u8fd8\u662f\u6709\u95ee\u9898\u7684\uff0c\u5373\u4e0d\u4e00\u5b9a\u80fd\u6574\u9664\uff0c\u76f4\u63a5\u8865\u5168\u5c31\u597d\u4e86","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#dominating-set","text":"","title":"\u652f\u914d\u96c6\u95ee\u9898(dominating set)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_16","text":"\u65e0\u5411\u56fe \\(G=<V,E>\\) \uff0c \\(K \\leq |V|, K\\in N^{+}\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728 \\(V'\\subset V\\) \uff0cst \\(|V'|\\leq K\\) \uff0c\u4e14 \\(\\forall v\\in V/V',st,\\exists u\\in V',uv\\in E\\)","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_17","text":"\u88ab\u6211xjb\u753b\u753b\u51fa\u6765\u4e86\u3002 \u8fd9\u4e2a\u4e1c\u897f\u663e\u7136\u548c\u70b9\u8986\u76d6\u95ee\u9898\u5f88\u50cf\u3002 \u4e8e\u662f\u8003\u8651\u7528\u70b9\u8986\u76d6\u95ee\u9898\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5047\u8bbe\u4e00\u4e2a\u70b9\u8986\u76d6\u7684\u5b9e\u4f8b\u662f \\(G'=<V',E'>\\) \u6784\u9020\u4e00\u4e2a\u65b0\u7684\u56fe \\(G''=<V'',E''>\\) \u5176\u4e2d\u5bf9\u4e8e \\(E'\\) \u4e2d\u7684\u6bcf\u6761\u8fb9 \\(uv\\) \uff0c \u589e\u91cf\u6784\u9020 \u4e00\u4e2a\u65b0\u7684\u70b9 \\(d_{i}\\) \uff0c \u589e\u91cf\u6784\u9020 \u4e24\u6761\u8fb9 \\(ud_{i},vd_{i}\\) \u8fd9\u4e2a\u95ee\u9898\u5c31\u53d8\u6210\u4e86\u4e00\u4e2a\u652f\u914d\u96c6\u95ee\u9898\u3002 \u6765\u4e00\u5f20\u56fe\u770b\u770b\u3002 \u57fa\u7840\u70b9\u8986\u76d6\u95ee\u9898 \u65b0\u6784\u90203\u4e2a\u70b94\uff0c5\uff0c6\uff0c\u8f6c\u5316\u6210\u4e00\u4e2a\u652f\u914d\u96c6\u7684\u95ee\u9898","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#3graph-3-colorability","text":"","title":"\u56fe3\u67d3\u8272\u95ee\u9898(graph 3-colorability)"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_18","text":"\u4e16\u4eba\u7686\u77e5","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_19","text":"\u7206\u667a\u529b*1 \u9996\u5148\u8fd9\u4e2a\u95ee\u9898\u770b\u8d77\u6765\u5c31\u5f883SAT\uff0c\u4e8e\u662f\u5c1d\u8bd5\u4ece3SAT\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002\u9996\u5148\u6bd4\u8f83\u597d\u60f3\u7684\u4e00\u4e2a\u90e8\u5206\u5c31\u662f \u5047\u8bbe\u5206\u522b\u67d3\u62101\uff0c2\uff0c3\u8fd93\u79cd\u989c\u8272\uff0c\u90a3\u4e48\u53ef\u4ee5\u6784\u9020\u4e00\u4e2a \\(K_{3}\\) \uff0c\u6765\u6307\u793a\u771f\u5047\u3002 \u7136\u540e\u5c31\u5f88\u56f0\u96be\u4e86/youl \u6211\u5728\u627e\u4e86\u4e00\u53d1\u8d44\u6599\u4e4b\u540e\u53d1\u73b0\u4e86\u4e0b\u9762\u8fd9\u603b\u6784\u9020\u65b9\u5f0f\uff0c\u53ef\u4ee5\u4ea7\u751fPQ\u7684\u6216 \\(P\\bigcup Q\\) \u4e8e\u662f\u5c31\u5f88\u7b80\u5355\u4e86... \u81f3\u4e8e\u600e\u4e48\u60f3\u51fa\u6765\u7684\u6211\u8fd8\u662f\u4e0d\u77e5\u9053\uff0c\u6211\u4f3c\u4e4e\u5bf9\u56fe\u8bba\u77e5\u8bc6\u5e76\u4e0d\u5f88\u654f\u611f\u7684\u6837\u5b50...","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#2partition-into-paths-of-length-2","text":"","title":"\u5212\u5206\u4e3a\u957f\u5ea6\u4e3a2\u7684\u901a\u8def\uff08partition into paths of length 2\uff09"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_20","text":"\u56fe \\(G=<V,E>\\) \uff0c \\(|V|=3q\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728\u4e00\u4e2a \\(V\\) \u7684\u5212\u5206\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u4e92\u8865\u76f8\u4ea4\u7684\u5b50\u96c6 \\(V_{i}=\\{v_{1},v_{2},v_{3}\\}\\) \u5176\u70b9\u5bfc\u51fa\u5b50\u56fe\uff0c\u5b58\u5728\u4e00\u6761\u957f\u5ea6\u4e3a2\u7684\u8def\u3002","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_21","text":"\u8003\u8651\u901a\u8fc7X3C\u95ee\u9898\u89c4\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898 \u5047\u8bbe\u6709\u4e00\u4e2aX3C\u7684\u95ee\u9898\u5b9e\u4f8b \\((a_{i},b_{i},c_{i})\\) \u6784\u9020 \\(3q\\) \u4e2a\u70b9\uff0c\u7136\u540e\u8fde\u8fb9 \\((a_{i},b_{i}),(b_{i},c_{i})\\) \u8fd9\u6837\u6bcf\u6b21\u4e00\u4e2a\u5212\u5206\uff0c\u5c31\u4ee3\u8868\u4e86\u9009\u62e9\u4e86X3C\u95ee\u9898\u4e2d\u7684\u4e00\u4e2a\u5143\u7d20\u3002","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#k-median","text":"","title":"k-median"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_22","text":"\u4e16\u4eba\u7686\u77e5","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_23","text":"\u8003\u8651\u901a\u8fc7\u652f\u914d\u96c6\u95ee\u9898\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5bf9\u4e8e\u652f\u914d\u96c6\u95ee\u9898\u7684\u56fe \\(G=<V,E>\\) \u5c06 \\(V\\) \u4e2d\u9876\u70b9\u590d\u5236\u4e00\u4efd\u4f5c\u4e3a\u5de5\u5382\uff0c\u6bcf\u4e2a\u70b9\u5411\u81ea\u5df1\u548c\u5173\u8054\u70b9\u8fde \\(d=0\\) \u7684\u8fb9\u3002 \u7136\u540e\u5c31\u505a\u5b8c\u4e86/youl","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#steiner-tree","text":"","title":"Steiner tree"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_24","text":"\u4e16\u4eba\u7686\u77e5","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_25","text":"\u88ab\u7206\u667a\u529b*3\uff0c\u88ab\u7206\u5230\u4e0d\u60f3\u5199\u8bc1\u660e\u4e86 http://profs.sci.univr.it/~rrizzi/classes/Complexity/provette/Santuari/steiner.pdf","title":"\u8bc1\u660e"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#set-splitting","text":"","title":"\u96c6\u5408\u5206\u88c2\u95ee\u9898\uff08set splitting\uff09"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_26","text":"\u4e00\u4e2a\u6709\u9650\u96c6 \\(S\\) \uff0c \\(C \\subset 2^{S}\\) \u8be2\u95ee\u662f\u5426\u5b58\u5728\u4e00\u4e2a \\(S\\) \u7684\u5212\u5206 \\(S_{1},S_{2}\\) \uff0c\u4f7f\u5f97 \\(\\forall x \\in C, x \\not\\subset S_{1},x\\not\\subset S_{2}\\)","title":"\u5b9e\u4f8b"},{"location":"blog/2021/NP-Complete%E9%97%AE%E9%A2%98%E4%B9%B1%E8%AF%81/#_27","text":"\u88ab\u7206\u667a\u529b*2 \u8fd9\u4e2a\u4e1c\u897f\u771f\u7684\u597d\u9760\u76f4\u89c9\u5440/youl\uff0c\u7ed9\u4e2a\u63d0\u793a\u5c31\u597d\u60f3\u4e86\u3002 \u8003\u8651\u4f7f\u75283SAT\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\uff0c\u4e0b\u9762\u6765\u7740\u624b\u6784\u9020 \\(C\\) \u5bf9\u4e8e \\((a_{i},b_{i},c_{i})\\) \u6765\u8bf4\uff0c\u6784\u9020 \\((a_{i},\\overline a_{i}),(b_{i},\\overline b_{i}),(c_{i},\\overline c_{i})\\) \u4ee5\u53ca \\((d, \\overline a_{i}, \\overline b_{i}, \\overline c_{i})\\) \u5047\u8bbe\u8fd9\u4e2a\u96c6\u5408\u5206\u88c2\u95ee\u9898\u5f97\u5230\u4e86\u4e00\u4e2a\u89e3\uff0c\u5c06 \\(d\\) \u6240\u5728\u7684\u96c6\u5408\u7684\u53d8\u91cf\u5168\u8bbe\u4e3a\u771f\uff0c\u5176\u4f59\u5168\u8bbe\u4e3a\u5047\u3002","title":"\u8bc1\u660e"},{"location":"blog/2021/Quartus2%E4%B8%8Emodelsim%E8%81%94%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/","tags":["\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406"],"text":"\u8c03\u8bd5\u7684\u65f6\u5019\u59d1\u4e14\u505a\u4e86\u4e00\u4e2a\u8c03\u8bd5\u7b14\u8bb0, \u7a0d\u5fae\u5217\u4e00\u4e9b\u56de\u5fc6\u4e2d\u7684\u5751\u5427. \u5b89\u88c5ModelSim\u7684\u65f6\u5019\u4e00\u5b9a\u8981\u4fdd\u8bc1\u548cQuartus\u7248\u672c\u53f7\u4e00\u81f4 \u7531Verilog\u4e2d\u4ea7\u751f\u7684 \"bug\" Verilog\u4e2d\u7684initial\u6a21\u5757\u5728\u4e0b\u8f7d\u5230\u5f00\u53d1\u677f\u4e0a\u65f6\u5e76\u4e0d\u4f1a\u751f\u6548. \u6240\u8c13\u7684\"\u521d\u59cb\u5316\"\u4ec5\u4ec5\u5728\u6a21\u62df\u4e2d\u751f\u6548. \u6240\u4ee5\u4e25\u683c\u6765\u8bf4\u8fd8\u662f\u8981\u52a0\u4e00\u4e2a\u4fe1\u53f7\u6765\u5bf9\u5bc4\u5b58\u5668\u8fdb\u884c\u521d\u59cb\u5316. Verilog \u5728Quartus\u4e2d\u7f16\u8bd1\u65f6\u4e00\u5b9a\u8981\u770b\u5176\u4e2d\u7684\u8b66\u544a\u4fe1\u606f, \u56e0\u4e3averilog\u5141\u8bb8\u4e86\u9690\u5f0f\u58f0\u660e\u4e00\u4e2awire \u4f8b\u5982\u6211\u6709\u4e00\u4e2amodule abab(input[3:0] a); \u5728\u8c03\u7528\u65f6\u76f4\u63a5\u5199\u4e86 abab xxx(b); \u9690\u5f0f\u4ea7\u751f\u4e86\u4e00\u4e2awire b, \u4f46\u662f\u8fd9\u4e2a\u9690\u5f0f\u4ea7\u751f\u7684\u4fe1\u53f7b\u53ea\u6709\u4e00\u4e2abit\u957f, \u5e76\u4e0d\u662f4bit\u957f\u7684. \u540c\u6837\u7684\u4f7f\u7528assign \u9690\u5f0f\u6765\u5b9a\u4e49\u4e00\u4e2awire \u4e5f\u4f1a\u4ea7\u751f\u5982\u4e0a\u7684 \"bug\". Verilog \u4e2d\u5bf9\u4e8e\u8f93\u5165\u7684\u957f\u5ea6\u6ca1\u6709\u505a\u5230\u4e25\u683c\u7684\u5339\u914d, \u6bd4\u5982\u4e0a\u6587\u4e2d\u7684 module abab(input[3:0] a); \u6211\u4e5f\u53ef\u4ee5, \u8fd9\u6837\u4f20\u53c2 wire [100:0] b; abab xxx(b); \u8fd9\u6837\u867d\u7136\u53ef\u4ee5\u8fc7\u7f16\u8bd1, \u4f46\u662f\u5728RTL\u6a21\u62df\u4e2d\u4f1a\u51fa\u73b0\u4e00\u4e9b\u5947\u602a\u7684bug \u6bd4\u5982\u8f93\u51fa\u4e3a\"z\". \u8fd8\u6709\u662fVerilog\u4e2d\u540c\u65f6\u68c0\u6d4b\u4e24\u4e2a\u4fe1\u53f7\u7684always, \u4e0d\u8fc7\u8fd9\u91cc\u6211\u4e5f\u4e0d\u77e5\u9053\u6b63\u7edf\u7684\u65b9\u6cd5\u662f\u4ec0\u4e48, \u4e3a\u4e86\u4fdd\u8bc1\u6b63\u786e. \u6700\u597d\u91c7\u53d6\u5982\u4e0b\u5199\u6cd5 always @(posedge clk or negedge rst) begin if(!rst) begin ... end else begin .. end end \u7531Quartus\u4ea7\u751f\u7684\"bug\" Quartus\u4e2d\u7684\u4eff\u771f\u529f\u80fd\u4e0d\u80fd\u770b\u5230\u4eff\u771f\u540e\u7684\u5185\u5b58\u60c5\u51b5. \u53ef\u4ee5\u901a\u8fc7\u91c7\u53d6\u4f7f\u7528Quartus\u751f\u6210\u6d4b\u8bd5\u6587\u4ef6, \u901a\u8fc7modelsim\u8fdb\u884c\u6a21\u62df\u4eff\u771f\u7684\u65b9\u5f0f. \u8fd9\u4e2a\u65b9\u5f0f\u9700\u8981\u81ea\u5df1\u5199testbench\u6587\u4ef6. \u4eff\u771f\u7684\u6b65\u9aa4\u53ef\u4ee5\u67e5\u770b\u8fd9\u4e2a \u89c6\u9891 \u671f\u95f4\u53ef\u80fd\u906d\u9047\u65e0\u6cd5\u6b63\u786e\u52a0\u8f7dRAM&ROM \u521d\u59cb\u5316\u6587\u4ef6\u7684\u60c5\u51b5, \u53ef\u4ee5\u67e5\u770b\u8fd9\u4e2a \u94fe\u63a5 Quartus\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u5305\u542b\u4e86\u8bb8\u591a\u5728\u4eff\u771f\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u7528\u4e0d\u5230\u7684\u5de5\u5e8f. \u5bf9\u4e8eRTL\u6a21\u62df(\u529f\u80fd\u6a21\u62df)\u6765\u8bf4, \u5e76\u4e0d\u9700\u8981\u5728Quartus\u4e2d\u91cd\u65b0\u7f16\u8bd1, \u53ea\u9700\u8981\u5173\u6389ModelSim \u91cd\u65b0\u8fdb\u884c\u4eff\u771f\u5c31\u53ef\u4ee5\u4e86. \u800c\u5bf9\u4e8e\u65f6\u5e8f\u6a21\u62df\u6765\u8bf4, \u9700\u8981\u91cd\u65b0\u7f16\u8bd1. \u5229\u7528\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u4ee5\u52a0\u5febdebug\u901f\u5ea6, \u5f53\u7136\u6700\u7a33\u5065\u7684\u65b9\u5f0f\u8fd8\u662f\u6bcf\u6b21\u91cd\u65b0\u7f16\u8bd1. Quartus\u4e2d\u91cd\u65b0\u7f16\u8bd1\u5e76\u4e0d\u4f1a\u81ea\u52a8\u4ea7\u751ftestbench\u6587\u4ef6, \u9700\u8981\u624b\u52a8\u6309\u6309\u94ae\u6765\u751f\u6210. \u7531ModelSim \u4ea7\u751f\u7684\"bug\" \u4f60\u53ef\u80fd\u4f1a\u53d1\u73b0\u4eff\u771f\u7ed3\u679c\u5728\u65f6\u5e8f\u4eff\u771f\u548c\u529f\u80fd\u4eff\u771f\u4e0b\u7ed3\u679c\u4e0d\u4e00\u6837. \u8fd9\u79cd\u60c5\u51b5\u5341\u5206\u6709\u98ce\u9669, \u5c3d\u53ef\u80fd\u4fdd\u8bc1\u4e24\u79cd\u4eff\u771f\u4e0b\u7ed3\u679c\u4e00\u81f4. \u4f46\u662f\u65f6\u5e8f\u4eff\u771f\u4e2d\u65e0\u6cd5\u67e5\u770bROM&RAM\u4e2d\u7684\u6570\u636e. \u5728\u529f\u80fd\u4eff\u771f\u4e2d\u53ef\u4ee5, \u5177\u4f53\u65b9\u5f0f\u53ef\u67e5\u770b\u8fd9\u4e2a \u94fe\u63a5 \u540c\u65f6\u5728\u65f6\u5e8f\u4eff\u771f\u7684\u65f6\u5019\u4e00\u5b9a\u8981\u6ce8\u610f\u65f6\u949f\u95f4\u9694\u4e0d\u80fd\u592a\u77ed\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u7ed3\u679c\u8fd8\u6ca1\u7a33\u5b9a\u7684\u65f6\u5019\u5c31\u8fdb\u884c\u4e86\u4e0b\u4e00\u6b65\u3002 \u65e0\u4e86, \u795d\u597d.","title":"Quartus2\u4e0emodelsim\u8054\u7528\u65f6\u7684\u4e00\u4e9b\u5751"},{"location":"blog/2021/Quartus2%E4%B8%8Emodelsim%E8%81%94%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/#verilog-bug","text":"Verilog\u4e2d\u7684initial\u6a21\u5757\u5728\u4e0b\u8f7d\u5230\u5f00\u53d1\u677f\u4e0a\u65f6\u5e76\u4e0d\u4f1a\u751f\u6548. \u6240\u8c13\u7684\"\u521d\u59cb\u5316\"\u4ec5\u4ec5\u5728\u6a21\u62df\u4e2d\u751f\u6548. \u6240\u4ee5\u4e25\u683c\u6765\u8bf4\u8fd8\u662f\u8981\u52a0\u4e00\u4e2a\u4fe1\u53f7\u6765\u5bf9\u5bc4\u5b58\u5668\u8fdb\u884c\u521d\u59cb\u5316. Verilog \u5728Quartus\u4e2d\u7f16\u8bd1\u65f6\u4e00\u5b9a\u8981\u770b\u5176\u4e2d\u7684\u8b66\u544a\u4fe1\u606f, \u56e0\u4e3averilog\u5141\u8bb8\u4e86\u9690\u5f0f\u58f0\u660e\u4e00\u4e2awire \u4f8b\u5982\u6211\u6709\u4e00\u4e2amodule abab(input[3:0] a); \u5728\u8c03\u7528\u65f6\u76f4\u63a5\u5199\u4e86 abab xxx(b); \u9690\u5f0f\u4ea7\u751f\u4e86\u4e00\u4e2awire b, \u4f46\u662f\u8fd9\u4e2a\u9690\u5f0f\u4ea7\u751f\u7684\u4fe1\u53f7b\u53ea\u6709\u4e00\u4e2abit\u957f, \u5e76\u4e0d\u662f4bit\u957f\u7684. \u540c\u6837\u7684\u4f7f\u7528assign \u9690\u5f0f\u6765\u5b9a\u4e49\u4e00\u4e2awire \u4e5f\u4f1a\u4ea7\u751f\u5982\u4e0a\u7684 \"bug\". Verilog \u4e2d\u5bf9\u4e8e\u8f93\u5165\u7684\u957f\u5ea6\u6ca1\u6709\u505a\u5230\u4e25\u683c\u7684\u5339\u914d, \u6bd4\u5982\u4e0a\u6587\u4e2d\u7684 module abab(input[3:0] a); \u6211\u4e5f\u53ef\u4ee5, \u8fd9\u6837\u4f20\u53c2 wire [100:0] b; abab xxx(b); \u8fd9\u6837\u867d\u7136\u53ef\u4ee5\u8fc7\u7f16\u8bd1, \u4f46\u662f\u5728RTL\u6a21\u62df\u4e2d\u4f1a\u51fa\u73b0\u4e00\u4e9b\u5947\u602a\u7684bug \u6bd4\u5982\u8f93\u51fa\u4e3a\"z\". \u8fd8\u6709\u662fVerilog\u4e2d\u540c\u65f6\u68c0\u6d4b\u4e24\u4e2a\u4fe1\u53f7\u7684always, \u4e0d\u8fc7\u8fd9\u91cc\u6211\u4e5f\u4e0d\u77e5\u9053\u6b63\u7edf\u7684\u65b9\u6cd5\u662f\u4ec0\u4e48, \u4e3a\u4e86\u4fdd\u8bc1\u6b63\u786e. \u6700\u597d\u91c7\u53d6\u5982\u4e0b\u5199\u6cd5 always @(posedge clk or negedge rst) begin if(!rst) begin ... end else begin .. end end","title":"\u7531Verilog\u4e2d\u4ea7\u751f\u7684 \"bug\""},{"location":"blog/2021/Quartus2%E4%B8%8Emodelsim%E8%81%94%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/#quartusbug","text":"Quartus\u4e2d\u7684\u4eff\u771f\u529f\u80fd\u4e0d\u80fd\u770b\u5230\u4eff\u771f\u540e\u7684\u5185\u5b58\u60c5\u51b5. \u53ef\u4ee5\u901a\u8fc7\u91c7\u53d6\u4f7f\u7528Quartus\u751f\u6210\u6d4b\u8bd5\u6587\u4ef6, \u901a\u8fc7modelsim\u8fdb\u884c\u6a21\u62df\u4eff\u771f\u7684\u65b9\u5f0f. \u8fd9\u4e2a\u65b9\u5f0f\u9700\u8981\u81ea\u5df1\u5199testbench\u6587\u4ef6. \u4eff\u771f\u7684\u6b65\u9aa4\u53ef\u4ee5\u67e5\u770b\u8fd9\u4e2a \u89c6\u9891 \u671f\u95f4\u53ef\u80fd\u906d\u9047\u65e0\u6cd5\u6b63\u786e\u52a0\u8f7dRAM&ROM \u521d\u59cb\u5316\u6587\u4ef6\u7684\u60c5\u51b5, \u53ef\u4ee5\u67e5\u770b\u8fd9\u4e2a \u94fe\u63a5 Quartus\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u5305\u542b\u4e86\u8bb8\u591a\u5728\u4eff\u771f\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u7528\u4e0d\u5230\u7684\u5de5\u5e8f. \u5bf9\u4e8eRTL\u6a21\u62df(\u529f\u80fd\u6a21\u62df)\u6765\u8bf4, \u5e76\u4e0d\u9700\u8981\u5728Quartus\u4e2d\u91cd\u65b0\u7f16\u8bd1, \u53ea\u9700\u8981\u5173\u6389ModelSim \u91cd\u65b0\u8fdb\u884c\u4eff\u771f\u5c31\u53ef\u4ee5\u4e86. \u800c\u5bf9\u4e8e\u65f6\u5e8f\u6a21\u62df\u6765\u8bf4, \u9700\u8981\u91cd\u65b0\u7f16\u8bd1. \u5229\u7528\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u4ee5\u52a0\u5febdebug\u901f\u5ea6, \u5f53\u7136\u6700\u7a33\u5065\u7684\u65b9\u5f0f\u8fd8\u662f\u6bcf\u6b21\u91cd\u65b0\u7f16\u8bd1. Quartus\u4e2d\u91cd\u65b0\u7f16\u8bd1\u5e76\u4e0d\u4f1a\u81ea\u52a8\u4ea7\u751ftestbench\u6587\u4ef6, \u9700\u8981\u624b\u52a8\u6309\u6309\u94ae\u6765\u751f\u6210.","title":"\u7531Quartus\u4ea7\u751f\u7684\"bug\""},{"location":"blog/2021/Quartus2%E4%B8%8Emodelsim%E8%81%94%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/#modelsim-bug","text":"\u4f60\u53ef\u80fd\u4f1a\u53d1\u73b0\u4eff\u771f\u7ed3\u679c\u5728\u65f6\u5e8f\u4eff\u771f\u548c\u529f\u80fd\u4eff\u771f\u4e0b\u7ed3\u679c\u4e0d\u4e00\u6837. \u8fd9\u79cd\u60c5\u51b5\u5341\u5206\u6709\u98ce\u9669, \u5c3d\u53ef\u80fd\u4fdd\u8bc1\u4e24\u79cd\u4eff\u771f\u4e0b\u7ed3\u679c\u4e00\u81f4. \u4f46\u662f\u65f6\u5e8f\u4eff\u771f\u4e2d\u65e0\u6cd5\u67e5\u770bROM&RAM\u4e2d\u7684\u6570\u636e. \u5728\u529f\u80fd\u4eff\u771f\u4e2d\u53ef\u4ee5, \u5177\u4f53\u65b9\u5f0f\u53ef\u67e5\u770b\u8fd9\u4e2a \u94fe\u63a5 \u540c\u65f6\u5728\u65f6\u5e8f\u4eff\u771f\u7684\u65f6\u5019\u4e00\u5b9a\u8981\u6ce8\u610f\u65f6\u949f\u95f4\u9694\u4e0d\u80fd\u592a\u77ed\uff0c\u5426\u5219\u53ef\u80fd\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u7ed3\u679c\u8fd8\u6ca1\u7a33\u5b9a\u7684\u65f6\u5019\u5c31\u8fdb\u884c\u4e86\u4e0b\u4e00\u6b65\u3002 \u65e0\u4e86, \u795d\u597d.","title":"\u7531ModelSim \u4ea7\u751f\u7684\"bug\""},{"location":"blog/2021/StrassenAlgorithm/","text":"Strassen \u7b97\u6cd5\u7684\u4e00\u4e01\u70b9\u63a8\u5bfc(\uff89*\uff65\u03c9\uff65)\uff89 Strassen Algorithm \u6b64\u5904\u6307\u7684\u662f\u8ba1\u7b97\u77e9\u9635\u4e58\u6cd5\u7684\u90a3\u4e2aStrassen\u7b97\u6cd5\u3002 \u672c\u6587\u5047\u8bbe\u4f60\u4e86\u89e3Strassen\u7b97\u6cd5\u7684\u6d41\u7a0b \u63a8\u5bfc \u6211\u4eec\u4e8b\u540e\u5f97\u77e5\u8fd9\u79cd\u7b97\u6cd5\u662f\u5c06\u539f\u6709\u7684 \\(8\\) \u7684\u4e58\u6cd5\u7ed3\u679c\u538b\u7f29\u6210\u4e86 \\(7\\) \u4e2a\u3002 \u6211\u4eec\u9996\u5148\u6765\u7ea6\u5b9a\u4e09\u79cdsmall case 3\u79cd small case 3\u79cdsmall case\u90fd\u662f\u7ecf\u8fc7\u5206\u6210 \u5927\u5c0f\u76f8\u540c \u7684\u5757\uff0c\u5f62\u6210\u77e9\u9635\u4e58\u4e00\u4e2a\u5411\u91cf\u7684\u5f62\u5f0f\u3002 \u5f62\u5982\u4e0b\u9762\u7684\u6837\u5b50 \\[\\begin{pmatrix}a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{pmatrix}\\begin{pmatrix} b_{1} \\\\ b_{2}\\end{pmatrix}\\] 1st \u7b2c\u4e00\u79cd\u4e3a \\(a_{11},a_{12},a_{21},a_{22}\\) \u90fd\u76f8\u7b49\uff0c\u8fd9\u4e2a\u65f6\u5019\u4e58\u6cd5\u7ed3\u679c\u5c31\u662f \\[\\begin{pmatrix} a(b_{1}+b_{2}) \\\\ a(b_{1}+b_{2})\\end{pmatrix}\\] \u663e\u7136\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\u6211\u4eec\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e00\u6b21\u77e9\u9635\u4e58\u6cd5\u5c31\u597d\u4e86 2nd \u7b2c\u4e8c\u79cd\u60c5\u51b5\u9996\u5148 \\(a_{11},a_{12},a_{21},a_{22}\\) \u7684 \u7edd\u5bf9\u503c\u76f8\u7b49 \uff0c\u5176\u6b21\u5bf9\u4e8e\u7b26\u53f7\u6765\u8bf4 \u8981\u4e48\u4e24\u884c\u7684\u7b26\u53f7\u4e0d\u540c\uff0c\u8981\u4e48\u4e24\u5217\u7684\u7b26\u53f7\u4e0d\u540c \u8fd9\u91cc\u7ed9\u51fa\u4e24\u884c\u7b26\u53f7\u4e0d\u540c\u7684\u60c5\u51b5\u4e0b\u7684\u7ed3\u679c\u3002 \\[\\begin{pmatrix} a(b_{1}+b_{2}) \\\\ -a(b_{1}+b_{2})\\end{pmatrix}\\] \u53ef\u4ee5\u53d1\u73b0\u6211\u4eec\u4e5f\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e00\u6b21\u77e9\u9635\u4e58\u6cd5\u3002 3rd \u7b2c\u4e09\u79cd\u60c5\u51b5\u5206\u5757\u540e\u7684\u77e9\u9635\u8981\u4e48\u662f\u4e0a\u4e09\u89d2\u77e9\u9635\uff0c\u8981\u4e48\u662f\u4e0b\u4e09\u89d2\u77e9\u9635\uff0c\u4e14\u77e9\u9635\u4e0d\u4f4d\u4e8e\u5bf9\u89d2\u7ebf\u4e0a\u7684\u975e\u96f6\u5143\u7edd\u5bf9\u503c\u7b49\u4e8e\u5bf9\u89d2\u7ebf\u4e4b\u5dee\u3002 \u5f62\u5982 \\(\\begin{pmatrix}a_{1}& a_{1}-a_{2} \\\\ 0 & a_{2}\\end{pmatrix}\\) \u53ef\u4ee5\u53d1\u73b0\u8fd9\u79cd\u60c5\u51b5\u4e0b\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e24\u6b21\u6b21\u77e9\u9635\u4e58\u6cd5\u3002 \\[\\begin{pmatrix} a_{1}(b_{1}+b_{2}) - a_{2}b_{2} \\\\ a_{2}b_{2}\\end{pmatrix}\\] \u4e58\u6cd5\u7ec4\u7684\u77e9\u9635\u8868\u793a\u65b9\u6cd5 \u91cd\u65b0\u56de\u5230\u95ee\u9898\u5f00\u59cb\uff0c\u6211\u4eec\u8981\u8ba1\u7b97\u4e24\u4e2a\u65b9\u9635\u76f8\u4e58\uff0c\u8bb0\u4e3a \\[\\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\times \\begin{pmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\end{pmatrix} = \\begin{pmatrix} C_{11} & C_{12} \\\\ C_{21} & C_{22} \\end{pmatrix}\\] \u663e\u7136 \\[C_{11} = A_{11}B_{11} + A_{12}B_{21} \\\\ C_{12}=A_{11}B_{12}+A_{12}B_{22} \\\\ C_{21}=A_{21}B_{11}+A_{22}B_{21} \\\\ C_{22}=A_{21}B_{12}+A_{22}B_{22}\\] \u6211\u4eec\u8981\u7684\u5176\u5b9e\u662f\u8fd9\u56db\u4e2a\u5206\u91cf\u4e8e\u662f\u73b0\u5728\u5c06\u7ed3\u679c\u5c55\u5e73\uff0c\u5982\u4e0b \\[\\begin{pmatrix} C_{11} \\\\ C_{12} \\\\ C_{21} \\\\ C_{22}\\end{pmatrix} = \\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix}\\begin{pmatrix} B_{11} \\\\ B_{21} \\\\ B_{12} \\\\ B_{22}\\end{pmatrix}\\] \u4e0b\u4e00\u6b65\u662f\u5c06\u4e2d\u95f4\u8fd9\u4e2a\u5927\u7684\u77e9\u9635\u7528\u4e0a\u97623\u79cdsmall case\u62c6\u5f00\u3002 \u5b9e\u6d4b\u8fd9\u91cc\u62c6\u5176\u5b9e\u4e5f\u6709\u6280\u5de7\uff0c\u5fc5\u987b\u6311\u9009\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\uff0c\u6211\u8bd5\u4e86\u4e00\u6b21\u5728\u4e00\u884c\u6216\u4e00\u5217\u4e0a\u7684\u65f6\u5019\u5e76\u4e0d\u80fd\u7ee7\u7eed\u5316\u7b80\uff08\u4e5f\u53ef\u80fd\u662f\u6211sb\u4e86\uff0c\u603b\u4e4b\u6211\u653e\u5728\u6700\u540e\u4e86\uff0c\u6b22\u8fce\u5c1d\u8bd5\u6784\u9020\uff09 \\[\\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix}A_{11} & -A_{11} & 0 & 0 \\\\ A_{11} & -A_{11} & 0 & 0 \\\\ 0 & 0 & -A_{22} & A_{22} \\\\ 0 & 0 & -A_{22} & A_{22}\\end{pmatrix} + \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{22} & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix}\\] \u5bf9\u4e8e\u5de6\u4fa7\u7684\u77e9\u9635\u518d\u8fdb\u884c\u5206\u5757\u540e\uff08\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u4fbf\u6210\u4e3a\u4e862\u4e2acase2\uff09\u53ef\u4ee5\u901a\u8fc72\u6b21\u4e58\u6cd5\u5f97\u5230\u7ed3\u679c\u3002 \u800c\u5bf9\u4e8e\u53f3\u4fa7\u7684\u77e9\u9635\u3002 \\[ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{22} & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix} = \\\\ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & 0 & -A_{11}-A_{22} & 0 \\\\ 0 & -A_{11}-A_{22} & 0 & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix}+\\begin{pmatrix}0 & 0 & 0& 0 \\\\ 0 & A_{11}+A_{22} & A_{11}+A_{22} & 0 \\\\ 0 & A_{11}+A_{22} & A_{11}+A_{22} & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\] \u5176\u4e2d\u53f3\u4fa7\u7684\u77e9\u9635\u5bf9\u5e94\u4e8ecase1\uff0c\u53ea\u9700\u8981\u4e00\u6b21\u4e58\u6cd5\u5c31\u597d\u4e86 \u5bf9\u4e8e\u7b49\u53f7\u53f3\u4fa7\u7b2c\u4e00\u4e2a\u77e9\u9635\u6765\u8bf4\u53ef\u4ee5\u5206\u6210\u4e24\u4e2acase3 \u5373 \\[\\begin{pmatrix}A_{22}-A_{11} & -A_{11}-A_{22} \\\\0 & A_{21} + 22\\end{pmatrix}, \\begin{pmatrix}A_{12}+A_{11} & 0 \\\\ -A_{11}-A_{22} & A_{12}-A_{22}\\end{pmatrix}\\] \u5468\u56f4\u76840\u5c31\u8865\u4e0d\u4e86 \u603b\u4e4b\u5bf9\u4e8e\u672c\u8282\u4e00\u5f00\u59cb\u7684\u5927\u77e9\u9635\u6765\u8bf4\u53ef\u4ee5\u5206\u89e3\u6210\u8fd9\u4e48\u51e0\u4e2a\u77e9\u9635\uff0c\u4e00\u79cd\u8fdb\u884c7\u6b21\u4e58\u6cd5\u5c31\u53ef\u4ee5\u5f97\u5230\u7ed3\u679c\u3002 \u53c2\u8003\u6587\u732e https://ccjou.wordpress.com/2013/06/04/%E5%88%86%E6%B2%BB%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95%E2%94%80%E2%94%80strassen-%E6%BC%94%E7%AE%97%E6%B3%95/ \u9644\u5f55 \\[\\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix}A_{11} & -A_{11} & 0 & 0 \\\\ A_{11} & -A_{11} & 0 & 0 \\\\ 0 & 0 & -A_{12} & A_{12} \\\\ 0 & 0 & -A_{12} & A_{12}\\end{pmatrix} + \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{12} & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix}\\] \u5bf9\u4e8e\u5de6\u4fa7\u7684\u77e9\u9635\u518d\u8fdb\u884c\u5206\u5757\u540e\uff08\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u4fbf\u6210\u4e3a\u4e862\u4e2acase2\uff09\u53ef\u4ee5\u901a\u8fc72\u6b21\u4e58\u6cd5\u5f97\u5230\u7ed3\u679c\u3002 \u800c\u5bf9\u4e8e\u53f3\u4fa7\u7684\u77e9\u9635\u3002 \\[ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{12} & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix} = \\\\ \\begin{pmatrix}0 & 0 & -A_{11}-A_{12} & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & -A_{11}-A_{12} & 0 & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix}+\\begin{pmatrix}0 & A_{12}+A_{11} & A_{12}+A_{11}& 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & A_{11}+A_{12} & A_{11}+A_{12} & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\]","title":"StrassenAlgorithm"},{"location":"blog/2021/StrassenAlgorithm/#strassen-algorithm","text":"\u6b64\u5904\u6307\u7684\u662f\u8ba1\u7b97\u77e9\u9635\u4e58\u6cd5\u7684\u90a3\u4e2aStrassen\u7b97\u6cd5\u3002 \u672c\u6587\u5047\u8bbe\u4f60\u4e86\u89e3Strassen\u7b97\u6cd5\u7684\u6d41\u7a0b","title":"Strassen Algorithm"},{"location":"blog/2021/StrassenAlgorithm/#_1","text":"\u6211\u4eec\u4e8b\u540e\u5f97\u77e5\u8fd9\u79cd\u7b97\u6cd5\u662f\u5c06\u539f\u6709\u7684 \\(8\\) \u7684\u4e58\u6cd5\u7ed3\u679c\u538b\u7f29\u6210\u4e86 \\(7\\) \u4e2a\u3002 \u6211\u4eec\u9996\u5148\u6765\u7ea6\u5b9a\u4e09\u79cdsmall case","title":"\u63a8\u5bfc"},{"location":"blog/2021/StrassenAlgorithm/#3-small-case","text":"3\u79cdsmall case\u90fd\u662f\u7ecf\u8fc7\u5206\u6210 \u5927\u5c0f\u76f8\u540c \u7684\u5757\uff0c\u5f62\u6210\u77e9\u9635\u4e58\u4e00\u4e2a\u5411\u91cf\u7684\u5f62\u5f0f\u3002 \u5f62\u5982\u4e0b\u9762\u7684\u6837\u5b50 \\[\\begin{pmatrix}a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{pmatrix}\\begin{pmatrix} b_{1} \\\\ b_{2}\\end{pmatrix}\\]","title":"3\u79cd small case"},{"location":"blog/2021/StrassenAlgorithm/#1st","text":"\u7b2c\u4e00\u79cd\u4e3a \\(a_{11},a_{12},a_{21},a_{22}\\) \u90fd\u76f8\u7b49\uff0c\u8fd9\u4e2a\u65f6\u5019\u4e58\u6cd5\u7ed3\u679c\u5c31\u662f \\[\\begin{pmatrix} a(b_{1}+b_{2}) \\\\ a(b_{1}+b_{2})\\end{pmatrix}\\] \u663e\u7136\u5bf9\u4e8e\u8fd9\u79cd\u60c5\u51b5\u6211\u4eec\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e00\u6b21\u77e9\u9635\u4e58\u6cd5\u5c31\u597d\u4e86","title":"1st"},{"location":"blog/2021/StrassenAlgorithm/#2nd","text":"\u7b2c\u4e8c\u79cd\u60c5\u51b5\u9996\u5148 \\(a_{11},a_{12},a_{21},a_{22}\\) \u7684 \u7edd\u5bf9\u503c\u76f8\u7b49 \uff0c\u5176\u6b21\u5bf9\u4e8e\u7b26\u53f7\u6765\u8bf4 \u8981\u4e48\u4e24\u884c\u7684\u7b26\u53f7\u4e0d\u540c\uff0c\u8981\u4e48\u4e24\u5217\u7684\u7b26\u53f7\u4e0d\u540c \u8fd9\u91cc\u7ed9\u51fa\u4e24\u884c\u7b26\u53f7\u4e0d\u540c\u7684\u60c5\u51b5\u4e0b\u7684\u7ed3\u679c\u3002 \\[\\begin{pmatrix} a(b_{1}+b_{2}) \\\\ -a(b_{1}+b_{2})\\end{pmatrix}\\] \u53ef\u4ee5\u53d1\u73b0\u6211\u4eec\u4e5f\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e00\u6b21\u77e9\u9635\u4e58\u6cd5\u3002","title":"2nd"},{"location":"blog/2021/StrassenAlgorithm/#3rd","text":"\u7b2c\u4e09\u79cd\u60c5\u51b5\u5206\u5757\u540e\u7684\u77e9\u9635\u8981\u4e48\u662f\u4e0a\u4e09\u89d2\u77e9\u9635\uff0c\u8981\u4e48\u662f\u4e0b\u4e09\u89d2\u77e9\u9635\uff0c\u4e14\u77e9\u9635\u4e0d\u4f4d\u4e8e\u5bf9\u89d2\u7ebf\u4e0a\u7684\u975e\u96f6\u5143\u7edd\u5bf9\u503c\u7b49\u4e8e\u5bf9\u89d2\u7ebf\u4e4b\u5dee\u3002 \u5f62\u5982 \\(\\begin{pmatrix}a_{1}& a_{1}-a_{2} \\\\ 0 & a_{2}\\end{pmatrix}\\) \u53ef\u4ee5\u53d1\u73b0\u8fd9\u79cd\u60c5\u51b5\u4e0b\u53ea\u9700\u8981 \u5b9e\u9645 \u8ba1\u7b97\u4e24\u6b21\u6b21\u77e9\u9635\u4e58\u6cd5\u3002 \\[\\begin{pmatrix} a_{1}(b_{1}+b_{2}) - a_{2}b_{2} \\\\ a_{2}b_{2}\\end{pmatrix}\\]","title":"3rd"},{"location":"blog/2021/StrassenAlgorithm/#_2","text":"\u91cd\u65b0\u56de\u5230\u95ee\u9898\u5f00\u59cb\uff0c\u6211\u4eec\u8981\u8ba1\u7b97\u4e24\u4e2a\u65b9\u9635\u76f8\u4e58\uff0c\u8bb0\u4e3a \\[\\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} \\times \\begin{pmatrix} B_{11} & B_{12} \\\\ B_{21} & B_{22} \\end{pmatrix} = \\begin{pmatrix} C_{11} & C_{12} \\\\ C_{21} & C_{22} \\end{pmatrix}\\] \u663e\u7136 \\[C_{11} = A_{11}B_{11} + A_{12}B_{21} \\\\ C_{12}=A_{11}B_{12}+A_{12}B_{22} \\\\ C_{21}=A_{21}B_{11}+A_{22}B_{21} \\\\ C_{22}=A_{21}B_{12}+A_{22}B_{22}\\] \u6211\u4eec\u8981\u7684\u5176\u5b9e\u662f\u8fd9\u56db\u4e2a\u5206\u91cf\u4e8e\u662f\u73b0\u5728\u5c06\u7ed3\u679c\u5c55\u5e73\uff0c\u5982\u4e0b \\[\\begin{pmatrix} C_{11} \\\\ C_{12} \\\\ C_{21} \\\\ C_{22}\\end{pmatrix} = \\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix}\\begin{pmatrix} B_{11} \\\\ B_{21} \\\\ B_{12} \\\\ B_{22}\\end{pmatrix}\\] \u4e0b\u4e00\u6b65\u662f\u5c06\u4e2d\u95f4\u8fd9\u4e2a\u5927\u7684\u77e9\u9635\u7528\u4e0a\u97623\u79cdsmall case\u62c6\u5f00\u3002 \u5b9e\u6d4b\u8fd9\u91cc\u62c6\u5176\u5b9e\u4e5f\u6709\u6280\u5de7\uff0c\u5fc5\u987b\u6311\u9009\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5143\u7d20\uff0c\u6211\u8bd5\u4e86\u4e00\u6b21\u5728\u4e00\u884c\u6216\u4e00\u5217\u4e0a\u7684\u65f6\u5019\u5e76\u4e0d\u80fd\u7ee7\u7eed\u5316\u7b80\uff08\u4e5f\u53ef\u80fd\u662f\u6211sb\u4e86\uff0c\u603b\u4e4b\u6211\u653e\u5728\u6700\u540e\u4e86\uff0c\u6b22\u8fce\u5c1d\u8bd5\u6784\u9020\uff09 \\[\\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix}A_{11} & -A_{11} & 0 & 0 \\\\ A_{11} & -A_{11} & 0 & 0 \\\\ 0 & 0 & -A_{22} & A_{22} \\\\ 0 & 0 & -A_{22} & A_{22}\\end{pmatrix} + \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{22} & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix}\\] \u5bf9\u4e8e\u5de6\u4fa7\u7684\u77e9\u9635\u518d\u8fdb\u884c\u5206\u5757\u540e\uff08\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u4fbf\u6210\u4e3a\u4e862\u4e2acase2\uff09\u53ef\u4ee5\u901a\u8fc72\u6b21\u4e58\u6cd5\u5f97\u5230\u7ed3\u679c\u3002 \u800c\u5bf9\u4e8e\u53f3\u4fa7\u7684\u77e9\u9635\u3002 \\[ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{22} & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix} = \\\\ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & 0 & -A_{11}-A_{22} & 0 \\\\ 0 & -A_{11}-A_{22} & 0 & A_{12}-A_{22} \\\\ 0 & 0 & A_{21}+A_{22} & 0\\end{pmatrix}+\\begin{pmatrix}0 & 0 & 0& 0 \\\\ 0 & A_{11}+A_{22} & A_{11}+A_{22} & 0 \\\\ 0 & A_{11}+A_{22} & A_{11}+A_{22} & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\] \u5176\u4e2d\u53f3\u4fa7\u7684\u77e9\u9635\u5bf9\u5e94\u4e8ecase1\uff0c\u53ea\u9700\u8981\u4e00\u6b21\u4e58\u6cd5\u5c31\u597d\u4e86 \u5bf9\u4e8e\u7b49\u53f7\u53f3\u4fa7\u7b2c\u4e00\u4e2a\u77e9\u9635\u6765\u8bf4\u53ef\u4ee5\u5206\u6210\u4e24\u4e2acase3 \u5373 \\[\\begin{pmatrix}A_{22}-A_{11} & -A_{11}-A_{22} \\\\0 & A_{21} + 22\\end{pmatrix}, \\begin{pmatrix}A_{12}+A_{11} & 0 \\\\ -A_{11}-A_{22} & A_{12}-A_{22}\\end{pmatrix}\\] \u5468\u56f4\u76840\u5c31\u8865\u4e0d\u4e86 \u603b\u4e4b\u5bf9\u4e8e\u672c\u8282\u4e00\u5f00\u59cb\u7684\u5927\u77e9\u9635\u6765\u8bf4\u53ef\u4ee5\u5206\u89e3\u6210\u8fd9\u4e48\u51e0\u4e2a\u77e9\u9635\uff0c\u4e00\u79cd\u8fdb\u884c7\u6b21\u4e58\u6cd5\u5c31\u53ef\u4ee5\u5f97\u5230\u7ed3\u679c\u3002","title":"\u4e58\u6cd5\u7ec4\u7684\u77e9\u9635\u8868\u793a\u65b9\u6cd5"},{"location":"blog/2021/StrassenAlgorithm/#_3","text":"https://ccjou.wordpress.com/2013/06/04/%E5%88%86%E6%B2%BB%E7%9F%A9%E9%99%A3%E4%B9%98%E6%B3%95%E2%94%80%E2%94%80strassen-%E6%BC%94%E7%AE%97%E6%B3%95/","title":"\u53c2\u8003\u6587\u732e"},{"location":"blog/2021/StrassenAlgorithm/#_4","text":"\\[\\begin{pmatrix} A_{11} & A_{12} & 0 & 0 \\\\ A_{21} & A_{22} & 0 & 0 \\\\ 0 & 0 & A_{11} & A_{12} \\\\ 0 & 0 & A_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix}A_{11} & -A_{11} & 0 & 0 \\\\ A_{11} & -A_{11} & 0 & 0 \\\\ 0 & 0 & -A_{12} & A_{12} \\\\ 0 & 0 & -A_{12} & A_{12}\\end{pmatrix} + \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{12} & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix}\\] \u5bf9\u4e8e\u5de6\u4fa7\u7684\u77e9\u9635\u518d\u8fdb\u884c\u5206\u5757\u540e\uff08\u5de6\u4e0a\u89d2\u548c\u53f3\u4e0b\u89d2\uff0c\u4fbf\u6210\u4e3a\u4e862\u4e2acase2\uff09\u53ef\u4ee5\u901a\u8fc72\u6b21\u4e58\u6cd5\u5f97\u5230\u7ed3\u679c\u3002 \u800c\u5bf9\u4e8e\u53f3\u4fa7\u7684\u77e9\u9635\u3002 \\[ \\begin{pmatrix}0 & A_{12}+A_{11} & 0 & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & 0 & A_{11}+A_{12} & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix} = \\\\ \\begin{pmatrix}0 & 0 & -A_{11}-A_{12} & 0 \\\\ A_{21}-A_{11} & A_{22}+A_{11} & 0 & 0 \\\\ 0 & -A_{11}-A_{12} & 0 & 0 \\\\ 0 & 0 & A_{21}+A_{12} & A_{22}-A_{12}\\end{pmatrix}+\\begin{pmatrix}0 & A_{12}+A_{11} & A_{12}+A_{11}& 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & A_{11}+A_{12} & A_{11}+A_{12} & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix}\\]","title":"\u9644\u5f55"},{"location":"blog/2021/X3C-1%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%88%92%E5%88%86%E9%97%AE%E9%A2%98%E7%9A%84NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/","text":"\u8001\u5e08\u4e0a\u8bfe\u7559\u7684\u4f5c\u4e1a \u8fd8\u86ee\u7b80\u5355\u7684\uff08 X3C-1\u95ee\u9898 \u9996\u5148\u4f60\u9700\u8981\u77e5\u9053\u4ec0\u4e48\u662fX3C\u95ee\u9898\uff08\u5047\u88c5\u4f60\u77e5\u9053\u4e86\uff0c\u5176\u5b9e\u662f\u6211\u61d2\u5f97\u5199\u4e86 X3C-1\u95ee\u9898\u662f\u4efb\u610f\u4e24\u4e2a\u5143\u7d20\u7684\u4ea4\u7684\u5927\u5c0f\u5c0f\u4e8e\u7b49\u4e8e1 \u8bc1\u660e \u6211\u4eec\u5c1d\u8bd5\u7528X3C\u6765\u5f52\u7ea6\u5230X3C-1\u6765\u8bc1\u660e\u8fd9\u4ef6\u4e8b\u60c5\u3002 \u5176\u5b9e\u86ee\u7b80\u5355\u7684\uff0c\u5047\u8bbe \\((a,b,c)\\) \u662fX3C\u96c6\u5408\u7684\u4e00\u4e2a\u5143\u7d20\u3002 \u6211\u4eec\u628a\u5b83\u62c6\u6210\u4ee5\u4e0b5\u4e2a\u5143\u7d20 \\[(a, e1, e2) \\\\ (b, e3, e4) \\\\ (c, e5, e6) \\\\ (e1, e3, e5) \\\\ (e2, e4, e6)\\] \u6b63\u786e\u6027\u663e\u7136\uff08 \u5e7f\u4e49\u5212\u5206\u95ee\u9898 \u72ed\u4e49\u7684\u5212\u5206\u95ee\u9898\u662f\u5c06\u96c6\u5408\u91cc\u7684\u5143\u7d20\u5212\u5206\u6210\u4e24\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u7684\u548c\u76f8\u7b49 \u800c\u5e7f\u4e49\u5212\u5206\u95ee\u9898\u4fbf\u662f\u4f7f\u5f97\u4e24\u4e2a\u90e8\u5206\u4fdd\u63011:2\u7684\u5173\u7cfb \u8bc1\u660e \u5c1d\u8bd5\u4ece\u5212\u5206\u95ee\u9898\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5047\u8bbe\u539f\u96c6\u5408\u4e3aS \u52a0\u5165 \\(\\frac{3}{2}S\\) \u4e0e \\(\\frac{7}{2}S\\) \u4e24\u4e2a\u5143\u7d20\uff0c\u6b63\u786e\u6027\u663e\u7136\uff08","title":"X3C-1\u4e0e\u5e7f\u4e49\u5212\u5206\u95ee\u9898\u7684NP\u5b8c\u5168\u6027\u8bc1\u660e"},{"location":"blog/2021/X3C-1%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%88%92%E5%88%86%E9%97%AE%E9%A2%98%E7%9A%84NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#x3c-1","text":"\u9996\u5148\u4f60\u9700\u8981\u77e5\u9053\u4ec0\u4e48\u662fX3C\u95ee\u9898\uff08\u5047\u88c5\u4f60\u77e5\u9053\u4e86\uff0c\u5176\u5b9e\u662f\u6211\u61d2\u5f97\u5199\u4e86 X3C-1\u95ee\u9898\u662f\u4efb\u610f\u4e24\u4e2a\u5143\u7d20\u7684\u4ea4\u7684\u5927\u5c0f\u5c0f\u4e8e\u7b49\u4e8e1","title":"X3C-1\u95ee\u9898"},{"location":"blog/2021/X3C-1%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%88%92%E5%88%86%E9%97%AE%E9%A2%98%E7%9A%84NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#_1","text":"\u6211\u4eec\u5c1d\u8bd5\u7528X3C\u6765\u5f52\u7ea6\u5230X3C-1\u6765\u8bc1\u660e\u8fd9\u4ef6\u4e8b\u60c5\u3002 \u5176\u5b9e\u86ee\u7b80\u5355\u7684\uff0c\u5047\u8bbe \\((a,b,c)\\) \u662fX3C\u96c6\u5408\u7684\u4e00\u4e2a\u5143\u7d20\u3002 \u6211\u4eec\u628a\u5b83\u62c6\u6210\u4ee5\u4e0b5\u4e2a\u5143\u7d20 \\[(a, e1, e2) \\\\ (b, e3, e4) \\\\ (c, e5, e6) \\\\ (e1, e3, e5) \\\\ (e2, e4, e6)\\] \u6b63\u786e\u6027\u663e\u7136\uff08","title":"\u8bc1\u660e"},{"location":"blog/2021/X3C-1%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%88%92%E5%88%86%E9%97%AE%E9%A2%98%E7%9A%84NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#_2","text":"\u72ed\u4e49\u7684\u5212\u5206\u95ee\u9898\u662f\u5c06\u96c6\u5408\u91cc\u7684\u5143\u7d20\u5212\u5206\u6210\u4e24\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u7684\u548c\u76f8\u7b49 \u800c\u5e7f\u4e49\u5212\u5206\u95ee\u9898\u4fbf\u662f\u4f7f\u5f97\u4e24\u4e2a\u90e8\u5206\u4fdd\u63011:2\u7684\u5173\u7cfb","title":"\u5e7f\u4e49\u5212\u5206\u95ee\u9898"},{"location":"blog/2021/X3C-1%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%88%92%E5%88%86%E9%97%AE%E9%A2%98%E7%9A%84NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/#_3","text":"\u5c1d\u8bd5\u4ece\u5212\u5206\u95ee\u9898\u5f52\u7ea6\u5230\u8fd9\u4e2a\u95ee\u9898\u3002 \u5047\u8bbe\u539f\u96c6\u5408\u4e3aS \u52a0\u5165 \\(\\frac{3}{2}S\\) \u4e0e \\(\\frac{7}{2}S\\) \u4e24\u4e2a\u5143\u7d20\uff0c\u6b63\u786e\u6027\u663e\u7136\uff08","title":"\u8bc1\u660e"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/","tags":["CMake"],"text":"cmake\u7684\u5751\u3002\u3002\u3002 cmake\u5e76\u4e0d\u5728mingw\u4e2d \u55ef\uff0c\u9700\u8981\u91cd\u65b0\u5b89\u88c5\u3002\u3002 vscode terminal\u7684\u73af\u5883\u53d8\u91cf\u9700\u8981\u91cd\u542fvscode\u624d\u80fd\u751f\u6548 mingw \u4e2d\u7684\u201cmake\u201d \u53eb\u505a\u201cmingw32-make\u201d cmake \u9ed8\u8ba4\u4f7f\u7528vs\u7684\u90a3\u5957\u5de5\u5177\u6808 \u4e5f\u5c31\u662f\u8bf4\u9700\u8981 cmake -G \"MinGW Makefiles\" [directoty] \u6ce8\u610f\u8fd9\u91cc\u5927\u5c0f\u5199\u654f\u611f! \u53c2\u6570\u6ca1\u6709\u9017\u53f7\u5206\u9694 \u5e38\u7528\u6307\u4ee4&\u529f\u80fd \u8bbe\u7f6e\u53d8\u91cf # set(Key Value) set(ABAB 1) # \u9700\u8981\u4f7f\u7528${ABAB}\u6765\u83b7\u53d6\u8fd9\u4e2a\u53d8\u91cf\u7684\u503c \u5e38\u7528\u53d8\u91cf PROJECT_SOURCE_DIR \u5f53\u524d\u5de5\u7a0b\u7684\u6700\u4e0a\u5c42\u76ee\u5f55 PROJECT_BINARY_DIR \u5f53\u524d\u5de5\u7a0b\u7684\u6784\u5efa\u76ee\u5f55\uff0c\u4e00\u822c\u6307\u6267\u884ccmake\u7684pwd \u6dfb\u52a0\u5934\u6587\u4ef6 include_directories() \u590d\u5236\u66ff\u6362\u6587\u4ef6 configure_file(<input>, <output>) \u6b64\u547d\u4ee4\u53ef\u4ee5\u5c06input\u590d\u5236\u5230output\u540c\u65f6\u66ff\u6362\u6587\u4ef6\u4e2d@VARIABLE@\u7684\u503c\uff0c\u66ff\u6362\u6210\u4e3a\u53d8\u91cf \u9012\u5f52CMakeLists.txt #\u6dfb\u52a0 add_subdirectory() \u751f\u6210\u94fe\u63a5\u6587\u4ef6 add_library() #\u7528\u6cd5\u57fa\u672c\u4e0eadd_executable()\u76f8\u540c link\u94fe\u63a5\u6587\u4ef6 target_link_libraries() #\u7528\u6cd5\u57fa\u672c\u4e0eadd_executable()\u76f8\u540c \u751f\u6210\u9009\u9879 if() endif() option(FLAG \"help text\" <ON/OFF>) # \u4f7f\u7528\u65f6\u53ef\u4ee5\u8fdb\u884c\u547d\u4ee4\u884c\u4f20\u53c2","title":"cmake\u7684\u5751"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#cmake","text":"","title":"cmake\u7684\u5751\u3002\u3002\u3002"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#cmakemingw","text":"\u55ef\uff0c\u9700\u8981\u91cd\u65b0\u5b89\u88c5\u3002\u3002","title":"cmake\u5e76\u4e0d\u5728mingw\u4e2d"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#vscode-terminalvscode","text":"","title":"vscode terminal\u7684\u73af\u5883\u53d8\u91cf\u9700\u8981\u91cd\u542fvscode\u624d\u80fd\u751f\u6548"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#mingw-make-mingw32-make","text":"","title":"mingw \u4e2d\u7684\u201cmake\u201d \u53eb\u505a\u201cmingw32-make\u201d"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#cmake-vs","text":"\u4e5f\u5c31\u662f\u8bf4\u9700\u8981 cmake -G \"MinGW Makefiles\" [directoty] \u6ce8\u610f\u8fd9\u91cc\u5927\u5c0f\u5199\u654f\u611f!","title":"cmake \u9ed8\u8ba4\u4f7f\u7528vs\u7684\u90a3\u5957\u5de5\u5177\u6808"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_1","text":"","title":"\u53c2\u6570\u6ca1\u6709\u9017\u53f7\u5206\u9694"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_2","text":"","title":"\u5e38\u7528\u6307\u4ee4&amp;\u529f\u80fd"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_3","text":"# set(Key Value) set(ABAB 1) # \u9700\u8981\u4f7f\u7528${ABAB}\u6765\u83b7\u53d6\u8fd9\u4e2a\u53d8\u91cf\u7684\u503c","title":"\u8bbe\u7f6e\u53d8\u91cf"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_4","text":"PROJECT_SOURCE_DIR \u5f53\u524d\u5de5\u7a0b\u7684\u6700\u4e0a\u5c42\u76ee\u5f55 PROJECT_BINARY_DIR \u5f53\u524d\u5de5\u7a0b\u7684\u6784\u5efa\u76ee\u5f55\uff0c\u4e00\u822c\u6307\u6267\u884ccmake\u7684pwd","title":"\u5e38\u7528\u53d8\u91cf"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_5","text":"include_directories()","title":"\u6dfb\u52a0\u5934\u6587\u4ef6"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_6","text":"configure_file(<input>, <output>) \u6b64\u547d\u4ee4\u53ef\u4ee5\u5c06input\u590d\u5236\u5230output\u540c\u65f6\u66ff\u6362\u6587\u4ef6\u4e2d@VARIABLE@\u7684\u503c\uff0c\u66ff\u6362\u6210\u4e3a\u53d8\u91cf","title":"\u590d\u5236\u66ff\u6362\u6587\u4ef6"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#cmakeliststxt","text":"#\u6dfb\u52a0 add_subdirectory()","title":"\u9012\u5f52CMakeLists.txt"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_7","text":"add_library() #\u7528\u6cd5\u57fa\u672c\u4e0eadd_executable()\u76f8\u540c","title":"\u751f\u6210\u94fe\u63a5\u6587\u4ef6"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#link","text":"target_link_libraries() #\u7528\u6cd5\u57fa\u672c\u4e0eadd_executable()\u76f8\u540c","title":"link\u94fe\u63a5\u6587\u4ef6"},{"location":"blog/2021/cmake%E7%9A%84%E5%9D%91/#_8","text":"if() endif() option(FLAG \"help text\" <ON/OFF>) # \u4f7f\u7528\u65f6\u53ef\u4ee5\u8fdb\u884c\u547d\u4ee4\u884c\u4f20\u53c2","title":"\u751f\u6210\u9009\u9879"},{"location":"blog/2021/edge-decomposition/","text":"Edge Decomposition NP-Complete\u7684\u8bb0\u5f55\u624b\u7a3f","title":"edge-decomposition"},{"location":"blog/2021/push-relabel-algorithm/","text":"push relabel algorithm \u57fa\u672c\u7406\u8bba(\u256f\u2035\u25a1\u2032)\u256f\ufe35\u253b\u2501\u253b {%pdf ./push-relabel_algorithn.pdf %}","title":"push-relabel_algorithm"},{"location":"blog/2021/%E4%BA%8C%E7%BB%B4%E6%9C%80%E7%9F%AD%E8%B7%AFNP-complete/","text":"\u5c1d\u8bd5\u7528\u4e8c\u5212\u5206\u95ee\u9898\u5f52\u7ea6\u5230\u4e8c\u7ef4\u6700\u77ed\u8def\u95ee\u9898\u3002 \u5047\u8bbe\u6709\u4e00\u4e2a\u96c6\u5408 \\(S\\) , \u5b9a\u4e49\u5176\u4e2d\u7684\u5143\u7d20\u4e3a \\(a_{i}\\) \u6743\u51fd\u6570\u4e3a \\(w: S \\rightarrow R\\) \u5b9a\u4e49\u9876\u70b9\u96c6\u5408\u4e3a \\(N = \\{(x,0), (0,x) | \\forall x \\in S\\}\\) \u8fb9\u96c6 \\(E = \\{((a_{i},0), (a_{i+1},0)),((0,a_{i}), (a_{i+1},0)),((0,a_{i}), (0,a_{i+1})),((a_{i},0), (0,a_{i+1}))| 1 \\leq i < |S|\\}\\) \u5b9a\u4e49 \\(\\large V = (\\frac{\\sum w(a_{i})}{2}, \\frac{\\sum w(a_{i})}{2})\\) \\[\\sum\\]","title":"\u4e8c\u7ef4\u6700\u77ed\u8defNP-complete"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/","text":"\u60f3\u8bd5\u8bd5\u770b\u81ea\u5df1\u80fd\u4e0d\u80fd\u5199\u51fa\u6c11\u79d1\u4e00\u6837\u7684\u6587\u98ce. \u63b7\u8272\u5b50, \u6295\u786c\u5e01\u53ef\u4ee5\u8bf4\u662f\u6700\u5148\u8fdb\u5165\u610f\u8bc6\u4e2d\u7684\u968f\u673a\u4e8b\u4ef6, \u4e00\u65b9\u9762\u4e0a\u968f\u673a\u65b9\u6cd5\u8ba9\u6211\u4eec\u62e5\u6709\u4e86\u4e00\u79cd\u53ef\u4ee5\u540c\u65f6\u5ba1\u89c6\u6240\u6709\u60c5\u51b5\u7684\u65b9\u6cd5, \u53e6\u4e00\u65b9\u9762\u968f\u673a\u65b9\u6cd5\u4e5f\u7ed9\u4e86\u5e38\u89c4\u975e\u968f\u5373\u65b9\u6cd5\u4e00\u79cd\u65b0\u7684\u5ba1\u89c6\u65b9\u6cd5. \u5207\u5c14\u8bfa\u592b\u754c \u5982\u679c \\(X_{1}, .., X_{n}\\) \u662f \\(\\{0,1\\}\\) \u4e0a\u4e24\u4e24\u72ec\u7acb\u7684\u968f\u673a\u53d8\u91cf, \u4e14 \\(\\mu = \\sum_{i=1}^{n}E(X_{i})\\) , \u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684 \\(\\delta >0\\) \u6709 \\[P\\{\\sum_{i=1}^{n}X_{i} \\geq (1 + \\delta)\\mu\\} \\leq (\\frac{e^{\\delta}}{(1+\\delta)^{(1+\\delta)}})^{\\mu}\\] \\[P\\{\\sum_{i=1}^{n}X_{i} \\geq (1 - \\delta)\\mu\\} \\leq (\\frac{e^{\\delta}}{(1-\\delta)^{(1-\\delta)}})^{\\mu}\\] \u5176\u63a8\u8bba $$P{|\\sum_{i=1}^{n}X_{i} - \\mu| \\geq c\\mu } \\leq 2e^{-\\min {c^{2}/4, c/2}\\mu } $$ \u7b49\u53f7\u53f3\u4fa7\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a\u5173\u4e8e \\(c\\) \u7684\u6307\u6570\u51fd\u6570, \u8fd9\u5c06\u4f1a\u7ed9\u5047\u8bbe\u68c0\u9a8c\u63d0\u4f9b\u6307\u6570\u822c\u7684\u4e0b\u964d\u80fd\u529b. \u4e5f\u5c31\u662f\u8bf4, \u5728\u8fdb\u884c\u5efa\u8bbe\u68c0\u9a8c\u7684\u65f6\u5019, \u9a8c\u8bc1\u547d\u9898\u7684\u6b63\u786e, \u5982\u679c\u6784\u9020\u5408\u7406, \u53ef\u4ee5\u53ea\u4f7f\u7528 \\(log\\) \u7ea7\u522b\u7684\u6570\u636e\u91cf. Bounded Error \u4f5c\u4e3a\u4e0a\u9762\u4f8b\u5b50\u7684\u76f4\u63a5\u5e94\u7528, \u5982\u679c\u6211\u4eec\u62e5\u6709\u4e00\u679a\u671d\u4e0a\u6982\u7387\u4e3a \\(\\rho\\) \u7684\u786c\u5e01, \u5176\u4e2d \\(\\rho > \\frac{1}{2}\\) , \u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684 \\(p=1 - \\frac{1}{2^n}\\) , \u6211\u4eec\u90fd\u53ef\u4ee5\u5728 \\(O(\\log n)\\) \u7684\u65f6\u95f4\u5185\u5f97\u5230\u8fd9\u6837\u4e00\u679a\u786c\u5e01. \\(\\operatorname{BPP}\\) \\(\\operatorname{BPTIME}(O(f(x)))\\) \u4ee3\u8868\u4e86\u80fd\u5728 \\(O(f(x))\\) \u7684\u6982\u7387\u56fe\u7075\u673a\u4e0a\u5224\u5b9a\u7684\u95ee\u9898\u7684\u96c6\u5408. \\(\\operatorname{BPP} = \\bigcup_{i = 0} ^ {\\inf}\\) \\(\\operatorname{BPTIME}(n^{i})\\) \u5219\u4ee3\u8868\u5728\u6982\u7387\u610f\u4e49\u4e0b \\(\\operatorname{P}\\) \u7684\u5bf9\u5e94\u7c7b. \u503c\u5f97\u6ce8\u610f\u7684\u662f, \u8fd9\u91cc\u7684\u8fd0\u884c\u65f6\u95f4, \u662f\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u4e0b\u7684\u6700\u574f\u8fd0\u884c\u65f6\u95f4, \u800c\u51b3\u5b9a\u8fd9\u6837\u4e00\u4e2a\u6982\u7387\u56fe\u7075\u673a\u662f\u5426\u63a5\u53d7\u4e00\u4e2a\u5b57\u7b26\u4e32\u53d6\u51b3\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u8f6c\u79fb\u4e4b\u4e0b, \u63a5\u53d7\u7684\u6982\u7387\u5927\u8fd8\u662f\u62d2\u7edd\u7684\u6982\u7387\u5927, \u5f53\u7136\u7531\u4e8e Bounded error \u7684\u60c5\u51b5\u4e0b, \u8fd9\u91cc\u7684\u6982\u7387\u53ea\u9700\u8981\u5927\u4e8e \\(\\frac{1}{2}\\) \u5c31\u597d\u4e86. \u5982\u679c\u63a5\u53d7\u7684\u6982\u7387\u5b9a\u4e49\u5982\u6b64\"\u677e\", \u90a3\u4e48\u5bf9\u4e8e\u8fd0\u884c\u65f6\u95f4\u5462, \u5b9e\u9645\u4e0a\u5982\u679c\u5c06\u6700\u574f\u65f6\u95f4\u66ff\u6362\u4e3a\u671f\u671b\u65f6\u95f4\u4e5f\u4e0d\u4f1a\u4ea7\u751f \\(\\operatorname{BPP}\\) \u53d1\u751f\u53d8\u5316, \u5f53\u7136\u4ece\u8fd9\u91cc\u5c31\u80fd\u7b80\u5355\u7aa5\u63a2\u51fa\u6982\u7387\u56fe\u7075\u673a\u4e0e\u975e\u786e\u5b9a\u6027\u56fe\u7075\u673a\u7684\u533a\u522b, \u867d\u7136\u5b83\u4eec\u90fd\u5177\u6709\u5ba1\u89c6\u6240\u6709\u53ef\u80fd\u60c5\u51b5\u7684\u80fd\u529b, \u4f46\u6982\u7387\u6027\u56fe\u7075\u673a\u9650\u5b9a\u4e86\u671f\u671b\u7684\u8fd0\u884c\u65f6\u95f4. \u540c\u65f6\u6982\u7387\u56fe\u7075\u673a\u63a5\u53d7\u8f93\u5165, \u53d6\u51b3\u4e8e\u63a5\u53d7\u7684\u60c5\u51b5\u662f\u591a\u662f\u5c11, \u800c\u5e76\u975e\u53ea\u6709\u4e00\u4e2a\u63a5\u53d7\u60c5\u51b5. \u5f88\u5bb9\u6613\u9a8c\u8bc1\u51fa \\(\\operatorname{P} \\subset \\operatorname{BPP}\\) , \u4f46\u662f\u5426\u76f8\u7b49\u4ecd\u7136\u662fOPEN\u7684. \u5f53\u7136\u7531\u4e8e\u7b80\u5355\u7684\u5b9a\u4e49,\u5f88\u5bb9\u6613\u5f97\u5230 \\(\\operatorname{BPP} \\subset \\operatorname{EXP}\\) , \u56e0\u4e3a\u53ef\u4ee5\u5728\u6307\u6570\u65f6\u95f4\u4e4b\u5185\u679a\u4e3e\u6240\u6709\u7684\u968f\u673a\u9009\u62e9. Derandomize \u524d\u6587\u63d0\u5230\u4e86\u5728\u5e38\u89c4\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u5f15\u5165\u6982\u7387, \u53ef\u4ee5\u6539\u53d8\u5ba1\u89c6\u7b97\u6cd5\u7684\u89c2\u70b9, \u4f8b\u5982\u53ef\u4ee5\u5728\u671f\u671b \\(O(n)\\) \u7684\u65f6\u95f4\u5185\u5f97\u5230\u4e00\u4e2a\u6570\u5217\u7684\u7b2c \\(k\\) \u5927, \u4f8b\u5982\u53ef\u4ee5\u5728\u671f\u671b\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5224\u5b9a\u8d28\u6570, \u867d\u7136\u524d\u4e24\u4e2a\u95ee\u9898\u90fd\u5b58\u5728\u66f4\u4f18\u79c0\u7684\u5728\u786e\u5b9a\u6027\u56fe\u7075\u673a\u4e0b\u7684\u5bf9\u5e94\u65b9\u6cd5, \u4f46\u90fd\u663e\u5f97\u66f4\u52a0\u590d\u6742. \u9664\u6b64\u4e4b\u5916\u4e5f\u6709\u66f4\u591a\u5df2\u88ab\u8bc1\u660e\u5c5e\u4e8e \\(\\operatorname{BPP}\\) , \u800c\u4e0d\u77e5\u9053\u662f\u5426\u5c5e\u4e8e \\(\\operatorname{P}\\) \u7684\u95ee\u9898, \u4f8b\u5982\u68c0\u9a8c\u4e00\u4e2a\u591a\u9879\u5f0f\u662f\u5426\u6052\u4e3a0. \u5373\u4f7f\u5982\u6b64\u4eba\u4eec\u4ecd\u7136\u76f8\u4fe1 \\(\\operatorname{P} = \\operatorname{BPP}\\) , \u6216\u8bb8\u662f\u56e0\u4e3a\u5bf9\u4e8e\u4e00\u4e9b\u7b80\u5355\u7684\u6982\u7387\u7b97\u6cd5, \u5b58\u5728\u53ef\u4ee5\u7b80\u5355\u6784\u9020\u51fa\u7684\u786e\u5b9a\u6027\u7b97\u6cd5. \u4f8b\u5982\u5bf9\u4e8eSet Cover \u5b58\u5728\u4e00\u4e2a\u8fd1\u4f3c\u5ea6\u4e3a \\(O(\\ln n)\\) \u7684\u7b97\u6cd5, \u57fa\u4e8e\u6982\u7387\u5bf9LP\u4e2d\u7684\u53d8\u91cf\u8fdb\u884c\u968f\u673a\u8d4b\u503c. \u53ef\u4ee5\u5f88\u7b80\u5355\u7684\u901a\u8fc7\u671f\u671b, \u6765\u53cd\u63a8\u51fa\u6bcf\u4e2a\u51b3\u7b56\u53d8\u91cf\u662f\u591a\u5c11, \u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u53eb\u505a Derandomize. RP and coRP \u4e3a\u4e86\u63a2\u7d22 \\(\\operatorname{P}\\) \u4e0e \\(\\operatorname{BPP}\\) \u4e4b\u95f4\u7684 gap , \u53ef\u4ee5\u66f4\u52a0\u6536\u7d27 \\(\\operatorname{BPP}\\) \u7684\u5b9a\u4e49, \u4f8b\u5982\u4f7f\u4e4b\u5728\u9519\u8bef\u7684\u6982\u7387\u53d8\u6210 0, \u4f7f\u4e4b\u6210\u4e3a \\(\\operatorname{RP}\\) , \u540c\u6837\u5f62\u6210 \\(\\operatorname{coRP}\\) , \u6709\u610f\u601d\u7684\u662f $\\operatorname{ZPP} = \\operatorname{RP} \\bigcap \\operatorname{coRP} $ Key \u4e00\u4e2a\u968f\u673a\u56fe\u7075\u673a\u53ef\u4ee5\u8f6c\u5316\u6210\u4e00\u4e2a\u9664\u4e00\u822c\u7684\u8f93\u5165\u4e4b\u5916\u8fd8\u6709\u4e00\u4e2a\u8f93\u5165\u7684\u4e32\u4e0d\u59a8\u628a\u5b83\u53eb\u505a key \u5427, \u6211\u4e5f\u4e0d\u77e5\u9053\u5e94\u8be5\u53eb\u4f5c\u4ec0\u4e48, \u8fd9\u4e2a key \u51b3\u5b9a\u4e86\u6574\u4e2a\u968f\u673a\u8fc7\u7a0b. \u5728\u8fd9\u6837\u7684\u5b9a\u4e49\u4e4b\u4e0b, \u53ef\u4ee5\u8bc1\u660e\u51fa \\(\\operatorname{BPP} \\subset \\operatorname{P_{/poly}}\\) \u4e0e \\(\\operatorname{BPP} \\subset \\operatorname{PH}\\) , \u66f4\u8fdb\u4e00\u6b65\u6709 \\(\\operatorname{BPP} \\subset \\operatorname{\\sum_{2}^{P}} \\bigcup \\operatorname{\\Pi_{2}^{P}}\\) . \u5b83\u8d77\u7801\u5b58\u5728\u4e8e\u591a\u9879\u5f0f\u5206\u7ea7\u4e4b\u4e2d\u4e86, \u4f46\u7531\u4e8e \\(\\operatorname{BPP}\\) \u57fa\u4e8e\u8bed\u4e49\u7684\u5b9a\u4e49, \u8ba9 \\(\\operatorname{BPP}\\) \u5c42\u7684\u5b8c\u5168\u95ee\u9898\u6bd4\u8f83\u96be\u4ee5\u627e\u5230, \u4e5f\u8ba9\u8fd9\u4e2a\u5c42\u7ea7\u7684\u53d1\u5c55\u6709\u4e86\u4e00\u4e9b\u56f0\u96be. \u4ea4\u4e92\u5f0f\u8bc1\u660e \u96f6\u77e5\u8bc6\u8bc1\u660e\u662f\u4ea4\u4e92\u5f0f\u8bc1\u660e\u4e2d\u7684\u4e00\u4e2a\u5c0f\u90e8\u5206, \u96f6\u77e5\u8bc6\u8bc1\u660e\u53ef\u4ee5\u8ba9\u6211\u4eec\u770b\u5230\u4e00\u4e2a\u80fd\u529b\u4e0d\u5f3a\u7684\u4e2a\u4f53, \u5982\u679c\u53ef\u4ee5\u8ddf\u4e00\u4e2a\u80fd\u529b\u66f4\u5f3a\u7684\u4e2a\u4f53\u4ea4\u4e92, \u4fbf\u80fd\u83b7\u5f97\u4e00\u4e2a\u6bd4\u8f83\u5f3a\u7684\u80fd\u529b. \u5f53\u8ba9\u53d7\u5236\u4e8e\u4ea4\u4e92\u7684\u5f62\u5f0f, \u83b7\u5f97\u7684\u80fd\u529b\u4e5f\u4e0d\u4e00\u6837, \u4f8b\u5982\u5982\u679c\u4e00\u4e2a\u666e\u901a\u7684\u56fe\u7075\u673a\u4e0e\u4e00\u4e2a\u80fd\u529b\u6781\u5f3a\u7684\u4e2a\u4f53\u4ea4\u4e92, \u8fd9\u91cc\u7684\u4e2a\u4f53\u53ef\u4ee5\u7a81\u7834\u56fe\u7075\u673a\u7684\u9650\u5236, \u8fd9\u6837\u4e00\u79cd\u4ea4\u4e92\u7684\u5f62\u5f0f\u53ef\u4ee5\u4ea7\u751f \\(\\operatorname{dIP}\\) \u7c7b, \u53ef\u4ee5\u53d1\u73b0\u5982\u679c\u5bf9\u4e8e \\(\\operatorname{NP}\\) \u7684\u8bed\u8a00, \u7531\u4e8e\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u77ed\u8bc1\u660e, \u90a3\u4e48\u4fbf\u53ef\u4ee5\u5728\u4e00\u8f6e\u4e4b\u5185\u5b8c\u6210\u4ea4\u4e92, \u800c\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u591a\u9879\u5f0f\u4ea4\u4e92\u56de\u5408, \u53ef\u4ee5\u5229\u7528\u975e\u786e\u5b9a\u6027\u56fe\u7075\u673a\u731c\u51fa\u4ea4\u4e92\u8fc7\u7a0b, \u4e8e\u662f\u4fbf\u53ef\u4ee5\u5f97\u5230 \\(\\operatorname{dIP} = \\operatorname{NP}\\) . \u8fd9\u4e2a\u7ed3\u679c\u53ef\u80fd\u6709\u70b9\u4ee4\u4eba\u5931\u671b. \u4f46\u5e78\u8fd0\u7684\u662f\u5982\u679c\u6211\u4eec\u5c06\u666e\u901a\u7684\u56fe\u7075\u673a\u66ff\u6362\u6210\u6982\u7387\u56fe\u7075\u673a, \u4fbf\u53ef\u4ee5\u8ba9\u80fd\u529b\u63d0\u5347\u5230 \\(\\operatorname{PSPACE}\\) , \u5373 \\(\\operatorname{IP} = \\operatorname{PSPACE}\\) . \u6240\u4ee5\u5982\u679c\u6709\u4e86\u4e00\u4e2a\u8272\u5b50, \u80fd\u5426\u589e\u5f3a\u673a\u5668\u7684\u80fd\u529b\u4ecd\u7136\u6709\u5f85\u5546\u69b7, \u800c\u4e14\u8272\u5b50\u4e5f\u65e0\u6cd5\u8ba9\u6211\u4eec\u5ba1\u89c6\u5168\u90e8\u7684\u7b54\u6848. \u4f46\u5982\u679c\u8272\u5b50\u65e0\u6cd5\u53ef\u4ee5\u5e26\u6765\u5de8\u5927\u7684\u63d0\u9ad8, \u90a3\u65e0\u5f02\u4e8e\u8bf4\u660e\u4e86\u5bfb\u627e\u7406\u60f3\u7684\u566a\u58f0\u662f\u65e0\u610f\u4e49\u7684.","title":"\u63b7\u8272\u5b50\u53ef\u4ee5\u8ba9\u6211\u53d8\u806a\u660e\u5417"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#_1","text":"\u5982\u679c \\(X_{1}, .., X_{n}\\) \u662f \\(\\{0,1\\}\\) \u4e0a\u4e24\u4e24\u72ec\u7acb\u7684\u968f\u673a\u53d8\u91cf, \u4e14 \\(\\mu = \\sum_{i=1}^{n}E(X_{i})\\) , \u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684 \\(\\delta >0\\) \u6709 \\[P\\{\\sum_{i=1}^{n}X_{i} \\geq (1 + \\delta)\\mu\\} \\leq (\\frac{e^{\\delta}}{(1+\\delta)^{(1+\\delta)}})^{\\mu}\\] \\[P\\{\\sum_{i=1}^{n}X_{i} \\geq (1 - \\delta)\\mu\\} \\leq (\\frac{e^{\\delta}}{(1-\\delta)^{(1-\\delta)}})^{\\mu}\\] \u5176\u63a8\u8bba $$P{|\\sum_{i=1}^{n}X_{i} - \\mu| \\geq c\\mu } \\leq 2e^{-\\min {c^{2}/4, c/2}\\mu } $$ \u7b49\u53f7\u53f3\u4fa7\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a\u5173\u4e8e \\(c\\) \u7684\u6307\u6570\u51fd\u6570, \u8fd9\u5c06\u4f1a\u7ed9\u5047\u8bbe\u68c0\u9a8c\u63d0\u4f9b\u6307\u6570\u822c\u7684\u4e0b\u964d\u80fd\u529b. \u4e5f\u5c31\u662f\u8bf4, \u5728\u8fdb\u884c\u5efa\u8bbe\u68c0\u9a8c\u7684\u65f6\u5019, \u9a8c\u8bc1\u547d\u9898\u7684\u6b63\u786e, \u5982\u679c\u6784\u9020\u5408\u7406, \u53ef\u4ee5\u53ea\u4f7f\u7528 \\(log\\) \u7ea7\u522b\u7684\u6570\u636e\u91cf.","title":"\u5207\u5c14\u8bfa\u592b\u754c"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#bounded-error","text":"\u4f5c\u4e3a\u4e0a\u9762\u4f8b\u5b50\u7684\u76f4\u63a5\u5e94\u7528, \u5982\u679c\u6211\u4eec\u62e5\u6709\u4e00\u679a\u671d\u4e0a\u6982\u7387\u4e3a \\(\\rho\\) \u7684\u786c\u5e01, \u5176\u4e2d \\(\\rho > \\frac{1}{2}\\) , \u90a3\u4e48\u5bf9\u4e8e\u4efb\u610f\u7684 \\(p=1 - \\frac{1}{2^n}\\) , \u6211\u4eec\u90fd\u53ef\u4ee5\u5728 \\(O(\\log n)\\) \u7684\u65f6\u95f4\u5185\u5f97\u5230\u8fd9\u6837\u4e00\u679a\u786c\u5e01.","title":"Bounded Error"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#operatornamebpp","text":"\\(\\operatorname{BPTIME}(O(f(x)))\\) \u4ee3\u8868\u4e86\u80fd\u5728 \\(O(f(x))\\) \u7684\u6982\u7387\u56fe\u7075\u673a\u4e0a\u5224\u5b9a\u7684\u95ee\u9898\u7684\u96c6\u5408. \\(\\operatorname{BPP} = \\bigcup_{i = 0} ^ {\\inf}\\) \\(\\operatorname{BPTIME}(n^{i})\\) \u5219\u4ee3\u8868\u5728\u6982\u7387\u610f\u4e49\u4e0b \\(\\operatorname{P}\\) \u7684\u5bf9\u5e94\u7c7b. \u503c\u5f97\u6ce8\u610f\u7684\u662f, \u8fd9\u91cc\u7684\u8fd0\u884c\u65f6\u95f4, \u662f\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u4e0b\u7684\u6700\u574f\u8fd0\u884c\u65f6\u95f4, \u800c\u51b3\u5b9a\u8fd9\u6837\u4e00\u4e2a\u6982\u7387\u56fe\u7075\u673a\u662f\u5426\u63a5\u53d7\u4e00\u4e2a\u5b57\u7b26\u4e32\u53d6\u51b3\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u8f6c\u79fb\u4e4b\u4e0b, \u63a5\u53d7\u7684\u6982\u7387\u5927\u8fd8\u662f\u62d2\u7edd\u7684\u6982\u7387\u5927, \u5f53\u7136\u7531\u4e8e Bounded error \u7684\u60c5\u51b5\u4e0b, \u8fd9\u91cc\u7684\u6982\u7387\u53ea\u9700\u8981\u5927\u4e8e \\(\\frac{1}{2}\\) \u5c31\u597d\u4e86. \u5982\u679c\u63a5\u53d7\u7684\u6982\u7387\u5b9a\u4e49\u5982\u6b64\"\u677e\", \u90a3\u4e48\u5bf9\u4e8e\u8fd0\u884c\u65f6\u95f4\u5462, \u5b9e\u9645\u4e0a\u5982\u679c\u5c06\u6700\u574f\u65f6\u95f4\u66ff\u6362\u4e3a\u671f\u671b\u65f6\u95f4\u4e5f\u4e0d\u4f1a\u4ea7\u751f \\(\\operatorname{BPP}\\) \u53d1\u751f\u53d8\u5316, \u5f53\u7136\u4ece\u8fd9\u91cc\u5c31\u80fd\u7b80\u5355\u7aa5\u63a2\u51fa\u6982\u7387\u56fe\u7075\u673a\u4e0e\u975e\u786e\u5b9a\u6027\u56fe\u7075\u673a\u7684\u533a\u522b, \u867d\u7136\u5b83\u4eec\u90fd\u5177\u6709\u5ba1\u89c6\u6240\u6709\u53ef\u80fd\u60c5\u51b5\u7684\u80fd\u529b, \u4f46\u6982\u7387\u6027\u56fe\u7075\u673a\u9650\u5b9a\u4e86\u671f\u671b\u7684\u8fd0\u884c\u65f6\u95f4. \u540c\u65f6\u6982\u7387\u56fe\u7075\u673a\u63a5\u53d7\u8f93\u5165, \u53d6\u51b3\u4e8e\u63a5\u53d7\u7684\u60c5\u51b5\u662f\u591a\u662f\u5c11, \u800c\u5e76\u975e\u53ea\u6709\u4e00\u4e2a\u63a5\u53d7\u60c5\u51b5. \u5f88\u5bb9\u6613\u9a8c\u8bc1\u51fa \\(\\operatorname{P} \\subset \\operatorname{BPP}\\) , \u4f46\u662f\u5426\u76f8\u7b49\u4ecd\u7136\u662fOPEN\u7684. \u5f53\u7136\u7531\u4e8e\u7b80\u5355\u7684\u5b9a\u4e49,\u5f88\u5bb9\u6613\u5f97\u5230 \\(\\operatorname{BPP} \\subset \\operatorname{EXP}\\) , \u56e0\u4e3a\u53ef\u4ee5\u5728\u6307\u6570\u65f6\u95f4\u4e4b\u5185\u679a\u4e3e\u6240\u6709\u7684\u968f\u673a\u9009\u62e9.","title":"\\(\\operatorname{BPP}\\)"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#derandomize","text":"\u524d\u6587\u63d0\u5230\u4e86\u5728\u5e38\u89c4\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u5f15\u5165\u6982\u7387, \u53ef\u4ee5\u6539\u53d8\u5ba1\u89c6\u7b97\u6cd5\u7684\u89c2\u70b9, \u4f8b\u5982\u53ef\u4ee5\u5728\u671f\u671b \\(O(n)\\) \u7684\u65f6\u95f4\u5185\u5f97\u5230\u4e00\u4e2a\u6570\u5217\u7684\u7b2c \\(k\\) \u5927, \u4f8b\u5982\u53ef\u4ee5\u5728\u671f\u671b\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5224\u5b9a\u8d28\u6570, \u867d\u7136\u524d\u4e24\u4e2a\u95ee\u9898\u90fd\u5b58\u5728\u66f4\u4f18\u79c0\u7684\u5728\u786e\u5b9a\u6027\u56fe\u7075\u673a\u4e0b\u7684\u5bf9\u5e94\u65b9\u6cd5, \u4f46\u90fd\u663e\u5f97\u66f4\u52a0\u590d\u6742. \u9664\u6b64\u4e4b\u5916\u4e5f\u6709\u66f4\u591a\u5df2\u88ab\u8bc1\u660e\u5c5e\u4e8e \\(\\operatorname{BPP}\\) , \u800c\u4e0d\u77e5\u9053\u662f\u5426\u5c5e\u4e8e \\(\\operatorname{P}\\) \u7684\u95ee\u9898, \u4f8b\u5982\u68c0\u9a8c\u4e00\u4e2a\u591a\u9879\u5f0f\u662f\u5426\u6052\u4e3a0. \u5373\u4f7f\u5982\u6b64\u4eba\u4eec\u4ecd\u7136\u76f8\u4fe1 \\(\\operatorname{P} = \\operatorname{BPP}\\) , \u6216\u8bb8\u662f\u56e0\u4e3a\u5bf9\u4e8e\u4e00\u4e9b\u7b80\u5355\u7684\u6982\u7387\u7b97\u6cd5, \u5b58\u5728\u53ef\u4ee5\u7b80\u5355\u6784\u9020\u51fa\u7684\u786e\u5b9a\u6027\u7b97\u6cd5. \u4f8b\u5982\u5bf9\u4e8eSet Cover \u5b58\u5728\u4e00\u4e2a\u8fd1\u4f3c\u5ea6\u4e3a \\(O(\\ln n)\\) \u7684\u7b97\u6cd5, \u57fa\u4e8e\u6982\u7387\u5bf9LP\u4e2d\u7684\u53d8\u91cf\u8fdb\u884c\u968f\u673a\u8d4b\u503c. \u53ef\u4ee5\u5f88\u7b80\u5355\u7684\u901a\u8fc7\u671f\u671b, \u6765\u53cd\u63a8\u51fa\u6bcf\u4e2a\u51b3\u7b56\u53d8\u91cf\u662f\u591a\u5c11, \u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u53eb\u505a Derandomize.","title":"Derandomize"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#rp-and-corp","text":"\u4e3a\u4e86\u63a2\u7d22 \\(\\operatorname{P}\\) \u4e0e \\(\\operatorname{BPP}\\) \u4e4b\u95f4\u7684 gap , \u53ef\u4ee5\u66f4\u52a0\u6536\u7d27 \\(\\operatorname{BPP}\\) \u7684\u5b9a\u4e49, \u4f8b\u5982\u4f7f\u4e4b\u5728\u9519\u8bef\u7684\u6982\u7387\u53d8\u6210 0, \u4f7f\u4e4b\u6210\u4e3a \\(\\operatorname{RP}\\) , \u540c\u6837\u5f62\u6210 \\(\\operatorname{coRP}\\) , \u6709\u610f\u601d\u7684\u662f $\\operatorname{ZPP} = \\operatorname{RP} \\bigcap \\operatorname{coRP} $","title":"RP and coRP"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#key","text":"\u4e00\u4e2a\u968f\u673a\u56fe\u7075\u673a\u53ef\u4ee5\u8f6c\u5316\u6210\u4e00\u4e2a\u9664\u4e00\u822c\u7684\u8f93\u5165\u4e4b\u5916\u8fd8\u6709\u4e00\u4e2a\u8f93\u5165\u7684\u4e32\u4e0d\u59a8\u628a\u5b83\u53eb\u505a key \u5427, \u6211\u4e5f\u4e0d\u77e5\u9053\u5e94\u8be5\u53eb\u4f5c\u4ec0\u4e48, \u8fd9\u4e2a key \u51b3\u5b9a\u4e86\u6574\u4e2a\u968f\u673a\u8fc7\u7a0b. \u5728\u8fd9\u6837\u7684\u5b9a\u4e49\u4e4b\u4e0b, \u53ef\u4ee5\u8bc1\u660e\u51fa \\(\\operatorname{BPP} \\subset \\operatorname{P_{/poly}}\\) \u4e0e \\(\\operatorname{BPP} \\subset \\operatorname{PH}\\) , \u66f4\u8fdb\u4e00\u6b65\u6709 \\(\\operatorname{BPP} \\subset \\operatorname{\\sum_{2}^{P}} \\bigcup \\operatorname{\\Pi_{2}^{P}}\\) . \u5b83\u8d77\u7801\u5b58\u5728\u4e8e\u591a\u9879\u5f0f\u5206\u7ea7\u4e4b\u4e2d\u4e86, \u4f46\u7531\u4e8e \\(\\operatorname{BPP}\\) \u57fa\u4e8e\u8bed\u4e49\u7684\u5b9a\u4e49, \u8ba9 \\(\\operatorname{BPP}\\) \u5c42\u7684\u5b8c\u5168\u95ee\u9898\u6bd4\u8f83\u96be\u4ee5\u627e\u5230, \u4e5f\u8ba9\u8fd9\u4e2a\u5c42\u7ea7\u7684\u53d1\u5c55\u6709\u4e86\u4e00\u4e9b\u56f0\u96be.","title":"Key"},{"location":"blog/2021/%E6%8E%B7%E8%89%B2%E5%AD%90%E5%8F%AF%E4%BB%A5%E8%AE%A9%E6%88%91%E5%8F%98%E8%81%AA%E6%98%8E%E5%90%97/#_2","text":"\u96f6\u77e5\u8bc6\u8bc1\u660e\u662f\u4ea4\u4e92\u5f0f\u8bc1\u660e\u4e2d\u7684\u4e00\u4e2a\u5c0f\u90e8\u5206, \u96f6\u77e5\u8bc6\u8bc1\u660e\u53ef\u4ee5\u8ba9\u6211\u4eec\u770b\u5230\u4e00\u4e2a\u80fd\u529b\u4e0d\u5f3a\u7684\u4e2a\u4f53, \u5982\u679c\u53ef\u4ee5\u8ddf\u4e00\u4e2a\u80fd\u529b\u66f4\u5f3a\u7684\u4e2a\u4f53\u4ea4\u4e92, \u4fbf\u80fd\u83b7\u5f97\u4e00\u4e2a\u6bd4\u8f83\u5f3a\u7684\u80fd\u529b. \u5f53\u8ba9\u53d7\u5236\u4e8e\u4ea4\u4e92\u7684\u5f62\u5f0f, \u83b7\u5f97\u7684\u80fd\u529b\u4e5f\u4e0d\u4e00\u6837, \u4f8b\u5982\u5982\u679c\u4e00\u4e2a\u666e\u901a\u7684\u56fe\u7075\u673a\u4e0e\u4e00\u4e2a\u80fd\u529b\u6781\u5f3a\u7684\u4e2a\u4f53\u4ea4\u4e92, \u8fd9\u91cc\u7684\u4e2a\u4f53\u53ef\u4ee5\u7a81\u7834\u56fe\u7075\u673a\u7684\u9650\u5236, \u8fd9\u6837\u4e00\u79cd\u4ea4\u4e92\u7684\u5f62\u5f0f\u53ef\u4ee5\u4ea7\u751f \\(\\operatorname{dIP}\\) \u7c7b, \u53ef\u4ee5\u53d1\u73b0\u5982\u679c\u5bf9\u4e8e \\(\\operatorname{NP}\\) \u7684\u8bed\u8a00, \u7531\u4e8e\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u77ed\u8bc1\u660e, \u90a3\u4e48\u4fbf\u53ef\u4ee5\u5728\u4e00\u8f6e\u4e4b\u5185\u5b8c\u6210\u4ea4\u4e92, \u800c\u5bf9\u4e8e\u4efb\u610f\u4e00\u4e2a\u591a\u9879\u5f0f\u4ea4\u4e92\u56de\u5408, \u53ef\u4ee5\u5229\u7528\u975e\u786e\u5b9a\u6027\u56fe\u7075\u673a\u731c\u51fa\u4ea4\u4e92\u8fc7\u7a0b, \u4e8e\u662f\u4fbf\u53ef\u4ee5\u5f97\u5230 \\(\\operatorname{dIP} = \\operatorname{NP}\\) . \u8fd9\u4e2a\u7ed3\u679c\u53ef\u80fd\u6709\u70b9\u4ee4\u4eba\u5931\u671b. \u4f46\u5e78\u8fd0\u7684\u662f\u5982\u679c\u6211\u4eec\u5c06\u666e\u901a\u7684\u56fe\u7075\u673a\u66ff\u6362\u6210\u6982\u7387\u56fe\u7075\u673a, \u4fbf\u53ef\u4ee5\u8ba9\u80fd\u529b\u63d0\u5347\u5230 \\(\\operatorname{PSPACE}\\) , \u5373 \\(\\operatorname{IP} = \\operatorname{PSPACE}\\) . \u6240\u4ee5\u5982\u679c\u6709\u4e86\u4e00\u4e2a\u8272\u5b50, \u80fd\u5426\u589e\u5f3a\u673a\u5668\u7684\u80fd\u529b\u4ecd\u7136\u6709\u5f85\u5546\u69b7, \u800c\u4e14\u8272\u5b50\u4e5f\u65e0\u6cd5\u8ba9\u6211\u4eec\u5ba1\u89c6\u5168\u90e8\u7684\u7b54\u6848. \u4f46\u5982\u679c\u8272\u5b50\u65e0\u6cd5\u53ef\u4ee5\u5e26\u6765\u5de8\u5927\u7684\u63d0\u9ad8, \u90a3\u65e0\u5f02\u4e8e\u8bf4\u660e\u4e86\u5bfb\u627e\u7406\u60f3\u7684\u566a\u58f0\u662f\u65e0\u610f\u4e49\u7684.","title":"\u4ea4\u4e92\u5f0f\u8bc1\u660e"},{"location":"blog/2021/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%B7%B7%E4%B9%B1%E6%9D%82%E8%AE%B0/","tags":["\u64cd\u4f5c\u7cfb\u7edf"],"text":"\u641e\u4e86\u70b9\u8d44\u6599\u641c\u7d22\u548c\u81ea\u884cyy \u672c\u6765\u5c31\u5199\u4e86\u5199\u6587\u4ef6\u7cfb\u7edf\uff0c\u540e\u6765\u5e72\u8106\u6269\u5c55\u5230\u6574\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u4e86\u3002 \u4e00\u822c\u6765\u8bf4\u7406\u6e05\u8fd9\u79cd\u95ee\u9898\u6709\u4e24\u79cd\u4e0d\u540c\u7684\u89c6\u89d2\u3002 \u6587\u4ef6\u7cfb\u7edf \u8fdb\u7a0b\u89d2\u5ea6 \u6bcf\u4e2a\u8fdb\u7a0b\u81ea\u5df1\u90fd\u7ef4\u62a4\u4e86\u4e24\u4e2adentry \u4e00\u4e2a\u662f\u6587\u4ef6\u7cfb\u7edf\u7684\u6839\u7684dentry\u53e6\u4e00\u4e2a\u5c31\u662f\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u7684dentry \u4ec0\u4e48\u662fdentry\uff1f \u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u8def\u5f84 /home/kvrmnks/a / \u8fd9\u4e2a\u8def\u5f84\u5bf9\u5e94\u4e86\u4e00\u4e2adentry /home \u8fd9\u4e2a\u8def\u5f84\u5bf9\u5e94\u4e86\u4e00\u4e2adentry /home/kvrmnks \u8fd9\u4e2a\u8def\u5f84\u4e5f\u5bf9\u5e94\u4e86\u4e00\u4e2adentry dentry\u5c31\u662f\u63cf\u8ff0\u4e00\u4e2a\u76ee\u5f55\u7684\u6570\u636e\u7ed3\u6784\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784 \u4e0d\u5b58\u5728 \u5916\u5b58\uff0c\u4ec5\u4ec5\u5b58\u5728\u4e8e\u5185\u5b58\uff08\u5f53\u7136\u5185\u5b58\u4ea4\u6362\u7684\u65f6\u5019\u5e76\u4e0d\u8003\u8651\uff09\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u4e2d\u5b58\u653e\u4e86\u5bf9\u5e94\u6587\u4ef6\uff08\u5305\u62ec\u6587\u4ef6\u5939\u548c\u6587\u4ef6\u5916\u8bbeblabla\uff0c\u6587\u4e2d\u6587\u4ef6\u5747\u4e3aUNIX\u4e0b\u7684\u6587\u4ef6\u5b9a\u4e49\uff09\u7684inode\u8282\u70b9\u3002 \u4e5f\u5b58\u653e\u4e86\u76ee\u5f55\u4e0b\u7684\u5b50dentry\uff0c\u5f53\u7136\u8fd8\u6709\u7236dentry\u3002 \u4ec0\u4e48\u662finode\uff1f \u7531\u4e8einode\u540c\u65f6\u5b58\u5728\u4e8e\u5916\u8bbe\u5185\u5b58\uff0c\u6587\u4e2d\u7528\u5916\u8bbeinode\u4e0e\u5185\u5b58inode\uff0c\u8fdb\u884c\u533a\u5206\uff0c\u6ca1\u6709\u524d\u7f00\u65f6\u4ee3\u8868\u5171\u540c\u70b9\u3002 inode\u4e2d\u5b58\u653e\u4e86\u6587\u4ef6\u7684\u5143\u6570\u636e\uff08\u521b\u5efa\u65f6\u95f4\uff0c\u4fee\u6539\u65f6\u95f4\uff0c\u8bbf\u95ee\u6743\u9650\uff0c\u5927\u5c0f\uff0c\u5757\u5927\u5c0f\u7b49\uff09 \u5185\u5b58inode\u4e2d\u5b58\u653e\u6709\u5bf9\u5e94\u76ee\u5f55\u4e0b\u7684dentry\uff0c\u5f53\u7136\u4e5f\u6709\u4e00\u4e9b\u6bd4\u5982\u8bfb\u5199\u6307\u9488\u7684\u6570\u636e\u3002 \u5230\u8fd9\u91cc\u5c31\u53ef\u4ee5\u53d1\u73b0\uff0c\u5728\u5185\u5b58inode\u548cdentry\u53ef\u4ee5\u4e92\u76f8\u8bbf\u95ee\uff0c\u5f53\u7136\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\uff08\u6ce8\u610f\u8fd9\u91cc\u5e76\u4e0d\u610f\u5473\u7740\u8bbf\u95ee\u4e0d\u53ef\u4e00\u5bf9\u4e00\uff09\uff0c\u6bd5\u7adf\u4e0d\u540c\u76ee\u5f55\u53ef\u4ee5\u6307\u5411\u540c\u4e00\u4e2a\u6587\u4ef6\uff08inode\uff09\u3002 \u5982\u679c\u7d22\u5f15\u6587\u4ef6\uff1f \u5176\u5b9e\u5341\u5206\u663e\u7136\uff0c\u9996\u5148\u4e0d\u8003\u8651\u6709mount\u548c\u8f6f\u786c\u94fe\u63a5\u4ee5\u53cadentry\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u3002 \u9996\u5148\u5224\u65ad\u662f\u4eceroot\u5f00\u59cb\u627e\uff0c\u8fd8\u662f\u4ece\u5de5\u4f5c\u76ee\u5f55\u5f00\u59cb\u627e\uff0c\u627e\u5230dentry\u3002 \u770b\u770b\u662f\u4e0d\u662f\u627e\u5230\u4e86\uff0c\u5426\u5219\u5c31\u4ecedentry\u7684\u5b50dentry\u91cc\u627e\uff0c\u91cd\u590d\u4ee5\u4e0a\u8fc7\u7a0b\uff0c\u76f4\u5230\u627e\u5230\u5bf9\u5e94\u7684dentry\uff0c\u8fd4\u56de\u5185\u5b58inode\u3002 \u62ff\u5230\u5185\u5b58inode\u4e86\u600e\u4e48\u8fdb\u884c\u64cd\u4f5c\u5462\uff1f \u9996\u5148\u7cfb\u7edf\u4f1a\u521b\u5efa\u4e00\u4e2afile\u6570\u636e\u7ed3\u6784\u6765\u4ee3\u8868 \u8fd9\u4e2a\u8fdb\u7a0b\u6253\u5f00\u7684\u6587\u4ef6 \uff08\u5f53\u7136\u53ef\u4ee5\u8054\u7cfb\u4e00\u4e0b\u8bfe\u4e0a\u5185\u5bb9\uff0c\u8fd9\u91cc\u5176\u5b9e\u662f\u5185\u6838\u521b\u5efa\u4e86\u8fd9\u4e2afile\u6570\u636e\u7ed3\u6784\uff0c\u8fdb\u7a0b\u5f97\u5230\u4e86\u6307\u9488\uff0c\u6307\u5411\u4e86\u5185\u6838\u4e2d\u7684file\u6570\u636e\u7ed3\u6784\uff09\uff0c\u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u4e5f\u662f\u4e0d\u5b58\u5728\u4e8e\u5916\u8bbe\u4e0a\u7684\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u7406\u6240\u5f53\u7136\u5730\u6709\u7740\u6307\u5411\u5185\u5b58inode\u7684\u6307\u9488\uff08\u4e0d\u7136\u5b83\u6709\u4ec0\u4e48\u7528\uff09\u3002 \u5e72\u561b\u8fd8\u8981\u518d\u7528file\u5c01\u88c5\u4e00\u5c42\u5462\uff0c\u7528inode\u4e0d\u597d\u5417\uff1f \u4e0d\u597d\uff0c\u56e0\u4e3a\u5b58\u5728\u591a\u4e2a\u7528\u6237\u6253\u5f00\u540c\u4e00\u4e2a\u6587\u4ef6\u6216\u8005\u4e00\u4e2a\u7528\u6237\u4e0d\u540c\u8fdb\u7a0b\u591a\u6b21\u6253\u5f00\u4e00\u4e2a\u6587\u4ef6\u7684\u60c5\u51b5\uff0c\u8054\u7cfb\u5230\u5185\u5b58inode\u4e2d\u5b58\u653e\u7740\u8bfb\u5199\u6307\u9488\uff0c\u663e\u7136\u4e0d\u53ef\u80fd\u5bf9\u6bcf\u4e00\u6b21\u6253\u5f00\u591a\u7ef4\u62a4\u4e00\u4e2a\uff0c\u4e8e\u662f\u5c31\u91cd\u65b0\u5c01\u88c5\u4e86\u4e00\u5c42\uff0c\u5c01\u88c5\u6210file\uff0c\u5b9e\u5219\u64cd\u4f5cfile\u65f6\u64cd\u4f5c\u5185\u5b58inode\u3002 \u600e\u4e48\u64cd\u4f5cfile\u6570\u636e\u7ed3\u6784\u5462\uff1f \u9996\u5148UNIX\u4e2d\u62bd\u8c61\u51fa\u4e86VFS\u8fd9\u79cd\u4e1c\u897f\uff0c\u5b9e\u73b0\u65b9\u5f0f\u4e4b\u4e00\u5c31\u662f\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u7ed3\u6784\u7ef4\u62a4\u4e00\u4e2a\u51fd\u6570\u6307\u9488\u8868\uff0c\u901a\u8fc7\u8fd9\u4e2a\u6307\u9488\u8868\u6765\u8fdb\u884c\u64cd\u4f5c\u3002 \u64cd\u4f5c\u7cfb\u7edf\u89d2\u5ea6 \u4ece\u64cd\u4f5c\u7cfb\u7edf\u7684\u89d2\u5ea6\u6765\u770b\u4e3b\u8981\u7684\u95ee\u9898\u4fbf\u662f\u8003\u8651\u5982\u4f55\u7ef4\u62a4\u4ee5\u4e0a\u51fa\u73b0\u5730\u6570\u636e\u7ed3\u6784\u3002 \u9996\u5148\u4e0d\u8003\u8651mount\uff0c\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\uff0cmount\u7684\u5b58\u5728\u50cf\u662f\u7ed9\u6574\u4e2a\u7cfb\u7edf\u6253\u4e86\u4e2a\u8865\u4e01\uff0c\u4e8e\u662f\u5148\u4e0d\u8003\u8651\u3002 dentry\u90fd\u4e0d\u5728\u5916\u8bbe\u91cc\uff0c\u600e\u4e48\u7ef4\u62a4\u5462\uff1f \u9996\u5148dentry\u662f\u968f\u7740\u5185\u6838\u8fd0\u884c\u52a8\u6001\u521b\u5efa\u7684\uff0c\u8d77\u59cb\u7684\u76ee\u5f55\u5b58\u653e\u5728superblock\u4e2d\u3002 \u4f46\u662f\u8fdedentry\u90fd\u6ca1\u6709\uff0c\u8be5\u600e\u4e48\u8bbf\u95ee\u4e00\u4e2a\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\u5462\uff1f ~~\u4e00\u5f00\u59cb\u786e\u5b9e\u88ab\u8fd9\u4e2a\u95ee\u9898\u56f0\u6270\u4e86\u597d\u4e45~~\uff0c\u4e0d\u8fc7\u60f3\u60f3\u770b\u76ee\u5f55\u4e5f\u662f\u4e00\u4e2a\u6587\u4ef6\uff0c\u5176\u6587\u4ef6\u6570\u636e\u5c31\u662f\u5b50\u6587\u4ef6\u4e86\u3002 superblock\u662f\u4ec0\u4e48\uff1f superblock\u5b58\u653e\u7740\u6574\u4e2a\u6587\u4ef6\u7cfb\u7edf\u7684\u5143\u6570\u636e\uff0c\u6bd4\u5982\u5757\u5927\u5c0f\u7b49\u3002 \u5f53\u7136\u5bf9\u4e8e\u4e0d\u540c\u7684\u6587\u4ef6\u7cfb\u7edf\u6765\u8bf4\uff0csuperblock\u7684\u5b9a\u4e49\u4e5f\u53ef\u80fd\u4e0d\u540c\u3002 \u5185\u5b58superblock\u4e2d\u5b58\u653e\u7740\u6240\u6709\u5185\u5b58inode\u7684\u6307\u9488\u3002 \u5982\u6b64\u8bf4\u6765\uff0c\u5185\u6838\u4e2d\u5bf9\u4e8e\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u9700\u8981\u7ef4\u62a4\u4e00\u4e2asuperblock\uff0c\u6240\u6709\u7684\u5185\u5b58inode\u8282\u70b9\uff0c\u4ee5\u53ca\u968f\u7740\u8fd0\u884c\u52a8\u6001\u521b\u5efa\u7684dentry\u3002 \u4e3a\u4e86\u7ed9\u8fdb\u7a0b\u64cd\u4f5c\u6587\u4ef6\uff0c\u4e5f\u8981\u7ef4\u62a4\u4e00\u4e2a\u5168\u5c40\u7684file\u6570\u636e\u7ed3\u6784\u94fe\u8868\u3002 \u5176\u4e2ddentry\u5f62\u6210\u4e00\u9897\u6811\u7684\u5f62\u72b6\uff0c\u6bcf\u4e2a\u8282\u70b9\u6307\u5411\u4e86\u5185\u5b58inode\u3002 \u5185\u5b58inode\u4e2d\u5b58\u653e\u7740\u6587\u4ef6\u7684\u5143\u6570\u636e\u3002 \u90a3\u4e48\u5728\u52a0\u5165mount\u7684\u60c5\u51b5\u4e0b\uff0c\u4f1a\u53d1\u751f\u4ec0\u4e48\u6837\u7684\u53d8\u5316\u5462\uff1f \u9996\u5148\u6bcf\u4e2adentry\u591a\u52a0\u4e86\u4e00\u4e2a\u6807\u8bb0\u4f4d\uff0c\u6765\u6807\u8bb0\u8fd9\u4e2adentry\u662f\u4e0d\u662f\u88abmount\u4e86\u3002 \u540c\u65f6\u5185\u6838\u9700\u8981\u7ef4\u62a4\u4e00\u68f5mount\u6570\u636e\u7ed3\u6784\u6811 mount\u6570\u636e\u7ed3\u6784\u4e2d\u7ef4\u62a4\u4e86\u7236mount\u6307\u9488\uff0cmount\u6302\u8f7d\u7684dentry\uff0cmount\u7684root dentry\uff0c\u8fd8\u6709\u5b50mount\u94fe\u8868\u3002 \u4e3b\u8981\u7684\u4fee\u6539\u5728\u7d22\u5f15\u6587\u4ef6\u65f6\uff0c\u5982\u679c\u5f53\u524d\u7684dentry\u88ab\u6807\u8bb0\u4e86\u88abmount \u4ece\u7236mount\u4e2d\u641c\u7d22\u5b50mount\u94fe\u8868\uff0c\u67e5\u770b\u5b50mount\u4e2d\u7684\u6302\u8f7ddentry\uff0c\u5982\u679c\u5339\u914d\uff0c\u8df3\u5230\u5b50mount\u7684root dentry\uff0c\u7ee7\u7eed\u4ee5\u4e0a\u6d41\u7a0b\u3002 mount\u540c\u65f6\u4e5f\u4f1a\u5e26\u6765\u5176\u4ed6\u7684\u5f71\u54cd\uff0c\u6bd4\u5982\u7531\u4e8e\u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\u7684\u4e0d\u540c\uff0c\u5904\u7406\u51fd\u6570\u4e5f\u4f1a\u53d1\u751f\u76f8\u5e94\u7684\u6539\u53d8\uff0c\u540c\u6837\u5229\u7528\u51fd\u6570\u6307\u9488\u8868\u7684\u65b9\u5f0f\u8fdb\u884c\u89e3\u51b3\u3002 \u5728\u6dfb\u52a0\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u5462\uff1f \u5176\u5b9e\u4e5f\u6ca1\u5565\uff0c\u65e0\u975e\u5c31\u662f\u5185\u5b58inode\u53ef\u80fd\u4e0d\u5168\u4e86\uff0c\u4e0d\u9700\u8981\u7684\u65f6\u5019\u5c31\u5199\u56de\u5230\u5916\u8bbe\u3002 \u540c\u6b65\u4e0e\u6b7b\u9501 \u5173\u4e8e\u9965\u997f \u663e\u7136\u5728\u8fdb\u7a0b\u7ba1\u7406\uff08CPU\u8c03\u5ea6\uff09\uff0c\u5916\u8bbe\u7ba1\u7406\u7b49\u5730\u65b9\u4e5f\u6d89\u53ca\u5230\u4e86\u9965\u997f\u8fd9\u4e2a\u6982\u5ff5\u3002 \u4f46\u662f\u5728\u4e0d\u540c\u5730\u65b9\u8ba8\u8bba\u9965\u997f\u65f6\u5b8c\u5168\u6709\u53ef\u80fd\u9677\u5165\u4e3b\u8bed\u7684\u6df7\u4e71\u3002 \u5728\u5916\u8bbe\u7ba1\u7406\u7684\u5730\u65b9\uff0c\u78c1\u76d8\u7684\u8c03\u5ea6\u7b97\u6cd5\uff08\u975e\u5148\u6765\u5148\u670d\u52a1\uff09\u6709\u53ef\u80fd\u4f1a\u4ea7\u751f\u9965\u997f\uff0c\u66f4\u8be6\u7ec6\u5730\u8bf4\uff0c\u662f\u5bfc\u81f4\u6709\u4e9b\u8bf7\u6c42\u6c38\u8fdc\u4e5f\u65e0\u6cd5\u54cd\u5e94\u3002 \u5728\u8fdb\u7a0b\u7ba1\u7406\u4e2d\uff0c\u4e00\u4e9b\u8c03\u5ea6\u7b97\u6cd5\u4e5f\u4f1a\u4ea7\u751f\u9965\u997f\uff0c\u4f8b\u5982FIFO\uff0c\u53c8\u5982\u8bbe\u5b9a\u4f18\u5148\u7ea7\u7684\u65b9\u6cd5\uff0c\u8fd9\u65f6\u5019\u9965\u997f\u7684\u7ed3\u679c\u662f\u4e00\u4e9b\u8fdb\u7a0b\u6c38\u8fdc\u4e5f\u65e0\u6cd5\u88ab\u8c03\u5ea6\u5230\u3002 \u800c\u8fd9\u91cc\u7684\u9965\u997f\u7684\u8868\u8ff0\u5219\u66f4\u52a0\u6a21\u7cca\uff0c\u751a\u81f3\u5728\u6211\u4e2a\u4eba\u7684\u7406\u89e3\u91cc\uff0c\u4f3c\u4e4e\u6240\u6709\u9664\u4e86\u6b7b\u9501\u4e4b\u5916\u7684\u5bfc\u81f4\u5e76\u53d1\u51fa\u73b0\u95ee\u9898\u7684\u60c5\u5f62\u90fd\u53eb\u9965\u997f\u3002 \u8ba8\u8bba\u6709\u5173\u540c\u6b65\u4e0e\u6b7b\u9501\u7684\u9965\u997f\u65f6\uff0c \u7406\u5e94\u5e94\u8be5\u5c06\u8fdb\u7a0b\u7ba1\u7406\u7684\u9965\u997f\u629b\u51fa\u5728\u8ba8\u8bba\u8303\u56f4 \u3002 \u4f8b\u5982\u5728\u54f2\u5b66\u5bb6\u5c31\u9910\u95ee\u9898\u4e2d\uff0c\u5982\u679c\u4e00\u76f4\u53ea\u5141\u8bb81\u4e2a\u54f2\u5b66\u5bb6\u5c31\u9910\uff0c\u4e5f\u4e0d\u80fd\u8bf4\u53d1\u751f\u4e86\u6b7b\u9501\uff0c\u7a0b\u5e8f\u4e5f\u80fd\u4e00\u76f4\u6267\u884c\u4e0d\u4f1a\u4e2d\u65ad\u3002 \u4f46\u662f\u8fd9\u6837\u5bfc\u81f4\u7684\u7ed3\u679c\u662f\u5176\u4ed6\u54f2\u5b66\u5bb6\u88ab\u997f\u6b7b\u4e86\u3002 \u518d\u6bd4\u5982\u4e00\u5ea7\u6865\uff0c\u6709\u6765\u56de\u4e24\u4e2a\u65b9\u5411\uff0c\u8bbe\u7f6e\u4e86\u4f18\u5148\u7ea7\uff0c\u4fdd\u8bc1\u6bcf\u6b21\u5148\u4ece\u5357\u5230\u5317\uff0c\u8fd9\u6837\u7a0b\u5e8f\u4e5f\u53ef\u4ee5\u6b63\u5e38\u8fd0\u884c\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u4ece\u5317\u5411\u5357\u7684\u8f66\u8f86\u62e5\u5835\uff0c\u8fd9\u4e5f\u662f\u8fd9\u91cc\u8ba8\u8bba\u7684\u4e00\u79cd\u9965\u997f\u3002 \u90a3\u4e48\u662f\u4e0d\u662f\u5b9a\u4e49\u8fd9\u91cc\u7684\u9965\u997f\u4e3a\u201c\u6bcf\u4e2a\u7ebf\u7a0b\uff0c\u90fd\u53ef\u4ee5\u673a\u4f1a\u5747\u7b49\u5730\u8fdb\u5165\u4e34\u754c\u533a\u201d\uff0c\u6216\u8005\u662f\u8bfe\u672c\u4e0a\u90a3\u53e5\u6709\u5173\u5224\u65ad\u662f\u5426\u89e3\u51b3\u4e86\u7f13\u51b2\u533a\u95ee\u9898\u7684\u5224\u636e\u201c\u4e00\u4e2a\u7ebf\u7a0b\u7b49\u5f85\u5176\u4ed6\u7ebf\u7a0b\u8fdb\u5165\u4e34\u754c\u533a\u7684\u6b21\u6570\u662f\u6709\u4e0a\u754c\u7684\u201d\u7b49\u7b49\u8bf8\u5982\u6b64\u7c7b\u610f\u601d\u7684\u53e5\u5b50\u3002 \u5f88\u5bb9\u6613\u5c31\u80fd\u7ed9\u51fa\u201c\u53cd\u4f8b\u201d\uff0c\u4f8b\u5982\u8fdb\u5165\u4e86\u4e34\u754c\u533a\uff0c\u7136\u540e\u53d1\u73b0\u4ec0\u4e48\u4e5f\u64cd\u4f5c\u4e0d\u4e86\u3002 \u4e8e\u662f\u5c31\u4ea7\u751f\u4e86\u540c\u6b65\u4e0e\u6b7b\u9501\u8fd9\u91cc\u201c\u9965\u997f\u201d\u5b9a\u4e49\u7684\u6df7\u4e71\u3002\u5f53\u7136\u6211\u4e5f\u6ca1\u4ec0\u4e48\u597d\u529e\u6cd5\u3002 \u5173\u4e8e\u5728\u8d44\u6e90\u5206\u914d\u56fe\u4e0a\u68c0\u67e5\u662f\u5426\u53d1\u751f\u6b7b\u9501\u7684\u7b97\u6cd5 \u672c\u6765\u4ee5\u4e3a\u7ecf\u5178\u7b97\u6cd5\u5df2\u7ecf\u8fbe\u5230\u4e0b\u754c\u4e86\uff0c\u5c31\u5728\u5c1d\u8bd5\u80fd\u4e0d\u80fd\u8bc1\u660e\u8fd9\u4e2a\u4e0b\u754c\uff0c\u5c1d\u8bd5\u4e86\u8bb8\u591a\u95ee\u9898\u7684\u5f52\u7ea6\uff0c\u6700\u540e\u53d1\u73b0\u80fd\u7ed9\u51fa\u4e00\u4e2a\u66f4\u597d\u7684\u7b97\u6cd5\u3002\u3002\u3002 \u9996\u5148\u5b9a\u4e49\u4e00\u4e9b\u8bb0\u53f7\uff0c\u5b9a\u4e49\u56fe \\(G = <V, E>\\) \u4e3a\u8d44\u6e90\u5206\u914d\u56fe\uff0c \\(P\\) \u4e3a\u8fdb\u7a0b\u96c6\u5408\uff0c \\(F\\) \u8868\u793a\u8d44\u6e90\u96c6\u5408\u3002 \u9996\u5148\u5bf9\u4e8e \\(P\\) \u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u679a\u4e3e\u51fa\u8fb9\u5230 \\(F\\) \u4e2d\u7684\u5143\u7d20\uff0c \\(F\\) \u4e2d\u5143\u7d20\u4e0a\u6807\u8bb0\uff0c\u8fd8\u9700\u8981\u5206\u914d\u591a\u5c11\u8fd9\u7c7b\u8d44\u6e90\u3002 \u6bcf\u4e2a \\(F\\) \u4e0a\u8fdb\u884c\u6392\u5e8f\uff0c\u663e\u7136\u53ef\u4ee5\u7ef4\u62a4\u4e00\u4e2a\u6307\u9488\uff0c\u56e0\u4e3a\u5728\u91ca\u653e\u7684\u65f6\u5019\u662f\u5355\u8c03\u7684\u3002 \u7a81\u7136\u4e0d\u60f3\u5199\u4e86\uff0c\u5927\u4e0d\u4e86\u5f53\u4e2a\u7ec3\u4e60\u9898\uff0c\u603b\u4e4b\u8fd9\u4e2a\u590d\u6742\u5ea6\u662f \\(O(E + VlogV)\\) \u7684 \u5173\u4e8e\u201c\u9884\u9632\u201d\u548c\u201c\u907f\u514d\u201d \u4e2a\u4eba\u4e5f\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u8981\u7528\u8fd9\u4e48\u4e24\u4e2a\u5341\u5206\u76f8\u8fd1\u7684\u8bcd\u8bed\u6765\u6df7\u6dc6\u6982\u5ff5\uff0c\u603b\u4e4b\u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e2a\u5927\u6982\u53ef\u884c\u7684\u610f\u4f1a\u65b9\u5f0f\u3002 \u9884\u9632 prevent \u907f\u514d avoid \u907f\u514d\u4ee3\u8868\u6b7b\u9501\u53ef\u80fd\u53d1\u751f\uff0c\u4f46\u662f\u64cd\u4f5c\u7cfb\u7edf\u201c\u7ed5\u201d\u4e86\u8fc7\u53bb \u9884\u9632\u4ee3\u8868\u6b7b\u9501\u6839\u672c\u4e0d\u53ef\u80fd\u53d1\u751f\uff0c\u56e0\u4e3a\u5176\u5fc5\u8981\u6761\u4ef6\u88ab\u7834\u574f\u6389\u4e86\u3002 \u603b\u4e4b\u5c31\u662f\u80e1\u8bf4\u5b8c\u4e86\uff08 \u53c2\u8003\u6587\u732e1 \u53c2\u8003\u6587\u732e2 \u53c2\u8003\u6587\u732e3","title":"\u64cd\u4f5c\u7cfb\u7edf\u6df7\u4e71\u6742\u8bb0"},{"location":"blog/2021/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%B7%B7%E4%B9%B1%E6%9D%82%E8%AE%B0/#_1","text":"","title":"\u6587\u4ef6\u7cfb\u7edf"},{"location":"blog/2021/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%B7%B7%E4%B9%B1%E6%9D%82%E8%AE%B0/#_2","text":"\u6bcf\u4e2a\u8fdb\u7a0b\u81ea\u5df1\u90fd\u7ef4\u62a4\u4e86\u4e24\u4e2adentry \u4e00\u4e2a\u662f\u6587\u4ef6\u7cfb\u7edf\u7684\u6839\u7684dentry\u53e6\u4e00\u4e2a\u5c31\u662f\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u7684dentry \u4ec0\u4e48\u662fdentry\uff1f \u5bf9\u4e8e\u8fd9\u6837\u4e00\u4e2a\u8def\u5f84 /home/kvrmnks/a / \u8fd9\u4e2a\u8def\u5f84\u5bf9\u5e94\u4e86\u4e00\u4e2adentry /home \u8fd9\u4e2a\u8def\u5f84\u5bf9\u5e94\u4e86\u4e00\u4e2adentry /home/kvrmnks \u8fd9\u4e2a\u8def\u5f84\u4e5f\u5bf9\u5e94\u4e86\u4e00\u4e2adentry dentry\u5c31\u662f\u63cf\u8ff0\u4e00\u4e2a\u76ee\u5f55\u7684\u6570\u636e\u7ed3\u6784\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784 \u4e0d\u5b58\u5728 \u5916\u5b58\uff0c\u4ec5\u4ec5\u5b58\u5728\u4e8e\u5185\u5b58\uff08\u5f53\u7136\u5185\u5b58\u4ea4\u6362\u7684\u65f6\u5019\u5e76\u4e0d\u8003\u8651\uff09\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u4e2d\u5b58\u653e\u4e86\u5bf9\u5e94\u6587\u4ef6\uff08\u5305\u62ec\u6587\u4ef6\u5939\u548c\u6587\u4ef6\u5916\u8bbeblabla\uff0c\u6587\u4e2d\u6587\u4ef6\u5747\u4e3aUNIX\u4e0b\u7684\u6587\u4ef6\u5b9a\u4e49\uff09\u7684inode\u8282\u70b9\u3002 \u4e5f\u5b58\u653e\u4e86\u76ee\u5f55\u4e0b\u7684\u5b50dentry\uff0c\u5f53\u7136\u8fd8\u6709\u7236dentry\u3002 \u4ec0\u4e48\u662finode\uff1f \u7531\u4e8einode\u540c\u65f6\u5b58\u5728\u4e8e\u5916\u8bbe\u5185\u5b58\uff0c\u6587\u4e2d\u7528\u5916\u8bbeinode\u4e0e\u5185\u5b58inode\uff0c\u8fdb\u884c\u533a\u5206\uff0c\u6ca1\u6709\u524d\u7f00\u65f6\u4ee3\u8868\u5171\u540c\u70b9\u3002 inode\u4e2d\u5b58\u653e\u4e86\u6587\u4ef6\u7684\u5143\u6570\u636e\uff08\u521b\u5efa\u65f6\u95f4\uff0c\u4fee\u6539\u65f6\u95f4\uff0c\u8bbf\u95ee\u6743\u9650\uff0c\u5927\u5c0f\uff0c\u5757\u5927\u5c0f\u7b49\uff09 \u5185\u5b58inode\u4e2d\u5b58\u653e\u6709\u5bf9\u5e94\u76ee\u5f55\u4e0b\u7684dentry\uff0c\u5f53\u7136\u4e5f\u6709\u4e00\u4e9b\u6bd4\u5982\u8bfb\u5199\u6307\u9488\u7684\u6570\u636e\u3002 \u5230\u8fd9\u91cc\u5c31\u53ef\u4ee5\u53d1\u73b0\uff0c\u5728\u5185\u5b58inode\u548cdentry\u53ef\u4ee5\u4e92\u76f8\u8bbf\u95ee\uff0c\u5f53\u7136\u662f\u4e00\u5bf9\u591a\u7684\u5173\u7cfb\uff08\u6ce8\u610f\u8fd9\u91cc\u5e76\u4e0d\u610f\u5473\u7740\u8bbf\u95ee\u4e0d\u53ef\u4e00\u5bf9\u4e00\uff09\uff0c\u6bd5\u7adf\u4e0d\u540c\u76ee\u5f55\u53ef\u4ee5\u6307\u5411\u540c\u4e00\u4e2a\u6587\u4ef6\uff08inode\uff09\u3002 \u5982\u679c\u7d22\u5f15\u6587\u4ef6\uff1f \u5176\u5b9e\u5341\u5206\u663e\u7136\uff0c\u9996\u5148\u4e0d\u8003\u8651\u6709mount\u548c\u8f6f\u786c\u94fe\u63a5\u4ee5\u53cadentry\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u3002 \u9996\u5148\u5224\u65ad\u662f\u4eceroot\u5f00\u59cb\u627e\uff0c\u8fd8\u662f\u4ece\u5de5\u4f5c\u76ee\u5f55\u5f00\u59cb\u627e\uff0c\u627e\u5230dentry\u3002 \u770b\u770b\u662f\u4e0d\u662f\u627e\u5230\u4e86\uff0c\u5426\u5219\u5c31\u4ecedentry\u7684\u5b50dentry\u91cc\u627e\uff0c\u91cd\u590d\u4ee5\u4e0a\u8fc7\u7a0b\uff0c\u76f4\u5230\u627e\u5230\u5bf9\u5e94\u7684dentry\uff0c\u8fd4\u56de\u5185\u5b58inode\u3002 \u62ff\u5230\u5185\u5b58inode\u4e86\u600e\u4e48\u8fdb\u884c\u64cd\u4f5c\u5462\uff1f \u9996\u5148\u7cfb\u7edf\u4f1a\u521b\u5efa\u4e00\u4e2afile\u6570\u636e\u7ed3\u6784\u6765\u4ee3\u8868 \u8fd9\u4e2a\u8fdb\u7a0b\u6253\u5f00\u7684\u6587\u4ef6 \uff08\u5f53\u7136\u53ef\u4ee5\u8054\u7cfb\u4e00\u4e0b\u8bfe\u4e0a\u5185\u5bb9\uff0c\u8fd9\u91cc\u5176\u5b9e\u662f\u5185\u6838\u521b\u5efa\u4e86\u8fd9\u4e2afile\u6570\u636e\u7ed3\u6784\uff0c\u8fdb\u7a0b\u5f97\u5230\u4e86\u6307\u9488\uff0c\u6307\u5411\u4e86\u5185\u6838\u4e2d\u7684file\u6570\u636e\u7ed3\u6784\uff09\uff0c\u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u4e5f\u662f\u4e0d\u5b58\u5728\u4e8e\u5916\u8bbe\u4e0a\u7684\u3002 \u8fd9\u4e2a\u6570\u636e\u7ed3\u6784\u7406\u6240\u5f53\u7136\u5730\u6709\u7740\u6307\u5411\u5185\u5b58inode\u7684\u6307\u9488\uff08\u4e0d\u7136\u5b83\u6709\u4ec0\u4e48\u7528\uff09\u3002 \u5e72\u561b\u8fd8\u8981\u518d\u7528file\u5c01\u88c5\u4e00\u5c42\u5462\uff0c\u7528inode\u4e0d\u597d\u5417\uff1f \u4e0d\u597d\uff0c\u56e0\u4e3a\u5b58\u5728\u591a\u4e2a\u7528\u6237\u6253\u5f00\u540c\u4e00\u4e2a\u6587\u4ef6\u6216\u8005\u4e00\u4e2a\u7528\u6237\u4e0d\u540c\u8fdb\u7a0b\u591a\u6b21\u6253\u5f00\u4e00\u4e2a\u6587\u4ef6\u7684\u60c5\u51b5\uff0c\u8054\u7cfb\u5230\u5185\u5b58inode\u4e2d\u5b58\u653e\u7740\u8bfb\u5199\u6307\u9488\uff0c\u663e\u7136\u4e0d\u53ef\u80fd\u5bf9\u6bcf\u4e00\u6b21\u6253\u5f00\u591a\u7ef4\u62a4\u4e00\u4e2a\uff0c\u4e8e\u662f\u5c31\u91cd\u65b0\u5c01\u88c5\u4e86\u4e00\u5c42\uff0c\u5c01\u88c5\u6210file\uff0c\u5b9e\u5219\u64cd\u4f5cfile\u65f6\u64cd\u4f5c\u5185\u5b58inode\u3002 \u600e\u4e48\u64cd\u4f5cfile\u6570\u636e\u7ed3\u6784\u5462\uff1f \u9996\u5148UNIX\u4e2d\u62bd\u8c61\u51fa\u4e86VFS\u8fd9\u79cd\u4e1c\u897f\uff0c\u5b9e\u73b0\u65b9\u5f0f\u4e4b\u4e00\u5c31\u662f\u5bf9\u4e8e\u6bcf\u4e2a\u6570\u636e\u7ed3\u6784\u7ef4\u62a4\u4e00\u4e2a\u51fd\u6570\u6307\u9488\u8868\uff0c\u901a\u8fc7\u8fd9\u4e2a\u6307\u9488\u8868\u6765\u8fdb\u884c\u64cd\u4f5c\u3002","title":"\u8fdb\u7a0b\u89d2\u5ea6"},{"location":"blog/2021/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%B7%B7%E4%B9%B1%E6%9D%82%E8%AE%B0/#_3","text":"\u4ece\u64cd\u4f5c\u7cfb\u7edf\u7684\u89d2\u5ea6\u6765\u770b\u4e3b\u8981\u7684\u95ee\u9898\u4fbf\u662f\u8003\u8651\u5982\u4f55\u7ef4\u62a4\u4ee5\u4e0a\u51fa\u73b0\u5730\u6570\u636e\u7ed3\u6784\u3002 \u9996\u5148\u4e0d\u8003\u8651mount\uff0c\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\uff0cmount\u7684\u5b58\u5728\u50cf\u662f\u7ed9\u6574\u4e2a\u7cfb\u7edf\u6253\u4e86\u4e2a\u8865\u4e01\uff0c\u4e8e\u662f\u5148\u4e0d\u8003\u8651\u3002 dentry\u90fd\u4e0d\u5728\u5916\u8bbe\u91cc\uff0c\u600e\u4e48\u7ef4\u62a4\u5462\uff1f \u9996\u5148dentry\u662f\u968f\u7740\u5185\u6838\u8fd0\u884c\u52a8\u6001\u521b\u5efa\u7684\uff0c\u8d77\u59cb\u7684\u76ee\u5f55\u5b58\u653e\u5728superblock\u4e2d\u3002 \u4f46\u662f\u8fdedentry\u90fd\u6ca1\u6709\uff0c\u8be5\u600e\u4e48\u8bbf\u95ee\u4e00\u4e2a\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\u5462\uff1f ~~\u4e00\u5f00\u59cb\u786e\u5b9e\u88ab\u8fd9\u4e2a\u95ee\u9898\u56f0\u6270\u4e86\u597d\u4e45~~\uff0c\u4e0d\u8fc7\u60f3\u60f3\u770b\u76ee\u5f55\u4e5f\u662f\u4e00\u4e2a\u6587\u4ef6\uff0c\u5176\u6587\u4ef6\u6570\u636e\u5c31\u662f\u5b50\u6587\u4ef6\u4e86\u3002 superblock\u662f\u4ec0\u4e48\uff1f superblock\u5b58\u653e\u7740\u6574\u4e2a\u6587\u4ef6\u7cfb\u7edf\u7684\u5143\u6570\u636e\uff0c\u6bd4\u5982\u5757\u5927\u5c0f\u7b49\u3002 \u5f53\u7136\u5bf9\u4e8e\u4e0d\u540c\u7684\u6587\u4ef6\u7cfb\u7edf\u6765\u8bf4\uff0csuperblock\u7684\u5b9a\u4e49\u4e5f\u53ef\u80fd\u4e0d\u540c\u3002 \u5185\u5b58superblock\u4e2d\u5b58\u653e\u7740\u6240\u6709\u5185\u5b58inode\u7684\u6307\u9488\u3002 \u5982\u6b64\u8bf4\u6765\uff0c\u5185\u6838\u4e2d\u5bf9\u4e8e\u4e00\u4e2a\u6587\u4ef6\u7cfb\u7edf\u9700\u8981\u7ef4\u62a4\u4e00\u4e2asuperblock\uff0c\u6240\u6709\u7684\u5185\u5b58inode\u8282\u70b9\uff0c\u4ee5\u53ca\u968f\u7740\u8fd0\u884c\u52a8\u6001\u521b\u5efa\u7684dentry\u3002 \u4e3a\u4e86\u7ed9\u8fdb\u7a0b\u64cd\u4f5c\u6587\u4ef6\uff0c\u4e5f\u8981\u7ef4\u62a4\u4e00\u4e2a\u5168\u5c40\u7684file\u6570\u636e\u7ed3\u6784\u94fe\u8868\u3002 \u5176\u4e2ddentry\u5f62\u6210\u4e00\u9897\u6811\u7684\u5f62\u72b6\uff0c\u6bcf\u4e2a\u8282\u70b9\u6307\u5411\u4e86\u5185\u5b58inode\u3002 \u5185\u5b58inode\u4e2d\u5b58\u653e\u7740\u6587\u4ef6\u7684\u5143\u6570\u636e\u3002 \u90a3\u4e48\u5728\u52a0\u5165mount\u7684\u60c5\u51b5\u4e0b\uff0c\u4f1a\u53d1\u751f\u4ec0\u4e48\u6837\u7684\u53d8\u5316\u5462\uff1f \u9996\u5148\u6bcf\u4e2adentry\u591a\u52a0\u4e86\u4e00\u4e2a\u6807\u8bb0\u4f4d\uff0c\u6765\u6807\u8bb0\u8fd9\u4e2adentry\u662f\u4e0d\u662f\u88abmount\u4e86\u3002 \u540c\u65f6\u5185\u6838\u9700\u8981\u7ef4\u62a4\u4e00\u68f5mount\u6570\u636e\u7ed3\u6784\u6811 mount\u6570\u636e\u7ed3\u6784\u4e2d\u7ef4\u62a4\u4e86\u7236mount\u6307\u9488\uff0cmount\u6302\u8f7d\u7684dentry\uff0cmount\u7684root dentry\uff0c\u8fd8\u6709\u5b50mount\u94fe\u8868\u3002 \u4e3b\u8981\u7684\u4fee\u6539\u5728\u7d22\u5f15\u6587\u4ef6\u65f6\uff0c\u5982\u679c\u5f53\u524d\u7684dentry\u88ab\u6807\u8bb0\u4e86\u88abmount \u4ece\u7236mount\u4e2d\u641c\u7d22\u5b50mount\u94fe\u8868\uff0c\u67e5\u770b\u5b50mount\u4e2d\u7684\u6302\u8f7ddentry\uff0c\u5982\u679c\u5339\u914d\uff0c\u8df3\u5230\u5b50mount\u7684root dentry\uff0c\u7ee7\u7eed\u4ee5\u4e0a\u6d41\u7a0b\u3002 mount\u540c\u65f6\u4e5f\u4f1a\u5e26\u6765\u5176\u4ed6\u7684\u5f71\u54cd\uff0c\u6bd4\u5982\u7531\u4e8e\u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\u7684\u4e0d\u540c\uff0c\u5904\u7406\u51fd\u6570\u4e5f\u4f1a\u53d1\u751f\u76f8\u5e94\u7684\u6539\u53d8\uff0c\u540c\u6837\u5229\u7528\u51fd\u6570\u6307\u9488\u8868\u7684\u65b9\u5f0f\u8fdb\u884c\u89e3\u51b3\u3002 \u5728\u6dfb\u52a0\u7f13\u5b58\u7684\u60c5\u51b5\u4e0b\u5462\uff1f \u5176\u5b9e\u4e5f\u6ca1\u5565\uff0c\u65e0\u975e\u5c31\u662f\u5185\u5b58inode\u53ef\u80fd\u4e0d\u5168\u4e86\uff0c\u4e0d\u9700\u8981\u7684\u65f6\u5019\u5c31\u5199\u56de\u5230\u5916\u8bbe\u3002","title":"\u64cd\u4f5c\u7cfb\u7edf\u89d2\u5ea6"},{"location":"blog/2021/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%B7%B7%E4%B9%B1%E6%9D%82%E8%AE%B0/#_4","text":"\u5173\u4e8e\u9965\u997f \u663e\u7136\u5728\u8fdb\u7a0b\u7ba1\u7406\uff08CPU\u8c03\u5ea6\uff09\uff0c\u5916\u8bbe\u7ba1\u7406\u7b49\u5730\u65b9\u4e5f\u6d89\u53ca\u5230\u4e86\u9965\u997f\u8fd9\u4e2a\u6982\u5ff5\u3002 \u4f46\u662f\u5728\u4e0d\u540c\u5730\u65b9\u8ba8\u8bba\u9965\u997f\u65f6\u5b8c\u5168\u6709\u53ef\u80fd\u9677\u5165\u4e3b\u8bed\u7684\u6df7\u4e71\u3002 \u5728\u5916\u8bbe\u7ba1\u7406\u7684\u5730\u65b9\uff0c\u78c1\u76d8\u7684\u8c03\u5ea6\u7b97\u6cd5\uff08\u975e\u5148\u6765\u5148\u670d\u52a1\uff09\u6709\u53ef\u80fd\u4f1a\u4ea7\u751f\u9965\u997f\uff0c\u66f4\u8be6\u7ec6\u5730\u8bf4\uff0c\u662f\u5bfc\u81f4\u6709\u4e9b\u8bf7\u6c42\u6c38\u8fdc\u4e5f\u65e0\u6cd5\u54cd\u5e94\u3002 \u5728\u8fdb\u7a0b\u7ba1\u7406\u4e2d\uff0c\u4e00\u4e9b\u8c03\u5ea6\u7b97\u6cd5\u4e5f\u4f1a\u4ea7\u751f\u9965\u997f\uff0c\u4f8b\u5982FIFO\uff0c\u53c8\u5982\u8bbe\u5b9a\u4f18\u5148\u7ea7\u7684\u65b9\u6cd5\uff0c\u8fd9\u65f6\u5019\u9965\u997f\u7684\u7ed3\u679c\u662f\u4e00\u4e9b\u8fdb\u7a0b\u6c38\u8fdc\u4e5f\u65e0\u6cd5\u88ab\u8c03\u5ea6\u5230\u3002 \u800c\u8fd9\u91cc\u7684\u9965\u997f\u7684\u8868\u8ff0\u5219\u66f4\u52a0\u6a21\u7cca\uff0c\u751a\u81f3\u5728\u6211\u4e2a\u4eba\u7684\u7406\u89e3\u91cc\uff0c\u4f3c\u4e4e\u6240\u6709\u9664\u4e86\u6b7b\u9501\u4e4b\u5916\u7684\u5bfc\u81f4\u5e76\u53d1\u51fa\u73b0\u95ee\u9898\u7684\u60c5\u5f62\u90fd\u53eb\u9965\u997f\u3002 \u8ba8\u8bba\u6709\u5173\u540c\u6b65\u4e0e\u6b7b\u9501\u7684\u9965\u997f\u65f6\uff0c \u7406\u5e94\u5e94\u8be5\u5c06\u8fdb\u7a0b\u7ba1\u7406\u7684\u9965\u997f\u629b\u51fa\u5728\u8ba8\u8bba\u8303\u56f4 \u3002 \u4f8b\u5982\u5728\u54f2\u5b66\u5bb6\u5c31\u9910\u95ee\u9898\u4e2d\uff0c\u5982\u679c\u4e00\u76f4\u53ea\u5141\u8bb81\u4e2a\u54f2\u5b66\u5bb6\u5c31\u9910\uff0c\u4e5f\u4e0d\u80fd\u8bf4\u53d1\u751f\u4e86\u6b7b\u9501\uff0c\u7a0b\u5e8f\u4e5f\u80fd\u4e00\u76f4\u6267\u884c\u4e0d\u4f1a\u4e2d\u65ad\u3002 \u4f46\u662f\u8fd9\u6837\u5bfc\u81f4\u7684\u7ed3\u679c\u662f\u5176\u4ed6\u54f2\u5b66\u5bb6\u88ab\u997f\u6b7b\u4e86\u3002 \u518d\u6bd4\u5982\u4e00\u5ea7\u6865\uff0c\u6709\u6765\u56de\u4e24\u4e2a\u65b9\u5411\uff0c\u8bbe\u7f6e\u4e86\u4f18\u5148\u7ea7\uff0c\u4fdd\u8bc1\u6bcf\u6b21\u5148\u4ece\u5357\u5230\u5317\uff0c\u8fd9\u6837\u7a0b\u5e8f\u4e5f\u53ef\u4ee5\u6b63\u5e38\u8fd0\u884c\uff0c\u4f46\u662f\u4f1a\u5bfc\u81f4\u4ece\u5317\u5411\u5357\u7684\u8f66\u8f86\u62e5\u5835\uff0c\u8fd9\u4e5f\u662f\u8fd9\u91cc\u8ba8\u8bba\u7684\u4e00\u79cd\u9965\u997f\u3002 \u90a3\u4e48\u662f\u4e0d\u662f\u5b9a\u4e49\u8fd9\u91cc\u7684\u9965\u997f\u4e3a\u201c\u6bcf\u4e2a\u7ebf\u7a0b\uff0c\u90fd\u53ef\u4ee5\u673a\u4f1a\u5747\u7b49\u5730\u8fdb\u5165\u4e34\u754c\u533a\u201d\uff0c\u6216\u8005\u662f\u8bfe\u672c\u4e0a\u90a3\u53e5\u6709\u5173\u5224\u65ad\u662f\u5426\u89e3\u51b3\u4e86\u7f13\u51b2\u533a\u95ee\u9898\u7684\u5224\u636e\u201c\u4e00\u4e2a\u7ebf\u7a0b\u7b49\u5f85\u5176\u4ed6\u7ebf\u7a0b\u8fdb\u5165\u4e34\u754c\u533a\u7684\u6b21\u6570\u662f\u6709\u4e0a\u754c\u7684\u201d\u7b49\u7b49\u8bf8\u5982\u6b64\u7c7b\u610f\u601d\u7684\u53e5\u5b50\u3002 \u5f88\u5bb9\u6613\u5c31\u80fd\u7ed9\u51fa\u201c\u53cd\u4f8b\u201d\uff0c\u4f8b\u5982\u8fdb\u5165\u4e86\u4e34\u754c\u533a\uff0c\u7136\u540e\u53d1\u73b0\u4ec0\u4e48\u4e5f\u64cd\u4f5c\u4e0d\u4e86\u3002 \u4e8e\u662f\u5c31\u4ea7\u751f\u4e86\u540c\u6b65\u4e0e\u6b7b\u9501\u8fd9\u91cc\u201c\u9965\u997f\u201d\u5b9a\u4e49\u7684\u6df7\u4e71\u3002\u5f53\u7136\u6211\u4e5f\u6ca1\u4ec0\u4e48\u597d\u529e\u6cd5\u3002 \u5173\u4e8e\u5728\u8d44\u6e90\u5206\u914d\u56fe\u4e0a\u68c0\u67e5\u662f\u5426\u53d1\u751f\u6b7b\u9501\u7684\u7b97\u6cd5 \u672c\u6765\u4ee5\u4e3a\u7ecf\u5178\u7b97\u6cd5\u5df2\u7ecf\u8fbe\u5230\u4e0b\u754c\u4e86\uff0c\u5c31\u5728\u5c1d\u8bd5\u80fd\u4e0d\u80fd\u8bc1\u660e\u8fd9\u4e2a\u4e0b\u754c\uff0c\u5c1d\u8bd5\u4e86\u8bb8\u591a\u95ee\u9898\u7684\u5f52\u7ea6\uff0c\u6700\u540e\u53d1\u73b0\u80fd\u7ed9\u51fa\u4e00\u4e2a\u66f4\u597d\u7684\u7b97\u6cd5\u3002\u3002\u3002 \u9996\u5148\u5b9a\u4e49\u4e00\u4e9b\u8bb0\u53f7\uff0c\u5b9a\u4e49\u56fe \\(G = <V, E>\\) \u4e3a\u8d44\u6e90\u5206\u914d\u56fe\uff0c \\(P\\) \u4e3a\u8fdb\u7a0b\u96c6\u5408\uff0c \\(F\\) \u8868\u793a\u8d44\u6e90\u96c6\u5408\u3002 \u9996\u5148\u5bf9\u4e8e \\(P\\) \u4e2d\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20\uff0c\u679a\u4e3e\u51fa\u8fb9\u5230 \\(F\\) \u4e2d\u7684\u5143\u7d20\uff0c \\(F\\) \u4e2d\u5143\u7d20\u4e0a\u6807\u8bb0\uff0c\u8fd8\u9700\u8981\u5206\u914d\u591a\u5c11\u8fd9\u7c7b\u8d44\u6e90\u3002 \u6bcf\u4e2a \\(F\\) \u4e0a\u8fdb\u884c\u6392\u5e8f\uff0c\u663e\u7136\u53ef\u4ee5\u7ef4\u62a4\u4e00\u4e2a\u6307\u9488\uff0c\u56e0\u4e3a\u5728\u91ca\u653e\u7684\u65f6\u5019\u662f\u5355\u8c03\u7684\u3002 \u7a81\u7136\u4e0d\u60f3\u5199\u4e86\uff0c\u5927\u4e0d\u4e86\u5f53\u4e2a\u7ec3\u4e60\u9898\uff0c\u603b\u4e4b\u8fd9\u4e2a\u590d\u6742\u5ea6\u662f \\(O(E + VlogV)\\) \u7684 \u5173\u4e8e\u201c\u9884\u9632\u201d\u548c\u201c\u907f\u514d\u201d \u4e2a\u4eba\u4e5f\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u8981\u7528\u8fd9\u4e48\u4e24\u4e2a\u5341\u5206\u76f8\u8fd1\u7684\u8bcd\u8bed\u6765\u6df7\u6dc6\u6982\u5ff5\uff0c\u603b\u4e4b\u8fd9\u91cc\u63d0\u4f9b\u4e00\u4e2a\u5927\u6982\u53ef\u884c\u7684\u610f\u4f1a\u65b9\u5f0f\u3002 \u9884\u9632 prevent \u907f\u514d avoid \u907f\u514d\u4ee3\u8868\u6b7b\u9501\u53ef\u80fd\u53d1\u751f\uff0c\u4f46\u662f\u64cd\u4f5c\u7cfb\u7edf\u201c\u7ed5\u201d\u4e86\u8fc7\u53bb \u9884\u9632\u4ee3\u8868\u6b7b\u9501\u6839\u672c\u4e0d\u53ef\u80fd\u53d1\u751f\uff0c\u56e0\u4e3a\u5176\u5fc5\u8981\u6761\u4ef6\u88ab\u7834\u574f\u6389\u4e86\u3002 \u603b\u4e4b\u5c31\u662f\u80e1\u8bf4\u5b8c\u4e86\uff08 \u53c2\u8003\u6587\u732e1 \u53c2\u8003\u6587\u732e2 \u53c2\u8003\u6587\u732e3","title":"\u540c\u6b65\u4e0e\u6b7b\u9501"},{"location":"blog/2021/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%9C%A8%E5%8F%AF%E5%88%97%E4%B8%AA%E5%B9%B6%E5%92%8C%E4%BA%A4%E8%BF%90%E7%AE%97%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%B0%81%E9%97%AD%E6%80%A7/","text":"\u6b63\u5219\u8bed\u8a00\u5728\u53ef\u5217\u4e2a\u5e76\u548c\u4ea4\u8fd0\u7b97\u4e0b\u7684\u4e0d\u5c01\u95ed\u6027 \u5f15\u7406 Myhill\u2013Nerode\u5b9a\u7406 \u5728 \\(L \\subset \\Sigma^{*}\\) \u4e0a\u5b9a\u4e49\u7b49\u4ef7\u5173\u7cfb\u3002 \\(\\forall x, y \\in L\\) \u82e5 \\(x=y\\) \u5219\u6709 \\(\\forall w \\in \\Sigma^*\\) , \\(xw \\in L, yw\\in L\\) \u540c\u65f6\u6210\u7acb\u6216\u540c\u65f6\u4e0d\u6210\u7acb\u3002 \u8bb0\u8be5\u7b49\u4ef7\u5173\u7cfb\u4e3a \\(R\\) \u82e5 \\(|L/R| < \\infty\\) \u5f53\u4e14\u4ec5\u5f53 \\(L\\) \u662f\u6b63\u5219\u8bed\u8a00\u3002 \u53ef\u5217\u4e2a\u6b63\u5219\u8bed\u8a00\u7684\u5e76 \u5b9a\u4e49 \u5b57\u7b26\u96c6 \\(\\Sigma = \\{0,1\\}\\) \u5b57\u7b26\u4e32\u96c6\u5408\u6ee1\u8db3\u4ee5\u4e0b\u9012\u63a8\u5f0f \\(S_{i} = S_{i-1}0^{i}1\\) \u521d\u59cb\u6761\u4ef6\u4e3a \\(S_{0}=1\\) \u53ef\u4ee5\u7b80\u5355\u5217\u4e00\u4e0b\u524d\u51e0\u4e2a \\(S_{1}=101,S_{2}=101001,S_{3}=1010010001\\) \u663e\u7136\u4e00\u4e2a\u6709\u9650\u957f\u7684\u5b57\u7b26\u4e32\u5f62\u6210\u7684\u96c6\u5408\u4e00\u5b9a\u662f\u6b63\u5219\u8bed\u8a00\u3002 \u8003\u8651 \\(\\large S = \\bigcup_{i=0}^{\\infty}\\{S_{i}\\}\\) \u663e\u7136 \\(S_{i} \\neq S_{j}, \\forall i\\neq j\\) \u5219 \\(|S/R| = \\aleph_{0}\\) \uff0c\u6545\u7531Myhill-Nerode\u5b9a\u7406\uff0c \\(S\\) \u4e0d\u662f\u6b63\u5219\u8bed\u8a00\u3002 \u53ef\u5217\u4e2a\u6b63\u5219\u8bed\u8a00\u7684\u4ea4 \u4e0d\u59a8\u8bb0\u5404\u4e2a\u6b63\u5219\u8bed\u8a00\u4e3a \\(S_{i}\\) \u6839\u636eDe Morgan`s law \\[\\large S = \\bigcap_{i=0}^{\\infty}S_{i} = \\bigcup_{i=0}^{\\infty}\\overline{S_{i}}\\] \u6839\u636e\u524d\u4e00\u90e8\u5206\u7684\u8bf4\u660e\uff0c\u8be5\u7ed3\u679c\u4e0d\u4e00\u5b9a\u662f\u6b63\u5219\u8bed\u8a00\u3002","title":"\u6b63\u5219\u8bed\u8a00\u5728\u53ef\u5217\u4e2a\u5e76\u548c\u4ea4\u8fd0\u7b97\u4e0b\u7684\u4e0d\u5c01\u95ed\u6027"},{"location":"blog/2021/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%9C%A8%E5%8F%AF%E5%88%97%E4%B8%AA%E5%B9%B6%E5%92%8C%E4%BA%A4%E8%BF%90%E7%AE%97%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%B0%81%E9%97%AD%E6%80%A7/#_1","text":"","title":"\u6b63\u5219\u8bed\u8a00\u5728\u53ef\u5217\u4e2a\u5e76\u548c\u4ea4\u8fd0\u7b97\u4e0b\u7684\u4e0d\u5c01\u95ed\u6027"},{"location":"blog/2021/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%9C%A8%E5%8F%AF%E5%88%97%E4%B8%AA%E5%B9%B6%E5%92%8C%E4%BA%A4%E8%BF%90%E7%AE%97%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%B0%81%E9%97%AD%E6%80%A7/#myhillnerode","text":"\u5728 \\(L \\subset \\Sigma^{*}\\) \u4e0a\u5b9a\u4e49\u7b49\u4ef7\u5173\u7cfb\u3002 \\(\\forall x, y \\in L\\) \u82e5 \\(x=y\\) \u5219\u6709 \\(\\forall w \\in \\Sigma^*\\) , \\(xw \\in L, yw\\in L\\) \u540c\u65f6\u6210\u7acb\u6216\u540c\u65f6\u4e0d\u6210\u7acb\u3002 \u8bb0\u8be5\u7b49\u4ef7\u5173\u7cfb\u4e3a \\(R\\) \u82e5 \\(|L/R| < \\infty\\) \u5f53\u4e14\u4ec5\u5f53 \\(L\\) \u662f\u6b63\u5219\u8bed\u8a00\u3002","title":"\u5f15\u7406 Myhill\u2013Nerode\u5b9a\u7406"},{"location":"blog/2021/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%9C%A8%E5%8F%AF%E5%88%97%E4%B8%AA%E5%B9%B6%E5%92%8C%E4%BA%A4%E8%BF%90%E7%AE%97%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%B0%81%E9%97%AD%E6%80%A7/#_2","text":"\u5b9a\u4e49 \u5b57\u7b26\u96c6 \\(\\Sigma = \\{0,1\\}\\) \u5b57\u7b26\u4e32\u96c6\u5408\u6ee1\u8db3\u4ee5\u4e0b\u9012\u63a8\u5f0f \\(S_{i} = S_{i-1}0^{i}1\\) \u521d\u59cb\u6761\u4ef6\u4e3a \\(S_{0}=1\\) \u53ef\u4ee5\u7b80\u5355\u5217\u4e00\u4e0b\u524d\u51e0\u4e2a \\(S_{1}=101,S_{2}=101001,S_{3}=1010010001\\) \u663e\u7136\u4e00\u4e2a\u6709\u9650\u957f\u7684\u5b57\u7b26\u4e32\u5f62\u6210\u7684\u96c6\u5408\u4e00\u5b9a\u662f\u6b63\u5219\u8bed\u8a00\u3002 \u8003\u8651 \\(\\large S = \\bigcup_{i=0}^{\\infty}\\{S_{i}\\}\\) \u663e\u7136 \\(S_{i} \\neq S_{j}, \\forall i\\neq j\\) \u5219 \\(|S/R| = \\aleph_{0}\\) \uff0c\u6545\u7531Myhill-Nerode\u5b9a\u7406\uff0c \\(S\\) \u4e0d\u662f\u6b63\u5219\u8bed\u8a00\u3002","title":"\u53ef\u5217\u4e2a\u6b63\u5219\u8bed\u8a00\u7684\u5e76"},{"location":"blog/2021/%E6%AD%A3%E5%88%99%E8%AF%AD%E8%A8%80%E5%9C%A8%E5%8F%AF%E5%88%97%E4%B8%AA%E5%B9%B6%E5%92%8C%E4%BA%A4%E8%BF%90%E7%AE%97%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%B0%81%E9%97%AD%E6%80%A7/#_3","text":"\u4e0d\u59a8\u8bb0\u5404\u4e2a\u6b63\u5219\u8bed\u8a00\u4e3a \\(S_{i}\\) \u6839\u636eDe Morgan`s law \\[\\large S = \\bigcap_{i=0}^{\\infty}S_{i} = \\bigcup_{i=0}^{\\infty}\\overline{S_{i}}\\] \u6839\u636e\u524d\u4e00\u90e8\u5206\u7684\u8bf4\u660e\uff0c\u8be5\u7ed3\u679c\u4e0d\u4e00\u5b9a\u662f\u6b63\u5219\u8bed\u8a00\u3002","title":"\u53ef\u5217\u4e2a\u6b63\u5219\u8bed\u8a00\u7684\u4ea4"},{"location":"blog/2022/Advanced_Algorithm/","tags":["TCS"],"text":"Maximum Cut greedy cut -> \\(\\frac{1}{2}\\) -approximation maximization approximation ratio \\(\\alpha\\) \\( \\(\\frac{SOL_{G}}{OPT_{G}} \\geq \\alpha\\) \\) minimization ... \\(\\leq\\) best approximation now 0.878~ (SDP semi-definite programming) unique games conjecture -> hard to do better. \u5982\u4f55\u8bbe\u8ba1\u7684? Random Cut Theorem for uniform random cut \\(E(S, T)\\) in graph \\(G\\) . \\[E[|E(S, T)|] = \\frac{|E|}{2}\\] Then De-randomization by conditional expectation. Travel from root to leaf while mark the vertex on decision tree. De-randomization by pairwise independence pairwise independent \\(X_{v}\\) mutual independent ( \\(\\log n\\) ) -> pairwise independent ( \\(n\\) ) use Parity construction enumerate all assignments of \\(\\log n\\) bit. Parity search. Fingerprinting answer equality. AB=C ? \\(O(n^{\\omega})\\) find a truth Freivald's Algorithm 1979 pick a uniform random \\(r \\in \\{0, 1\\}^{n}\\) check \\(A(Br) = Cr\\) ? proof ??? each time \\(\\frac{1}{2}\\) Polynomial Identity Testing (PIT) \\(f, g \\in F[x]\\) of degree \\(d\\) if \\(f = g\\) ? f and g are black-box. You can do evaluation. Deterministic algorithm (polynomial interpolation) Fundamental theorem of algebra Randomized algorithm pick a uniform random r check if \\(f(r) = 0\\) communication complexity consider # of bits communicated Yao 1979 Every deterministic communication protocol solving EQ communicates \\(n\\) bits in the worst-case. use a small field like [p] \\(Z_{p}\\) pick a prime \\(p \\in [n^2, 2n^2]\\) probability \\(O(\\frac{1}{n})\\) what about \\(f \\in F[x_{1}, \\cdots, x_{n}]\\) of degree d. poly-time deterministic for PIT -> either NEXP != P/poly or #P != FP means that w.h.p. there is a poly-time deterministic for PIT. There are some unknown powerful weapons. Vandermonde determinant (like a black block) Schwartz-Zippel Theorem \\(f \\neq 0 \\rightarrow \\mathrm{Pr}[f(x_{1}, \\cdots, x_{n})=0] \\leq \\frac{d}{|S|}\\) # of any \\(f \\neq 0\\) in any cube \\(S^{n}\\) \\(\\leq d |S|^{n-1}\\) application of Schwartz-Zippel graph perfect matching isomorphism of rooted tree Reed-Muller codes hardness vs randomness tradeoff PCP binary graph perfect matching Hall's theorem (matching theorem!) Hungarian method O(n^3) Hopcroft-Karp algorithm \\(O(m\\sqrt{n})\\) Edmonds matrix entries are variables (n*n not same as adjacent matrix) perfect matching -> permutation det(A) != 0 <=> exists a perfect matching \\[det(A):=\\sum_{\\pi \\in S_{n}} (-1)^{sgn(\\pi)} \\prod_{i=1}^{n}A_{i,\\pi(i)}\\] use Schwartz-Zippel to check \\(det(A) = 0 ?\\) (Chistov's algorithm) to solve det(A) parallel! Fingerprinting: hidden requisite: random function another fingerprint \uff08\u901a\u4fe1\u534f\u8bae\u90a3\u91cc\uff09 \u76f4\u63a5\u89e3\u8bfb\u6210\u4e3a2\u8fdb\u5236\u8868\u793a\uff0cpick random prime \\(p \\in [k]\\) Karp-Rabin algorthm (pattern-matching) Balls into Bins birthday \u5355\u5c04 coupon collector \u6ee1\u5c04 occupancy \u6700\u5927\u503c \\[\\frac{1}{|[m]\\rightarrow[n]|}\\] 1-1 birthday on-to coupon collector pre-image size occupancy Birthday Paradox \\(m > 57\\) more than 99% two same birthday \\[\\prod_{i=0}^{n-1} (1 - \\frac{i}{m})\\] use chain rule Perfect Hashing \\(m = n^2\\) Pr[no collision] Simple Uniform Hash Assumption H(|[n] - > [m]|) = nlogm Break the assumption ! Universal Hashing (Universal hash family) k-universal Linear congruential model Proposal Algorithm (Gale-Shapley algorithm) Conwey Lattice theorem Principle of Deferred Decisions Poisson approximation m balls into n bins \\(\\sim Bin(m, \\frac{1}{n})\\) i.i.d. Poisson random variables \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) \\[\\mathbb{Pr}[Y=k] = \\frac{e^{-\\lambda}\\lambda^{k}}{k!}\\] for \\(k \\in \\mathbb{Z}^{+}\\) \\[\\mathbb{E}[Y] = \\mathbb{Var}[Y] = \\lambda\\] Coupon collector: \\[\\mathbb{Pr}[\\land_{i=1}^{n}Y_{i}>0] = (1 - e^{-\\frac{m}{n}})^{n}\\] (Poisson approximation brings independence here) So \\[\\lim_{n \\rightarrow \\infty} \\mathbb{Pr}[X \\geq n\\ln n + cn] = 1 - e^{-e^{-c}}\\] (sharp threshold like monotonous properties in random graph) \u50cf\u662f\u6c34\u9f99\u5934\u8c03\u53c2\uff01 Occupancy problems: \\[\\mathbb{Pr}[\\max_{1 \\leq i \\leq n} Y_{i} < L] = (\\mathbb{Pr}[Y_{i} < L])^{n} \\leq (1 - \\mathbb{Pr}[Y_{i} = L])^{n}\\] wtf... Theorem: \\(\\forall m_{1}, \\cdots, m_{n} \\in \\mathbb{N}\\) s.t. \\(\\sum_{i=1}^{n}m_{i} = m\\) \\[\\mathbb{Pr}[\\land_{i=1}^{n} X_{i} = m_{i}] = \\mathbb{Pr}[\\land_{i=1}^{n}Y_{i}=m_{i} | \\sum_{i=1}^{n}m_{i} = m]\\] When \\(m = n \\ln n + cn\\) i.i.d. \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) and \\(Y = \\sum_{i=1}^{n} Y_{i}\\) \\[\\mathbb{Pr}[\\land_{i=1}^{n}Y_{i} > 0] = \\mathbb{Pr}[\\land_{i=1}^{n} Y_{i} > 0 | Y = m] \\pm o(1)\\] Theorem: \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) , \\(\\forall\\) nonnegative function \\(f\\) \\[\\mathbb{E}[f(X_{1}, \\cdots, X_{n})] \\leq e \\sqrt{m} \\mathbb{E}[f(Y_{1}, \\cdots, Y_{n})]\\] Occupancy problem: \\[\\mathbb{Pr}[\\max_{i=1}^{n}X_{i} < L] \\leq e\\sqrt{m} \\mathbb{Pr}[\\max_{i=1}^{n} Y_{i} < L]\\] \\(\\mathbb{E}\\) becomes \\(\\mathbb{Pr}\\) when \\(f\\) is an indicator. Load Balancing application: HashTable's query time complexity Distributed computation (namely load balancing ) \\(Y_{i,j}\\) iff ball \\(j\\) lands in bin \\(i\\) . \\[\\mathbb{E}[\\max] \\neq \\max \\mathbb{E}[]\\] Conclusion \\(m = \\Theta(n)\\) , \\(O(\\frac{\\log n}{\\log \\log n})\\) whp \\(m = \\Omega(n\\log n)\\) , \\(O(\\frac{m}{n})\\) whp whp \\(1 - \\frac{1}{n}\\) or \\(1 - \\frac{1}{n^{c}}\\) usually c does not have influence on time complexity. \\[\\frac{1}{nn^{c-1}} \\leq \\frac{1}{100n^{c-1}} \\leq \\frac{1}{100}\\] why such definition? usually polynomial false examples wlp wvlp(exp) whlp \\[\\mathbb{P^{i}}(\\exists i:X_{i}>t) \\leq \\sum_{i=1}^{n}\\mathbb{P}(X_{i}\\geq t) \\leq \\frac{1}{n}\\] \\(C_{m}^{t} \\leq \\frac{em}{t}^{t}\\) Concentration Chernoff Bounds (Herman Chernoff) much stronger thant Markov's inequality (linear descent) convenient chernoff bounds (when \\(\\mathbb{E} \\in \\Omega(\\log n)\\) , somehow linear) Moment generating function + extended Markov's inequality 1.Use Markov's inequality on moment generating function 2.use independence of \\(X_{i}\\) , (NOT linearity of expectation) 3. \\(1+y \\leq e^{y}\\) 4.optimize \\(\\lambda\\) (More) Chernoff Bounds negatively associated r.v. Hoeffding's inequality Hoeffding's lemma \\(X \\in [a, b]\\) , \\(\\mathbb{E}[X]=0\\) \\[\\mathbb{E}[e^{\\lambda X}] \\leq exp(\\frac{\\lambda^{2}(b-a)^{2}}{8})\\] Hoeffding's inequality in Action: Randomized Quicksort \\(\\Theta (n\\log n)\\) whp proof: consider every path then union bound Power of two choices place the ball in the less loaded bin. Power of d choices \\(O(\\log^{d}(n))\\) ? X! Hashing and Sketching based on random mapping Count distinct elements input: \\(x_{1}, \\cdots, x_{n} \\in U = [n]\\) output: \\(Z = |\\{x_{1}, \\cdots, x_{n}\\}|\\) Data stream model: input date item comes one at a time. Naive alg: \\(\\Omega(z\\log N)\\) Sketch: (lossy) representation of data using space << Z Is it possible? No Lower bound: (Alon-Matias-Szegedy Godel prize): any deterministic(exact or approx) alg must use \\(\\Omega(N)\\) bits of space in the worst case. (Intuition: communication complexity set disjoin) must use both random and approx Sketcher!: fu jian yi bo, yi quan chao ren \\((\\epsilon, \\delta)\\) -estimator: \\(\\hat{Z}\\) \\[\\mathbb{Pr}[(1 - \\epsilon)z \\leq \\hat{Z} \\leq (1 + \\epsilon)z] > 1 - \\delta\\] PAC learning insight: need both random and approx Shakespeare: 30k words (idealized)uniform hash function h: \\(U \\rightarrow [0,1]\\) \\(\\{h(x_{1}), \\cdots, h(x_{n})\\}\\) estimator: \\[\\mathbb{E}[\\min h(x_{i})] = \\mathbb{Pr}[] = \\frac{1}{z+1}\\] First order approximation \\(\\hat{Z} = \\frac{1}{\\min_{i} h(x_{i})} - 1\\) estimator variance is too large! Markov's inequality \\[\\mathbb{Pr}[X > t] \\leq \\frac{\\mathbb{E}[X]}{t}\\] Corollary \\(f(x) \\geq 0\\) \\[\\mathbb{Pr}[f(X) > t] \\leq \\frac{\\mathbb{E}[f(X)]}{t}\\] Chebyshev's inequality \\[\\mathbb{Pr}[|X-\\mathbb{E}[X]| \\geq t] \\leq \\frac{\\mathrm{Var}[X]}{t^{t}}\\] variance cannot be bounded. \u627e\u627e\u662f\u54ea\u91cc\u8d21\u732e\u8fc7\u53bb\u7684 exchange of sum and variance needs only pair-wise independent. \u8d85\u7eb2\u5185\u5bb9 Universal Hash family (Carter and Wegman 1979) Flajolet-Martin algorithm k-universal strong k-universal Linear congruential hashing: Degree-k polynomial in finite field with random coefficients zeros(y) = max(i: 2^{i}|y) denote # of trailing 0's \\[\\mathbb{Pr}[\\hat{Z} < \\frac{z}{C} \\lor \\hat{Z} > C z] \\leq \\frac{3}{C}\\] \u4e00\u4e2a\u51fd\u6570\u80fd\u505a\u5230\u7684\u6700\u597d\u7684\u4e86 BJKST Algorithm 2-wise independent hash function \\(h: [N] \\rightarrow [M]\\) \\[\\hat{Z} = \\frac{kM}{Y_{k}}\\] \u5bf9\u7406\u60f3\u5316\u7684 min sketch \u7684\u79bb\u6563\u5316. \u5b9a\u4e49\u4e00\u4e2a\u968f\u673a\u53d8\u91cf, \u5199\u6210 pair-wise \u4e8b\u4ef6\u7684\u548c. (\u65b9\u4fbf\u6c42\u671f\u671b\u548c\u65b9\u5dee) Frequency Moments Data stream: \\(x_{1}, x_{2}, \\cdots, x_{n} \\in U\\) for each \\(x \\in U\\) , define frequency of \\(x\\) as \\(f_{x} = |\\{i: x_{i} = x\\}|\\) k-th frequency moments: \\(F_{k} = \\sum_{x \\in U} f^{k}_{x}\\) Space complexity for \\((\\epsilon, \\delta)\\) -estimation: constant \\(\\epsilon, \\delta\\) for \\(k \\leq 2\\) : polylog(N) AMS'96 for \\(k > 2\\) : \\(\\theta(N^{1 - \\frac{2}{k}})\\) Indyk-Woodruff'05 Count distinct elements: \\(F_{0}\\) optimal algorithm [Kane-Nelson-Woodruff'10] \\(O(\\epsilon^{-2}+\\log N)\\) Frequency estimation output estimator of \\(f_{x}\\) within additive error multiplicative error \u592a\u96be\u4e86 Heavy hitters: items that appears \\(> \\epsilon n\\) times. \u9632\u6b62ddos Data Structure for set look CS168 Tool box! bloom filter \u6570\u636e\u5e93 bloom counter count min sketch (CMS) \u4e3a\u4ec0\u4e48\u8fd9\u91cc\u53ea\u9700\u8981 2-universal \u5462??? \u611f\u89c9\u662f\u56e0\u4e3a\u6269\u5927\u4e86\u5185\u5b58 Concentration of Measure \u6982\u7387\u8bba\u6c89\u601d\u5f55 Chernoff Bound Bernstein Inequality sum of independent trials Sub-Gaussian Random variables A centered( \\(\\mathbb{E}[Y] = 0\\) ) random variable Y is said to be sub-Gaussian with variance factor \\(\\nu\\) if \\[\\mathbb{E}[e^{\\lambda Y}] \\leq \\exp\\frac{\\lambda^{2} \\nu}{2}\\] Another interpretation of Chernoff-Hoeffding The method of bounded differences (McDiarmid's Inequality) \u4efb\u4f55 lipschitz function \u5728 prod measure \u90fd\u63a5\u8fd1\u4e00\u4e2a\u5e38\u51fd\u6570 \u5373\u4f7f alg \u4e0d\u968f\u673a, data \u4e5f\u53ef\u80fd\u968f\u673a. Chernoff -> 1-Lipschitz Hoeffding -> \\((b_{i} - a_{i})\\) -Lipschitz \u5fc3\u7406\u53f2\u5b66(?) consider # empty bins in Balls into Bins \\[Y = f(X_{1}, \\cdots, X_{m}) = n - |\\{X_{1}, \\cdots, X_{m}\\}|\\] is 1-Lipschitz. Pattern Matching k-Lipschitz Sprinkling Points on Hypercube iso pari metric Harper's inequality (iso pari metric in Hamming Space) telagrand inequality McDiarmid's Inequality (worst-case) For independent random variable \\(X_{1}, X_{2}, \\cdots, X_{n}\\) , if n-variate function \\(f\\) satisfies the Lipschitz condition: for every \\(1 \\leq i \\leq n\\) , \\[|f(x_{1}, \\cdots, x_{n}) - f(x_{1}, \\cdots, x_{i-1}, y_{i}, x_{i+1}, \\cdots, x_{n})| \\leq c_{i}\\] for any possible \\(i\\) and \\(y_{i}\\) . Then for any \\(t > 0\\) , \\( \\(\\mathbb{Pr}[|f(x_{1}, \\cdots, x_{n}) - \\mathbb{E}f(x_{1}, \\cdots, x_{n})| \\geq t ] \\leq 2e^{-\\frac{t^{2}}{2\\sum_{i=1}^{n}c_{i}^{2}}}\\) \\) This is a very powerful tool which can directly lead to Chernoff bound and Hoeffding bound. Martingale A sequence of random variables \\(X_{0}, X_{1}, \\cdots\\) is a martingale if for all \\(t>0\\) , \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] = X_{t-1}\\] This expectancy is actually a function. \\(f(X_{0}, X_{1}, \\cdots, X_{t-1})\\) \\[\\mathbb{E}[\\mathbb{E}[X|Y]] = \\mathbb{E}[X]\\] \\[\\mathbb{E}[\\mathbb{E}[X|Y, Z]|Z] = \\mathbb{E}[X|Z]\\] e.g. Fair gambling game Super-Martingale \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] \\geq X_{t-1}\\] Sub-Martingale \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] \\leq X_{t-1}\\] Martingale (Generalized Version) (filtration of a sequence of \\(\\sigma\\) -algebra): A sequence of random variables \\(Y_{0}, Y_{1}, \\cdots\\) is a martingale w.r.t. to \\(X_{0}, X_{1}, \\cdots\\) if for all \\(t \\geq 0\\) , \\(Y_{t}\\) is a function of \\(X_{0}, \\cdots, X_{t}\\) \\[\\mathbb{E}[Y_{t+1}|X_{0}, \\cdots, X_{t}] = Y_{t}\\] A fair gambling game: \\(X_{i}\\) : outcome (win/loss) of the \\(i\\) -th betting \\(Y_{i}\\) : capital after the \\(i\\) -th betting Azuma's Inequality For martingale \\(Y_{0}, Y_{1}, \\cdots\\) (w.r.t. \\(X_{0}, X_{1}, ...\\) ) satisfying: \\[\\forall i \\geq 0, |Y_{i} - Y_{i-1}| \\leq c_{i}\\] for any \\(n\\geq 1\\) and \\(t > 0\\) : \\[\\mathbb{Pr}[|Y_{n} - Y_{0}| \\geq t] \\leq \\exp (-\\frac{t^{2}}{2\\sum_{i=1}^{n}c_{i}^{2}})\\] Martingale rules: \u5982\u4f55\u5fc5\u80dc! \u8d4c\u8f93\u4e86\u5c31\u52a0\u500d, \u8d62\u4e86\u7acb\u9a6c\u8dd1\u8def! \u6240\u4ee5\u4e0b\u6ce8\u662f\u6709\u4e0a\u9650\u7684... (\u522b\u60f3\u4e86\u522b\u60f3\u4e86) Doob Martingale A Doob sequence \\(Y_{0}, Y_{1}, \\cdots, Y_{n}\\) of an \\(n\\) -variate function \\(f\\) w.r.t. a random vector \\((X_{1}, ..., X_{n})\\) is: \\[\\forall 0 \\leq i \\leq n, Y_{i} = \\mathbb{E}[f(X_{1}, \\cdots, X_{n})|X_{1}, \\cdots, X_{i}]\\] Theorem: The Doob sequence \\(Y_{0}, Y_{1}, \\cdots, Y_{n}\\) is a martingale w.r.t. \\(X_{1}, X_{2}, \\cdots, X_{n}\\) . Dimension reduction Metric embedding \\(d(x, x) = 0\\) \\(d(x, y) = d(y, x)\\) \\(d(x, y) + d(y, z) >= d(x, y)\\) low-distortion: for small \\(\\alpha \\geq 1\\) \\(\\forall x_{1}, x_{2} \\in X\\) , \\(\\frac{1}{\\alpha}d_{X}(x_{1}, x_{2}) \\leq d_{Y}(\\phi(x_{1}), \\phi(x_{2})) \\leq \\alpha d_{X}(x_{1}, x_{2})\\) somehow approximation spherical -> planar ? exists such \\(\\alpha\\) ?: NO convert the problem from a hard metric space into a easy metric space. (find a low distortion mapping) Euclidean embedding Input: n points \\(x_{1}, x_{2}, \\cdots, x_{n} \\in \\mathbb{R}^{d}\\) Output: \\(y_{1}, \\cdots, y_{n} \\in \\mathbb{R}^{k}\\) \\[(1 - \\epsilon)||x_{i} - x_{j}|| \\leq ||y_{i} - y_{j}|| \\leq (1 + \\epsilon)||x_{i} - x_{j}||\\] usually k << d (the curse of dimensionality) consider how small can k be For what distance || . || The embedding should be efficiently constructible. Johnson-Lindenstrauss Theorem 1984 (also check CS168Toolbox) \\[(1 - \\epsilon)||x_{i} - x_{j}||^{2}_{2} \\leq ||y_{i} - y_{j}||^{2}_{2} \\leq (1 + \\epsilon)||x_{i} - x_{j}||^{2}_{2}\\] k = \\(O(\\frac{\\log n}{\\epsilon^{2}})\\) optimal! (k is irrelevant to \\(d\\) !) A linear transformation! The probabilistic method: for random \\(A \\in \\mathbb{R}^{k \\times d}\\) \\[\\mathbb{P}[\\forall x, y \\in S: (1 - \\epsilon)||x - y||^{2}_{2} \\leq ||Ax - Ay||^{2}_{2} \\leq (1 + \\epsilon)||x - y||^{2}_{2}] = 1 - O(\\frac{1}{n})\\] We just need to prove this probability is greater than 0 in order to prove this theorem. What kind of \"random\"? Efficient construction of random \\(A \\in \\mathbb{R}^{k \\times d}\\) projection onto uniform random k-dimensional subspace; (Johnson-Lindenstrauss, Dasgupta-Gupta) independent Gaussian entries; (Indyk-Motwani) i.i.d. -1/+1 entries (Achlioptas) independent Gaussian entries For some suitable k = \\(O(\\frac{\\log n}{\\epsilon^2})\\) Entries of \\(A \\in \\mathbb{R}^{k \\times d}\\) are choosen i.i.d. from \\(\\mathcal{N}(0, \\frac{1}{k})\\) \\[1 - \\epsilon \\leq \\frac{||Ax - Ay||^{2}_{2}}{||x - y||^{2}_{2}} \\leq 1 + \\epsilon\\] \\[\\frac{||Ax - Ay||^{2}_{2}}{||x - y||^{2}_{2}} = ||A \\frac{x - y}{||x - y||_2}||_2^2\\] \\[\\mathbb{P}[| ||Au||_2^2 - 1| > \\epsilon] \\leq \\frac{1}{n^3}\\] Here we use concentration of measurement Chernoff bound for \\(\\chi^2\\) distributions","title":"Advanced Algorithm"},{"location":"blog/2022/Advanced_Algorithm/#maximum-cut","text":"greedy cut -> \\(\\frac{1}{2}\\) -approximation maximization approximation ratio \\(\\alpha\\) \\( \\(\\frac{SOL_{G}}{OPT_{G}} \\geq \\alpha\\) \\) minimization ... \\(\\leq\\) best approximation now 0.878~ (SDP semi-definite programming) unique games conjecture -> hard to do better. \u5982\u4f55\u8bbe\u8ba1\u7684?","title":"Maximum Cut"},{"location":"blog/2022/Advanced_Algorithm/#random-cut","text":"Theorem for uniform random cut \\(E(S, T)\\) in graph \\(G\\) . \\[E[|E(S, T)|] = \\frac{|E|}{2}\\] Then","title":"Random Cut"},{"location":"blog/2022/Advanced_Algorithm/#de-randomization-by-conditional-expectation","text":"Travel from root to leaf while mark the vertex on decision tree.","title":"De-randomization by conditional expectation."},{"location":"blog/2022/Advanced_Algorithm/#de-randomization-by-pairwise-independence","text":"pairwise independent \\(X_{v}\\) mutual independent ( \\(\\log n\\) ) -> pairwise independent ( \\(n\\) ) use Parity construction enumerate all assignments of \\(\\log n\\) bit. Parity search.","title":"De-randomization by pairwise independence"},{"location":"blog/2022/Advanced_Algorithm/#fingerprinting","text":"answer equality.","title":"Fingerprinting"},{"location":"blog/2022/Advanced_Algorithm/#abc","text":"\\(O(n^{\\omega})\\) find a truth Freivald's Algorithm 1979 pick a uniform random \\(r \\in \\{0, 1\\}^{n}\\) check \\(A(Br) = Cr\\) ? proof ??? each time \\(\\frac{1}{2}\\)","title":"AB=C ?"},{"location":"blog/2022/Advanced_Algorithm/#polynomial-identity-testing-pit","text":"\\(f, g \\in F[x]\\) of degree \\(d\\) if \\(f = g\\) ? f and g are black-box. You can do evaluation. Deterministic algorithm (polynomial interpolation) Fundamental theorem of algebra Randomized algorithm pick a uniform random r check if \\(f(r) = 0\\) communication complexity consider # of bits communicated Yao 1979 Every deterministic communication protocol solving EQ communicates \\(n\\) bits in the worst-case. use a small field like [p] \\(Z_{p}\\) pick a prime \\(p \\in [n^2, 2n^2]\\) probability \\(O(\\frac{1}{n})\\) what about \\(f \\in F[x_{1}, \\cdots, x_{n}]\\) of degree d. poly-time deterministic for PIT -> either NEXP != P/poly or #P != FP means that w.h.p. there is a poly-time deterministic for PIT. There are some unknown powerful weapons. Vandermonde determinant (like a black block)","title":"Polynomial Identity Testing (PIT)"},{"location":"blog/2022/Advanced_Algorithm/#schwartz-zippel-theorem","text":"\\(f \\neq 0 \\rightarrow \\mathrm{Pr}[f(x_{1}, \\cdots, x_{n})=0] \\leq \\frac{d}{|S|}\\) # of any \\(f \\neq 0\\) in any cube \\(S^{n}\\) \\(\\leq d |S|^{n-1}\\) application of Schwartz-Zippel graph perfect matching isomorphism of rooted tree Reed-Muller codes hardness vs randomness tradeoff PCP","title":"Schwartz-Zippel Theorem"},{"location":"blog/2022/Advanced_Algorithm/#binary-graph-perfect-matching","text":"Hall's theorem (matching theorem!) Hungarian method O(n^3) Hopcroft-Karp algorithm \\(O(m\\sqrt{n})\\) Edmonds matrix entries are variables (n*n not same as adjacent matrix) perfect matching -> permutation det(A) != 0 <=> exists a perfect matching \\[det(A):=\\sum_{\\pi \\in S_{n}} (-1)^{sgn(\\pi)} \\prod_{i=1}^{n}A_{i,\\pi(i)}\\] use Schwartz-Zippel to check \\(det(A) = 0 ?\\) (Chistov's algorithm) to solve det(A) parallel! Fingerprinting: hidden requisite: random function another fingerprint \uff08\u901a\u4fe1\u534f\u8bae\u90a3\u91cc\uff09 \u76f4\u63a5\u89e3\u8bfb\u6210\u4e3a2\u8fdb\u5236\u8868\u793a\uff0cpick random prime \\(p \\in [k]\\) Karp-Rabin algorthm (pattern-matching)","title":"binary graph perfect matching"},{"location":"blog/2022/Advanced_Algorithm/#balls-into-bins","text":"birthday \u5355\u5c04 coupon collector \u6ee1\u5c04 occupancy \u6700\u5927\u503c \\[\\frac{1}{|[m]\\rightarrow[n]|}\\] 1-1 birthday on-to coupon collector pre-image size occupancy","title":"Balls into Bins"},{"location":"blog/2022/Advanced_Algorithm/#birthday-paradox","text":"\\(m > 57\\) more than 99% two same birthday \\[\\prod_{i=0}^{n-1} (1 - \\frac{i}{m})\\] use chain rule","title":"Birthday Paradox"},{"location":"blog/2022/Advanced_Algorithm/#perfect-hashing","text":"\\(m = n^2\\) Pr[no collision] Simple Uniform Hash Assumption H(|[n] - > [m]|) = nlogm Break the assumption ! Universal Hashing (Universal hash family) k-universal Linear congruential model Proposal Algorithm (Gale-Shapley algorithm) Conwey Lattice theorem Principle of Deferred Decisions","title":"Perfect Hashing"},{"location":"blog/2022/Advanced_Algorithm/#poisson-approximation","text":"m balls into n bins \\(\\sim Bin(m, \\frac{1}{n})\\) i.i.d. Poisson random variables \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) \\[\\mathbb{Pr}[Y=k] = \\frac{e^{-\\lambda}\\lambda^{k}}{k!}\\] for \\(k \\in \\mathbb{Z}^{+}\\) \\[\\mathbb{E}[Y] = \\mathbb{Var}[Y] = \\lambda\\] Coupon collector: \\[\\mathbb{Pr}[\\land_{i=1}^{n}Y_{i}>0] = (1 - e^{-\\frac{m}{n}})^{n}\\] (Poisson approximation brings independence here) So \\[\\lim_{n \\rightarrow \\infty} \\mathbb{Pr}[X \\geq n\\ln n + cn] = 1 - e^{-e^{-c}}\\] (sharp threshold like monotonous properties in random graph) \u50cf\u662f\u6c34\u9f99\u5934\u8c03\u53c2\uff01 Occupancy problems: \\[\\mathbb{Pr}[\\max_{1 \\leq i \\leq n} Y_{i} < L] = (\\mathbb{Pr}[Y_{i} < L])^{n} \\leq (1 - \\mathbb{Pr}[Y_{i} = L])^{n}\\] wtf... Theorem: \\(\\forall m_{1}, \\cdots, m_{n} \\in \\mathbb{N}\\) s.t. \\(\\sum_{i=1}^{n}m_{i} = m\\) \\[\\mathbb{Pr}[\\land_{i=1}^{n} X_{i} = m_{i}] = \\mathbb{Pr}[\\land_{i=1}^{n}Y_{i}=m_{i} | \\sum_{i=1}^{n}m_{i} = m]\\] When \\(m = n \\ln n + cn\\) i.i.d. \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) and \\(Y = \\sum_{i=1}^{n} Y_{i}\\) \\[\\mathbb{Pr}[\\land_{i=1}^{n}Y_{i} > 0] = \\mathbb{Pr}[\\land_{i=1}^{n} Y_{i} > 0 | Y = m] \\pm o(1)\\] Theorem: \\(Y_{1}, \\cdots, Y_{n} \\sim Pois(\\frac{m}{n})\\) , \\(\\forall\\) nonnegative function \\(f\\) \\[\\mathbb{E}[f(X_{1}, \\cdots, X_{n})] \\leq e \\sqrt{m} \\mathbb{E}[f(Y_{1}, \\cdots, Y_{n})]\\] Occupancy problem: \\[\\mathbb{Pr}[\\max_{i=1}^{n}X_{i} < L] \\leq e\\sqrt{m} \\mathbb{Pr}[\\max_{i=1}^{n} Y_{i} < L]\\] \\(\\mathbb{E}\\) becomes \\(\\mathbb{Pr}\\) when \\(f\\) is an indicator.","title":"Poisson approximation"},{"location":"blog/2022/Advanced_Algorithm/#load-balancing","text":"application: HashTable's query time complexity Distributed computation (namely load balancing ) \\(Y_{i,j}\\) iff ball \\(j\\) lands in bin \\(i\\) . \\[\\mathbb{E}[\\max] \\neq \\max \\mathbb{E}[]\\] Conclusion \\(m = \\Theta(n)\\) , \\(O(\\frac{\\log n}{\\log \\log n})\\) whp \\(m = \\Omega(n\\log n)\\) , \\(O(\\frac{m}{n})\\) whp whp \\(1 - \\frac{1}{n}\\) or \\(1 - \\frac{1}{n^{c}}\\) usually c does not have influence on time complexity. \\[\\frac{1}{nn^{c-1}} \\leq \\frac{1}{100n^{c-1}} \\leq \\frac{1}{100}\\] why such definition? usually polynomial false examples wlp wvlp(exp) whlp \\[\\mathbb{P^{i}}(\\exists i:X_{i}>t) \\leq \\sum_{i=1}^{n}\\mathbb{P}(X_{i}\\geq t) \\leq \\frac{1}{n}\\] \\(C_{m}^{t} \\leq \\frac{em}{t}^{t}\\)","title":"Load Balancing"},{"location":"blog/2022/Advanced_Algorithm/#concentration","text":"Chernoff Bounds (Herman Chernoff) much stronger thant Markov's inequality (linear descent) convenient chernoff bounds (when \\(\\mathbb{E} \\in \\Omega(\\log n)\\) , somehow linear) Moment generating function + extended Markov's inequality 1.Use Markov's inequality on moment generating function 2.use independence of \\(X_{i}\\) , (NOT linearity of expectation) 3. \\(1+y \\leq e^{y}\\) 4.optimize \\(\\lambda\\) (More) Chernoff Bounds negatively associated r.v. Hoeffding's inequality Hoeffding's lemma \\(X \\in [a, b]\\) , \\(\\mathbb{E}[X]=0\\) \\[\\mathbb{E}[e^{\\lambda X}] \\leq exp(\\frac{\\lambda^{2}(b-a)^{2}}{8})\\] Hoeffding's inequality in Action: Randomized Quicksort \\(\\Theta (n\\log n)\\) whp proof: consider every path then union bound Power of two choices place the ball in the less loaded bin. Power of d choices \\(O(\\log^{d}(n))\\) ? X!","title":"Concentration"},{"location":"blog/2022/Advanced_Algorithm/#hashing-and-sketching","text":"based on random mapping","title":"Hashing and Sketching"},{"location":"blog/2022/Advanced_Algorithm/#count-distinct-elements","text":"input: \\(x_{1}, \\cdots, x_{n} \\in U = [n]\\) output: \\(Z = |\\{x_{1}, \\cdots, x_{n}\\}|\\) Data stream model: input date item comes one at a time. Naive alg: \\(\\Omega(z\\log N)\\) Sketch: (lossy) representation of data using space << Z Is it possible? No Lower bound: (Alon-Matias-Szegedy Godel prize): any deterministic(exact or approx) alg must use \\(\\Omega(N)\\) bits of space in the worst case. (Intuition: communication complexity set disjoin) must use both random and approx Sketcher!: fu jian yi bo, yi quan chao ren \\((\\epsilon, \\delta)\\) -estimator: \\(\\hat{Z}\\) \\[\\mathbb{Pr}[(1 - \\epsilon)z \\leq \\hat{Z} \\leq (1 + \\epsilon)z] > 1 - \\delta\\] PAC learning insight: need both random and approx Shakespeare: 30k words (idealized)uniform hash function h: \\(U \\rightarrow [0,1]\\) \\(\\{h(x_{1}), \\cdots, h(x_{n})\\}\\) estimator: \\[\\mathbb{E}[\\min h(x_{i})] = \\mathbb{Pr}[] = \\frac{1}{z+1}\\] First order approximation \\(\\hat{Z} = \\frac{1}{\\min_{i} h(x_{i})} - 1\\) estimator variance is too large! Markov's inequality \\[\\mathbb{Pr}[X > t] \\leq \\frac{\\mathbb{E}[X]}{t}\\] Corollary \\(f(x) \\geq 0\\) \\[\\mathbb{Pr}[f(X) > t] \\leq \\frac{\\mathbb{E}[f(X)]}{t}\\] Chebyshev's inequality \\[\\mathbb{Pr}[|X-\\mathbb{E}[X]| \\geq t] \\leq \\frac{\\mathrm{Var}[X]}{t^{t}}\\] variance cannot be bounded. \u627e\u627e\u662f\u54ea\u91cc\u8d21\u732e\u8fc7\u53bb\u7684 exchange of sum and variance needs only pair-wise independent.","title":"Count distinct elements"},{"location":"blog/2022/Advanced_Algorithm/#universal-hash-family-carter-and-wegman-1979-flajolet-martin-algorithm","text":"k-universal strong k-universal Linear congruential hashing: Degree-k polynomial in finite field with random coefficients zeros(y) = max(i: 2^{i}|y) denote # of trailing 0's \\[\\mathbb{Pr}[\\hat{Z} < \\frac{z}{C} \\lor \\hat{Z} > C z] \\leq \\frac{3}{C}\\] \u4e00\u4e2a\u51fd\u6570\u80fd\u505a\u5230\u7684\u6700\u597d\u7684\u4e86","title":"\u8d85\u7eb2\u5185\u5bb9 Universal Hash family (Carter and Wegman 1979) Flajolet-Martin algorithm"},{"location":"blog/2022/Advanced_Algorithm/#bjkst-algorithm","text":"2-wise independent hash function \\(h: [N] \\rightarrow [M]\\) \\[\\hat{Z} = \\frac{kM}{Y_{k}}\\] \u5bf9\u7406\u60f3\u5316\u7684 min sketch \u7684\u79bb\u6563\u5316. \u5b9a\u4e49\u4e00\u4e2a\u968f\u673a\u53d8\u91cf, \u5199\u6210 pair-wise \u4e8b\u4ef6\u7684\u548c. (\u65b9\u4fbf\u6c42\u671f\u671b\u548c\u65b9\u5dee)","title":"BJKST Algorithm"},{"location":"blog/2022/Advanced_Algorithm/#frequency-moments","text":"Data stream: \\(x_{1}, x_{2}, \\cdots, x_{n} \\in U\\) for each \\(x \\in U\\) , define frequency of \\(x\\) as \\(f_{x} = |\\{i: x_{i} = x\\}|\\) k-th frequency moments: \\(F_{k} = \\sum_{x \\in U} f^{k}_{x}\\) Space complexity for \\((\\epsilon, \\delta)\\) -estimation: constant \\(\\epsilon, \\delta\\) for \\(k \\leq 2\\) : polylog(N) AMS'96 for \\(k > 2\\) : \\(\\theta(N^{1 - \\frac{2}{k}})\\) Indyk-Woodruff'05 Count distinct elements: \\(F_{0}\\) optimal algorithm [Kane-Nelson-Woodruff'10] \\(O(\\epsilon^{-2}+\\log N)\\)","title":"Frequency Moments"},{"location":"blog/2022/Advanced_Algorithm/#frequency-estimation","text":"output estimator of \\(f_{x}\\) within additive error multiplicative error \u592a\u96be\u4e86 Heavy hitters: items that appears \\(> \\epsilon n\\) times. \u9632\u6b62ddos","title":"Frequency estimation"},{"location":"blog/2022/Advanced_Algorithm/#data-structure-for-set","text":"look CS168 Tool box! bloom filter \u6570\u636e\u5e93 bloom counter count min sketch (CMS) \u4e3a\u4ec0\u4e48\u8fd9\u91cc\u53ea\u9700\u8981 2-universal \u5462??? \u611f\u89c9\u662f\u56e0\u4e3a\u6269\u5927\u4e86\u5185\u5b58","title":"Data Structure for set"},{"location":"blog/2022/Advanced_Algorithm/#concentration-of-measure","text":"\u6982\u7387\u8bba\u6c89\u601d\u5f55 Chernoff Bound Bernstein Inequality sum of independent trials","title":"Concentration of Measure"},{"location":"blog/2022/Advanced_Algorithm/#sub-gaussian-random-variables","text":"A centered( \\(\\mathbb{E}[Y] = 0\\) ) random variable Y is said to be sub-Gaussian with variance factor \\(\\nu\\) if \\[\\mathbb{E}[e^{\\lambda Y}] \\leq \\exp\\frac{\\lambda^{2} \\nu}{2}\\] Another interpretation of Chernoff-Hoeffding","title":"Sub-Gaussian Random variables"},{"location":"blog/2022/Advanced_Algorithm/#the-method-of-bounded-differences","text":"(McDiarmid's Inequality) \u4efb\u4f55 lipschitz function \u5728 prod measure \u90fd\u63a5\u8fd1\u4e00\u4e2a\u5e38\u51fd\u6570 \u5373\u4f7f alg \u4e0d\u968f\u673a, data \u4e5f\u53ef\u80fd\u968f\u673a. Chernoff -> 1-Lipschitz Hoeffding -> \\((b_{i} - a_{i})\\) -Lipschitz \u5fc3\u7406\u53f2\u5b66(?) consider # empty bins in Balls into Bins \\[Y = f(X_{1}, \\cdots, X_{m}) = n - |\\{X_{1}, \\cdots, X_{m}\\}|\\] is 1-Lipschitz. Pattern Matching k-Lipschitz Sprinkling Points on Hypercube iso pari metric Harper's inequality (iso pari metric in Hamming Space) telagrand inequality","title":"The method of bounded differences"},{"location":"blog/2022/Advanced_Algorithm/#mcdiarmids-inequality-worst-case","text":"For independent random variable \\(X_{1}, X_{2}, \\cdots, X_{n}\\) , if n-variate function \\(f\\) satisfies the Lipschitz condition: for every \\(1 \\leq i \\leq n\\) , \\[|f(x_{1}, \\cdots, x_{n}) - f(x_{1}, \\cdots, x_{i-1}, y_{i}, x_{i+1}, \\cdots, x_{n})| \\leq c_{i}\\] for any possible \\(i\\) and \\(y_{i}\\) . Then for any \\(t > 0\\) , \\( \\(\\mathbb{Pr}[|f(x_{1}, \\cdots, x_{n}) - \\mathbb{E}f(x_{1}, \\cdots, x_{n})| \\geq t ] \\leq 2e^{-\\frac{t^{2}}{2\\sum_{i=1}^{n}c_{i}^{2}}}\\) \\) This is a very powerful tool which can directly lead to Chernoff bound and Hoeffding bound.","title":"McDiarmid's Inequality (worst-case)"},{"location":"blog/2022/Advanced_Algorithm/#martingale","text":"A sequence of random variables \\(X_{0}, X_{1}, \\cdots\\) is a martingale if for all \\(t>0\\) , \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] = X_{t-1}\\] This expectancy is actually a function. \\(f(X_{0}, X_{1}, \\cdots, X_{t-1})\\) \\[\\mathbb{E}[\\mathbb{E}[X|Y]] = \\mathbb{E}[X]\\] \\[\\mathbb{E}[\\mathbb{E}[X|Y, Z]|Z] = \\mathbb{E}[X|Z]\\] e.g. Fair gambling game Super-Martingale \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] \\geq X_{t-1}\\] Sub-Martingale \\[\\mathbb{E}[X_{t}|X_{0}, X_{1}, \\cdots, X_{t-1}] \\leq X_{t-1}\\] Martingale (Generalized Version) (filtration of a sequence of \\(\\sigma\\) -algebra): A sequence of random variables \\(Y_{0}, Y_{1}, \\cdots\\) is a martingale w.r.t. to \\(X_{0}, X_{1}, \\cdots\\) if for all \\(t \\geq 0\\) , \\(Y_{t}\\) is a function of \\(X_{0}, \\cdots, X_{t}\\) \\[\\mathbb{E}[Y_{t+1}|X_{0}, \\cdots, X_{t}] = Y_{t}\\] A fair gambling game: \\(X_{i}\\) : outcome (win/loss) of the \\(i\\) -th betting \\(Y_{i}\\) : capital after the \\(i\\) -th betting","title":"Martingale"},{"location":"blog/2022/Advanced_Algorithm/#azumas-inequality","text":"For martingale \\(Y_{0}, Y_{1}, \\cdots\\) (w.r.t. \\(X_{0}, X_{1}, ...\\) ) satisfying: \\[\\forall i \\geq 0, |Y_{i} - Y_{i-1}| \\leq c_{i}\\] for any \\(n\\geq 1\\) and \\(t > 0\\) : \\[\\mathbb{Pr}[|Y_{n} - Y_{0}| \\geq t] \\leq \\exp (-\\frac{t^{2}}{2\\sum_{i=1}^{n}c_{i}^{2}})\\] Martingale rules: \u5982\u4f55\u5fc5\u80dc! \u8d4c\u8f93\u4e86\u5c31\u52a0\u500d, \u8d62\u4e86\u7acb\u9a6c\u8dd1\u8def! \u6240\u4ee5\u4e0b\u6ce8\u662f\u6709\u4e0a\u9650\u7684... (\u522b\u60f3\u4e86\u522b\u60f3\u4e86)","title":"Azuma's Inequality"},{"location":"blog/2022/Advanced_Algorithm/#doob-martingale","text":"A Doob sequence \\(Y_{0}, Y_{1}, \\cdots, Y_{n}\\) of an \\(n\\) -variate function \\(f\\) w.r.t. a random vector \\((X_{1}, ..., X_{n})\\) is: \\[\\forall 0 \\leq i \\leq n, Y_{i} = \\mathbb{E}[f(X_{1}, \\cdots, X_{n})|X_{1}, \\cdots, X_{i}]\\] Theorem: The Doob sequence \\(Y_{0}, Y_{1}, \\cdots, Y_{n}\\) is a martingale w.r.t. \\(X_{1}, X_{2}, \\cdots, X_{n}\\) .","title":"Doob Martingale"},{"location":"blog/2022/Advanced_Algorithm/#dimension-reduction","text":"","title":"Dimension reduction"},{"location":"blog/2022/Advanced_Algorithm/#metric-embedding","text":"\\(d(x, x) = 0\\) \\(d(x, y) = d(y, x)\\) \\(d(x, y) + d(y, z) >= d(x, y)\\) low-distortion: for small \\(\\alpha \\geq 1\\) \\(\\forall x_{1}, x_{2} \\in X\\) , \\(\\frac{1}{\\alpha}d_{X}(x_{1}, x_{2}) \\leq d_{Y}(\\phi(x_{1}), \\phi(x_{2})) \\leq \\alpha d_{X}(x_{1}, x_{2})\\) somehow approximation spherical -> planar ? exists such \\(\\alpha\\) ?: NO convert the problem from a hard metric space into a easy metric space. (find a low distortion mapping)","title":"Metric embedding"},{"location":"blog/2022/Advanced_Algorithm/#euclidean-embedding","text":"Input: n points \\(x_{1}, x_{2}, \\cdots, x_{n} \\in \\mathbb{R}^{d}\\) Output: \\(y_{1}, \\cdots, y_{n} \\in \\mathbb{R}^{k}\\) \\[(1 - \\epsilon)||x_{i} - x_{j}|| \\leq ||y_{i} - y_{j}|| \\leq (1 + \\epsilon)||x_{i} - x_{j}||\\] usually k << d (the curse of dimensionality) consider how small can k be For what distance || . || The embedding should be efficiently constructible.","title":"Euclidean embedding"},{"location":"blog/2022/Advanced_Algorithm/#johnson-lindenstrauss-theorem-1984-also-check-cs168toolbox","text":"\\[(1 - \\epsilon)||x_{i} - x_{j}||^{2}_{2} \\leq ||y_{i} - y_{j}||^{2}_{2} \\leq (1 + \\epsilon)||x_{i} - x_{j}||^{2}_{2}\\] k = \\(O(\\frac{\\log n}{\\epsilon^{2}})\\) optimal! (k is irrelevant to \\(d\\) !) A linear transformation! The probabilistic method: for random \\(A \\in \\mathbb{R}^{k \\times d}\\) \\[\\mathbb{P}[\\forall x, y \\in S: (1 - \\epsilon)||x - y||^{2}_{2} \\leq ||Ax - Ay||^{2}_{2} \\leq (1 + \\epsilon)||x - y||^{2}_{2}] = 1 - O(\\frac{1}{n})\\] We just need to prove this probability is greater than 0 in order to prove this theorem. What kind of \"random\"? Efficient construction of random \\(A \\in \\mathbb{R}^{k \\times d}\\) projection onto uniform random k-dimensional subspace; (Johnson-Lindenstrauss, Dasgupta-Gupta) independent Gaussian entries; (Indyk-Motwani) i.i.d. -1/+1 entries (Achlioptas) independent Gaussian entries For some suitable k = \\(O(\\frac{\\log n}{\\epsilon^2})\\) Entries of \\(A \\in \\mathbb{R}^{k \\times d}\\) are choosen i.i.d. from \\(\\mathcal{N}(0, \\frac{1}{k})\\) \\[1 - \\epsilon \\leq \\frac{||Ax - Ay||^{2}_{2}}{||x - y||^{2}_{2}} \\leq 1 + \\epsilon\\] \\[\\frac{||Ax - Ay||^{2}_{2}}{||x - y||^{2}_{2}} = ||A \\frac{x - y}{||x - y||_2}||_2^2\\] \\[\\mathbb{P}[| ||Au||_2^2 - 1| > \\epsilon] \\leq \\frac{1}{n^3}\\] Here we use concentration of measurement Chernoff bound for \\(\\chi^2\\) distributions","title":"Johnson-Lindenstrauss Theorem 1984 (also check CS168Toolbox)"},{"location":"blog/2022/CS168Toolbox/","tags":["TCS"],"text":"This is my notes about the CS168 in Stanford University Dimensionality Reduction Want to reduce the large dimension into small dimension ( usually independent with input size ) while preserving distance. Distance distance or similarity exact distance: 1 - [x==y] similarity of set ( or multi-set ): Jaccard Similarity \\(J(S,T) = \\frac{|S \\bigcap T|}{|S\\bigcup T|}\\) \\(l_{p}\\) distance. framework reduce dimension while preserving expect. Then use independent trials. exact distance use universal hash function assumption assume \\(h: U \\rightarrow [b]+1\\) k hash function \\(h_{1}, h_{2}, ... , h_{k}\\) \\(\\epsilon\\) - Heavy Hitters \\[\\# = \\min_{i=1}^{k} B(f_{i}(x)) = \\min_{i=1}^{k} \\sum_{j=1}^{n}[f_{i}(x) = f_{j}(x)]\\] \\[E[\\#] = \\min_{i=1}^{k} \\sum_{j=1}^{n}E[[f_{i}(x) = f_{j}(x)]] = \\#x + \\frac{n-\\#x}{b} \\leq \\#x + \\frac{n}{b}\\] use Markov's inequality \\[\\mathrm{Pr}[\\# - \\#x > \\delta \\frac{n}{b}] \\leq \\frac{1}{\\delta}\\] to achieve \\((\\delta, \\epsilon)\\) , let \\(b = \\frac{2}{\\epsilon}\\) , \\(\\delta = 2\\) . Then use independent trials \\(\\frac{1}{2^{p}} < \\delta\\) , then \\(p = \\log(\\frac{1}{\\delta})\\) . Jaccard similarity pick a random permutation of \\(U\\) . hash each element to the smallest element. \\(l_{2}\\) distance - Johnson-Lindenstrauss transform motivation: random projection (inner product with a vector generated by standard Gaussian distribution) random vector \\(\\textbf{r} \\sim N^{n}(0, 1)\\) \\[X = \\textbf{x}_{1}\\textbf{r} - \\textbf{x}_{2}\\textbf{r} = \\sum_{i=1}^{n} (x_{1,i} - x_{2, i})r_{i} \\sim N(0, l_{2}^2)\\] which means that \\(X\\) is an unbiased estimator of \\(l^{2}_{2}\\) . other distances ... what about cosine similarity, edit distance and wasserstein distance. Learning (Binary classification here) Assume data are samples from a prior distribution \\(D\\) on the universe \\(U\\) . element has its only label. mainly cares about the sample complexity. finite well-separated case finite: there is a function set \\(\\{f_{1}, ..., f_{h}\\}\\) including the ground truth \\(f^{*}\\) . well-separated: if \\(f_{i} \\neq f^{*}\\) , then the generalization error is at least \\(\\epsilon\\) . Theorem: if \\[n \\geq \\frac{1}{\\epsilon}(\\ln h+\\ln \\frac{1}{\\delta} )\\] Then with probability \\(1 - \\delta\\) , the output \\(f = f^{*}\\) . PROOF: \\(Pr[ f=^{X}f^{*} | f\\neq f^{*}] \\leq (1-\\epsilon)^{n} \\leq e^{-\\epsilon n}\\) \\(Pr[\\exists f_{i} = f^{*}] \\leq (h-1)e^{-\\epsilon n} \\leq he^{-\\epsilon n}\\) \\(he^{-\\epsilon n} \\leq \\delta\\) \\(n \\geq \\frac{1}{\\epsilon}(\\ln h + \\ln \\frac{1}{\\delta})\\) Q.E.D finite case Theorem: if \\[n \\geq \\frac{c}{\\epsilon}(\\ln h+\\ln \\frac{1}{\\delta})\\] Then with probability \\(1 - \\delta\\) , the output \\(f\\) 's generalization error is less than \\(\\epsilon\\) . easy to drive from previous theorem. Linear Classifiers Throw the assumption of finite function set. However there is still the ground true that has the form of linear classifier. Theorem: if \\[n \\geq \\frac{c}{\\epsilon}(d + \\ln \\frac{1}{\\delta})\\] Then there is a constant \\(c\\) , with probability \\(1 - \\delta\\) , the generalization error is less than \\(\\epsilon\\) . proof motivation: the curse of dimensionality (approximation). note the number of samples is linear to the dimension. (because we use about \\(e^{d}\\) functions to approximate in theory, but we usually calculate the superplane to express the function) Non-Zero Training Error and the ERM Algorithm ERM (empirical risk minimization) just output the function with minimum training error. Theorem (Uniform Convergence): if \\[n \\geq \\frac{c}{\\epsilon ^2}(d + \\ln \\frac{1}{\\delta})\\] then for every linear classifier, it holds that generalization error in training error +- \\(\\epsilon\\) Theorem (PAC for non-zero training error): easy to drive from previous theorem Increasing Dimensionality according to the previous section, when samples are larger than (or linear to) dimension, it will lead to best-fit. but for non-zero error case, we do not know the dimension exactly. So we may need to flirt with line between overfitting and generalization. when n << d, we need to increase the dimension. Polynomial embedding just add cross-product into the higher dimension. It is better when the dimension is meaningful. JL transform actually we need to apply some non-linear operator to each dimension. Because JL transform actually the combination of each dimension. In real world, the kernel function is a good way to implement. Regularization Regularization states that you have some preference of your model. There are usually two views about the effect of regularization. Bayesian view and frequentist view Bayesian view Here the regularization comes naturally from the likelihood. For example, we assume the model is \\(y = \\left \\langle x, a\\right \\rangle + z\\) \\(z \\sim N(0, 1)\\) , \\(a_{i} \\sim N(0, \\sigma^2)\\) we assume that \\(x\\) 's are fixed for simplicity. The likelihood is \\[\\mathrm{Pr}(a)\\mathrm{Pr}(\\frac{data}{a}) = \\prod_{i}^{d}e^{-\\frac{a^2_{i}}{2\\sigma^2}}\\prod_{i}^{n}e^{-\\frac{(y_{i}-\\left \\langle x_{i}, a \\right \\rangle)^{2}}{2}}\\] max this likelihood means minimize \\(\\sum_{i=1}^{d}\\frac{a_{i}^{2}}{2\\sigma^2} + \\sum_{i=1}^{n} (y_{i} - \\left \\langle x_{i}, a\\right \\rangle)^2\\) The first part is regularization. Also it shows that the regularization may depend on the hypothesis of model. Frequentist view The given example is about \\(l_{0}\\) regularization. (define \\(0^0 = 0\\) ) \\(l_{0}\\) regularization shows the sparsity. \\(l_{1}\\) regularization it can be a proxy of \\(l_{0}\\) regularization. Principle Component Analysis The motivation is that we want to map the data into a \\(d\\) - dimension vector space. Somehow we want to preserve the \\(|\\prod_{S}v| \\sim |v|\\) Luckily, we know that \\(d\\) - dimension space can be interpret into a span of d vectors \\(v_{1}, ..., v_{d}\\) . And the objective function is \\(\\max \\sum_{i=1}^{n} \\sqrt{\\sum_{j=1}^{d} \\left \\langle x_{i}, v_{j} \\right \\rangle ^{2}}\\) . why max? Because of the triangle inequality. Usually we compact the data as a matrix \\(A\\) whose columns states for attributes and row stand for pieces of data. We create a new matrix \\(X\\) of vectors \\(v\\) whose \\(i\\) th column is \\(v_{i}\\) , in order to model the objective function as matrix operation. The objective function is \\((AX)^{T}AX = X^{T}A^{T}AX = X^{T}U^{T}DUX\\) according to spectrum theorem. \\(U\\) is orthogonal matrix and \\(D\\) is diagonal matrix. Basically \\(X\\) is variable that we can choose. If \\(d=1\\) , \\(|Ux| = |x|\\) , denote \\(u = Ux\\) the objective function becomes \\(u^{T}Du\\) . Assume the elements of \\(D\\) are sorted as decreasing order. \\(u = e_{1}\\) . So \\(x = U^{T}e_{1}\\) or x is the first column of \\(U\\) . Implementation (The Power Iteration) The key problems of PCA are singular values and singular vectors. Singular polynomial is hard to find roots ... Maybe there are some ways to find reductions. But here the motivation is that we pick a vector \\(x\\) and apply to operator many times. Theorem, for any \\(\\delta, \\epsilon > 0\\) , letting \\(v_{1}\\) denote the top eigenvector of \\(A\\) , with probability at least \\(1-\\delta\\) over the choice of \\(u_{0}\\) , \\[|\\langle \\frac{A^{t}u_{0}}{|A^{t}u_{0}|}, v_{1} \\rangle| \\geq 1 - \\epsilon\\] provided \\[t > O(\\frac{\\log d + \\log \\frac{1}{\\epsilon} + \\log \\frac{1}{\\delta}}{\\log \\frac{\\lambda_{1}}{\\lambda_{2}}})\\] where \\(\\frac{\\lambda_{1}}{\\lambda_{2}}\\) is the spectral gap. proof let \\(v_{1}, \\cdots, v_{k}\\) be k orthonormal vectors. \\[ \\begin{aligned} |\\langle \\frac{A^{t}u_{0}}{|A^{t}u_{0}|}, v_{1} \\rangle | &= |\\frac{\\langle u_{0}, v_{1} \\rangle \\lambda_{1}^{t}}{\\sqrt{\\sum_{i=1}^{d}\\langle u_{0}, v_{i} \\rangle^{2} \\lambda_{i}^{2t}}}| \\\\ &\\geq |\\frac{\\langle u_{0}, v_{1}\\rangle \\lambda^{t}}{\\sqrt{\\langle u_{0}, v_{1} \\rangle^2 \\lambda_{1}^{2t} + \\lambda_{2}^{2t}}}| \\\\ &\\geq |\\frac{\\langle u_{0}, v_{i} \\rangle \\lambda^{t}}{|\\langle u_{0}, v_{1} \\rangle| \\lambda_{1}^{t} + \\lambda_{2}^{t}}|\\\\ &= |\\frac{1}{1 + \\frac{1}{\\langle u_{0}, v_{1} \\rangle } \\frac{\\lambda_{2}}{\\lambda_{1}}^{t}}| \\end{aligned} \\] So, let this < \\(\\epsilon\\) . \\[ t > \\frac{\\log |\\frac{1}{\\langle u_{0}, v_{1} \\rangle}| + \\log \\frac{1}{\\epsilon}}{\\log |\\frac{\\lambda_{1}}{\\lambda_{2}}|}\\] Someone told me that \\(\\langle u_{0}, v_{1} \\rangle > \\frac{\\delta}{2\\sqrt{d}}\\) with probability \\(1 - \\delta\\) . (I do not how to prove this.) so \\(\\log \\frac{1}{\\langle u_{0}, v_{1} \\rangle} < \\log d + \\log \\frac{1}{\\delta}\\) which completes the proof. Low-rank Matrix Decomposition SVD The key method is the SVD(Singular Value Decomposition) which states that every matrix \\(A\\) can be interpreted as \\(USV^{T}\\) I do not willing to include the proof here, because that the constructive proof shows few motivation. Some motivations are here \\[A^{T}A = (USV^{T})^{T} USV^{T} = VS^{T}SV^{T}\\] According to PCA, V contains eigen-vectors of \\(A\\) . Also \\[ AA^{T} = (VS^{T}U^{T})^{T}(VS^{T}U^{T}) = USS^{T}U^{T} \\] The similarity holds for \\(U\\) . Actually SVD links the eigenvalues of \\(A\\) and \\(A^{T}\\) Also these facts help us to calculate the SVD(just use power iteration). Low-rank Matrix Recall the matrix with rank \\(k\\) can be interpret as \\(\\sum_{i=1}^{k}\\textbf{u}_{i} \\textbf{v}_{i}^{T}\\) . under Frobenius norm, it can be shown the SVD derives the best approximation. Frobenius norm \\[||M||_{F} = \\sqrt{\\sum_{i,j}m^{2}_{i,j}}\\] for any matrix \\(A\\) and its rank-k approximation using SVD \\(A_{k}\\) . Then for any rank-k matrix \\(B\\) . Then \\[||A - A_{k}||_{F} \\leq ||A - B||_{F}\\] Although we can approximate the matrix under Frobenius norm, but the decomposition is not unique. \\[A_{k} = U_{k}V^{T}_{k} = U_{k}B^{-1}BT^{T}_{k} = (U_{k}B^{-1})(T_{k}B^{T})^{T}\\] But if we extend matrix to tensor, something will happen. Low-rank tensor Decomposition A rank-k \\(n \\times n \\times n\\) tensor \\(A\\) can be interpret as \\[A_{x,y,z} = \\sum_{i=1}^{k} u_{i}(x)v_{i}(y)w_{i}(z) \\] ATTENTION: \\((u_{1}, \\cdots, u_{k})\\) linearly independent, same for \\(v's\\) and \\(w's\\) And we can use the notation \\(\\oplus\\) . \\[A = \\sum_{i=1}^{k} u_{i} \\oplus v_{i} \\oplus w_{i}\\] Theorem: Given a 3-tensor with rank \\(k\\) , the decomposition is unique(up to scale a constant) Jenrich's algorithm random two unit vectors \\(x, y \\in \\mathbb{R}^{n}\\) define \\(A_{x}, A_{y}\\) . \\[A_{x}(a, b) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b)\\sum_{j=1}^{n}w_{i}(j)x(j) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b) \\langle w, x_{i} \\rangle\\] \\[A_{y}(a, b) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b)\\sum_{j=1}^{n}w_{i}(j)y(j) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b) \\langle w, y_{i} \\rangle\\] compute \\[A_{x}A_{y}^{-1} = QSQ^{-1}\\] \\[A_{x}^{-1}A_{y} = (Y^{T})^{-1}TY^{T}\\] with probability 1, \\(Q\\) describes \\((u_{1}, u_{2}, \\cdots, u_{k})\\) and \\(Y\\) describes \\((v_{1}, v_{2}, \\cdots, v_{k})\\) . solve the linear system to compute \\((w_{1}, w_{2}, \\cdots, w_{k})\\) . correctness: \\[A_{x} = UDV^{T}, A_{y} = UEV^{T}\\] \\[A_{x}A^{-1}_{y} = UDE^{-1}U^{-1}\\] \\[A_{x}^{-1}A_{y} = V^{T^{-1}}D^{-1}EV^{T}\\] if \\(x, y\\) pick randomly, it's likely that \\(A_{x}A_{y}^{-1}\\) and \\(A^{-1}_{x}A_{y}\\) 's eigenvalues are distinct, so we can distinguish different eigenvectors. And because of the \\(S, T\\) should be the reciprocative, so we can group correct eigenvectors. Spectral Graph Theory The magic about representing the graph as matrix. Denote rank matrix as \\(D\\) and adjacent matrix as \\(A\\) . Define Laplacian matrix as \\(L = D - A\\) . Note \\(L\\) is a symmetric matrix. now consider \\[ Lv_{i} = deg(i)v_{i} - \\sum_{j\\sim i} v_{j} = \\sum_{j \\sim i} (v_{i} - v_{j}) \\] \\[ \\begin{align} v^{T}Lv &= \\sum_{i=1}^{n} v_{i} \\sum_{j \\sim i} (v_{i} - v_{j}) \\\\ &= \\sum_{i<j: j \\sim i}(v_{i} - v_{j})^{2} \\end{align} \\] So if we put all the vertices on the real numberline. \\(v^{T}Lv\\) is the square sum of all the path. Eigenvalues and Eigenvectors \\(L\\) has \\(n\\) non-negative real eigenvalues because \\(L\\) is a symmetric matrix and \\(v^{T}Lv \\geq 0\\) . The fact is that the minimum eigenvalue is \\(0\\) . Let \\(v = (\\frac{1}{\\sqrt{n}}, \\cdots, \\frac{1}{\\sqrt{n}})\\) . \\[Lv_{i} = \\sum_{j \\sim i} (v_{i} - v_{j}) = 0\\] Theorem: The number of zero eigenvalues of the Laplacian matrix equals the number connected components of the graph. proof we first show that # connected components < # zero eigenvalues Let \\(S_{i}\\) be a maximal connected components, construct a vector \\(v\\) , \\(v_{i} = \\frac{1}{\\sqrt{|S_{i}|}} \\mathbb{I}[x \\in S_{i}]\\) So it can form # connected component orthonormal vectors. Then about the other side, recall \\(v^{T}Lv\\) , if \\(v_{k+1}\\) is orthogonal to \\(v_{1}, \\cdots, v_{k}\\) , assume \\(v_{k+1, j} \\neq 0\\) , then for positions of the same maximal connected component must \\(\\neq 0\\) , so it must not orthogonal to all vectors. \\(\\blacksquare\\) Conductance and isoperimeter Some intuitions are that \\(v^{T}Lv = \\lambda v^{T}v = \\sum_{i \\sim j} (v_{i} - v_{j})^{2}\\) , the 2nd smallest eigenvalue somehow place vertices ``near''. This fact can be used to embed vertices into a \\(d\\) -dimensional space. Map vertex \\(i\\) to \\((v_{2}(i), v_{3}(i))\\) making the adjacancy near. While choose the 2 largest eigenvector will bring them apart. This also lead to the implementation in clustering and graph coloring. Definition: isoperimeter of a cut \\(\\theta(S)\\) \\[\\theta(S) = \\frac{|\\delta(S)|}{\\min(|S|, |V - S|)}\\] The isoperimeter ratio of the graph \\(G\\) is \\[\\min_{S \\subset V(G)} \\delta(S)\\] This number interpret the connectivity of a graph. And the second smallest eigenvalue \\(\\lambda_{2}\\) (maybe \\(\\lambda_{2} = 0\\) ) will give some insight of this number like those intuitions above. Theorem: Given a graph \\(G = (V, E)\\) and any set \\(S \\subset V\\) , it holds that \\[\\delta(S) \\geq \\lambda_{2} (1 - \\frac{\\min(|S|, |V - S|)}{|V|})\\] proof: We assume that \\(|S| < |V - S|\\) . We can interpret \\(\\delta(S)\\) by \\(v^{T}Lv\\) . Define \\(v\\) as when \\(i \\notin S\\) , \\(v(i) = -\\frac{|S|}{|V|}\\) , while \\(i \\in S\\) , \\(v(i) = 1 - \\frac{|S|}{|V|}\\) . \\[v^{T}Lv = \\sum_{(i,j) \\in \\delta(S)} (v_{i} - v_{j})^{2} = |\\delta(S)|\\] Recall that if \\(\\lambda_{1}, \\cdots, \\lambda_{n}\\) and \\(v_{1}, \\cdots, v_{n}\\) are eigenvalues and eigenvectors of \\(L\\) . \\[v^{T}Lv = \\sum_{i=1}^{n} \\langle v, v_{i} \\rangle v_{i}^{T}v_{i}\\] So if we extract the eigenvalue \\(0\\) and corresponding eigenvector \\((\\frac{1}{\\sqrt{n}}, \\cdots, \\frac{1}{\\sqrt{n}})\\) . So \\[\\lambda_{2} = \\min_{x: x^{T}v_{1} = 0} \\frac{v^{T}Lv}{v^{T}v} \\leq \\frac{|\\delta(S)|}{|S|(1 - \\frac{|S|}{|v|})}\\] So \\[|\\delta(S)| \\geq \\lambda_{2} |S|(1 - \\frac{|S|}{|V|})\\] \\(\\blacksquare\\) Cheeger's Theorem If \\(\\lambda_{2}\\) is the second smallest eigenvalue of a d-regular graph, Then there exists a set \\(S \\subset V\\) such that \\[\\frac{\\lambda_{2}}{2d} \\leq \\mathrm{cond}(S) \\leq \\frac{\\sqrt{2\\lambda_{2}}}{\\sqrt{d}}\\] Diffusion model and Random walks Let \\(w: V \\rightarrow \\mathbb{R}\\) , define this process \\(w_{i+1}(x) = \\frac{1}{\\mathrm{Adj}(x)}\\sum_{x\\sim y}w_{i}(y)\\) So we know that \\(w_{i+1} = D^{-1}Aw_{i}\\) This is actually the power iteration. Sampling and estimation Reservoir Sampling want to sample \\(k\\) data from totally \\(N\\) data uniformly. Just recall how to implement permutation in C++. uniform random swap this datum with some element existing. Markov inequality and Chebyshev's inequality all included by the ''counting and sampling'' Importance Sampling intuitions are sample more important data (long-tail distribution) or much variance data (cut down variance). Estimating the missing mass Good-Turing frequency estimation scheme. \\[\\mathbb{Pr}[next draw is something new] \\approx \\frac{\\# elements\\quad seen\\quad once}{n}\\] MCMC Theorem Fundamental theory of Markov Chain for every two states \\(s_{i}, s_{j}\\) , it is possible to eventually get to state \\(s_{j}\\) , if one starts in state \\(s_{i}\\) . The chain is aperiodic: for a pair states, \\(s_{i}\\) , \\(s_{j}\\) , consider the set of time \\(\\{t_{1}, t_{2},\\cdots \\}\\) consisting of all \\(t\\) for which \\(\\mathbb{Pr}[X_{t}=s_{j}|X_{0}=s_{i}]>0\\) . A chain is aperiodic if $gcd({t_{1}, t_{2},\\cdots })=1 $ Then for any states \\(s\\) , \\[\\lim_{t \\rightarrow \\infty}D(t,s) \\rightarrow \\pi\\] other information will be included by Counting and sampling. Discrete Fourier Transform and Convolution As a mathematical tool, Fourier transform has a variety of implementations. There are also different versions to define Fourier transform. Matrix form \\[\\mathcal{F}(v) = M_{n}v\\] Let \\(w_{n} = e^{-\\frac{2\\pi i}{n}}\\) . Then \\(M_{i,j} = w_{n}^{ij}\\) . NB \\(M_{n}\\) is 0-indexed. To get the inverse of \\(M\\) , first consider \\(M^{2}\\) consider \\(k\\) th column of \\(M\\) is \\((e^{-\\frac{2\\pi i 0}{n}}, e^{-\\frac{2\\pi ik}{n}}, e^{-\\frac{2\\pi i2k}{n}}, \\cdots, e^{-\\frac{2\\pi i(n-1)k}{n}})^{T}\\) \\(M\\) is a symmetric matrix. So its \\(p\\) th row is \\((e^{-\\frac{2\\pi i0}{n}}, e^{-\\frac{2\\pi ip}{n}}, e^{-\\frac{2\\pi i 2p}{n}}, \\cdots, e^{-\\frac{2\\pi i(n-1)p}{n}})\\) compute inner-product When \\(1 \\neq e^{- \\frac{2\\pi i (k+p)}{n}}\\) \\[\\sum_{j=0}^{n-1} e^{-\\frac{2\\pi ij(k+p)}{n}} = \\frac{1 - e^{-2\\pi i(k+q)}}{1 - e^{-\\frac{2\\pi i(k+q)}{n}}}\\] So \\(M^{2}\\) is analogous with the \\(\\mathbb{I}_{n}\\) Let \\(k\\) th column of \\(M\\) be \\(M^{i}\\) . Then \\[M^{-1} = \\frac{1}{n}(M^{1}, M^{n}, M^{n-1}, \\cdots, M^{2})\\] We can also use inverse representation of \\(w_{n}\\) . Polynomial evaluation and interpolation Matrix in that form can be view as linear polynomial evaluation on specific points set. Both the evaluation and interpolation can be done in \\(O(n\\log n)\\) time. Also the killer method is the convolution. Change of basis The discrete Fourier transform can be viewed as a way of basis decomposition like the continuous version of Fourier transform. The Fast Fourier transform Discrete fourier transform can be done in \\(O(n\\log n)\\) time much faster than the matrix multiplication. Intuitively \\(M\\) are well-structured. Convolution There are many ways to define convolution. One is using polynomial multiplication. Definition: the convolution of two vectors \\(v, w\\) of respective length \\(n, m\\) is denoted \\(v*u = u*v\\) and is defined to be the vector of coefficients of the product of the polynomials associated to \\(v\\) and \\(w\\) , \\(P_{v}(x)P_{w}(x)\\) . Fact: convolution can be interpreted by Fourier transform as \\[v*w = \\mathcal{F}^{-1}(\\mathcal{F}(v) \\times \\mathcal{F}(w))\\] NB here we do not specify the dimension of Fourier transform. But with the view of polynomial multiplication, the dimension is at least \\(n + m\\) . (The continuous version of Fourier transform usually has infinite dimensions.) Also if \\(q = v*w\\) , then \\[v = \\mathcal{F}^{-1}(\\mathcal{F}(q)./\\mathcal{F}(w))\\] Another definition: Any transformation of a vector that is linear and translational invariant is a convolution. Can be used in differential equations and physical force.(?)","title":"CS168 The Modern Algorithmic Toolbox"},{"location":"blog/2022/CS168Toolbox/#dimensionality-reduction","text":"Want to reduce the large dimension into small dimension ( usually independent with input size ) while preserving distance.","title":"Dimensionality Reduction"},{"location":"blog/2022/CS168Toolbox/#distance","text":"distance or similarity exact distance: 1 - [x==y] similarity of set ( or multi-set ): Jaccard Similarity \\(J(S,T) = \\frac{|S \\bigcap T|}{|S\\bigcup T|}\\) \\(l_{p}\\) distance.","title":"Distance"},{"location":"blog/2022/CS168Toolbox/#framework","text":"reduce dimension while preserving expect. Then use independent trials.","title":"framework"},{"location":"blog/2022/CS168Toolbox/#exact-distance","text":"use universal hash function assumption assume \\(h: U \\rightarrow [b]+1\\) k hash function \\(h_{1}, h_{2}, ... , h_{k}\\)","title":"exact distance"},{"location":"blog/2022/CS168Toolbox/#epsilon-heavy-hitters","text":"\\[\\# = \\min_{i=1}^{k} B(f_{i}(x)) = \\min_{i=1}^{k} \\sum_{j=1}^{n}[f_{i}(x) = f_{j}(x)]\\] \\[E[\\#] = \\min_{i=1}^{k} \\sum_{j=1}^{n}E[[f_{i}(x) = f_{j}(x)]] = \\#x + \\frac{n-\\#x}{b} \\leq \\#x + \\frac{n}{b}\\] use Markov's inequality \\[\\mathrm{Pr}[\\# - \\#x > \\delta \\frac{n}{b}] \\leq \\frac{1}{\\delta}\\] to achieve \\((\\delta, \\epsilon)\\) , let \\(b = \\frac{2}{\\epsilon}\\) , \\(\\delta = 2\\) . Then use independent trials \\(\\frac{1}{2^{p}} < \\delta\\) , then \\(p = \\log(\\frac{1}{\\delta})\\) .","title":"\\(\\epsilon\\) -  Heavy Hitters"},{"location":"blog/2022/CS168Toolbox/#jaccard-similarity","text":"pick a random permutation of \\(U\\) . hash each element to the smallest element.","title":"Jaccard similarity"},{"location":"blog/2022/CS168Toolbox/#l_2-distance-johnson-lindenstrauss-transform","text":"motivation: random projection (inner product with a vector generated by standard Gaussian distribution) random vector \\(\\textbf{r} \\sim N^{n}(0, 1)\\) \\[X = \\textbf{x}_{1}\\textbf{r} - \\textbf{x}_{2}\\textbf{r} = \\sum_{i=1}^{n} (x_{1,i} - x_{2, i})r_{i} \\sim N(0, l_{2}^2)\\] which means that \\(X\\) is an unbiased estimator of \\(l^{2}_{2}\\) .","title":"\\(l_{2}\\) distance - Johnson-Lindenstrauss transform"},{"location":"blog/2022/CS168Toolbox/#other-distances","text":"what about cosine similarity, edit distance and wasserstein distance.","title":"other distances ..."},{"location":"blog/2022/CS168Toolbox/#learning-binary-classification-here","text":"Assume data are samples from a prior distribution \\(D\\) on the universe \\(U\\) . element has its only label. mainly cares about the sample complexity.","title":"Learning (Binary classification here)"},{"location":"blog/2022/CS168Toolbox/#finite-well-separated-case","text":"finite: there is a function set \\(\\{f_{1}, ..., f_{h}\\}\\) including the ground truth \\(f^{*}\\) . well-separated: if \\(f_{i} \\neq f^{*}\\) , then the generalization error is at least \\(\\epsilon\\) . Theorem: if \\[n \\geq \\frac{1}{\\epsilon}(\\ln h+\\ln \\frac{1}{\\delta} )\\] Then with probability \\(1 - \\delta\\) , the output \\(f = f^{*}\\) . PROOF: \\(Pr[ f=^{X}f^{*} | f\\neq f^{*}] \\leq (1-\\epsilon)^{n} \\leq e^{-\\epsilon n}\\) \\(Pr[\\exists f_{i} = f^{*}] \\leq (h-1)e^{-\\epsilon n} \\leq he^{-\\epsilon n}\\) \\(he^{-\\epsilon n} \\leq \\delta\\) \\(n \\geq \\frac{1}{\\epsilon}(\\ln h + \\ln \\frac{1}{\\delta})\\) Q.E.D","title":"finite well-separated case"},{"location":"blog/2022/CS168Toolbox/#finite-case","text":"Theorem: if \\[n \\geq \\frac{c}{\\epsilon}(\\ln h+\\ln \\frac{1}{\\delta})\\] Then with probability \\(1 - \\delta\\) , the output \\(f\\) 's generalization error is less than \\(\\epsilon\\) . easy to drive from previous theorem.","title":"finite case"},{"location":"blog/2022/CS168Toolbox/#linear-classifiers","text":"Throw the assumption of finite function set. However there is still the ground true that has the form of linear classifier. Theorem: if \\[n \\geq \\frac{c}{\\epsilon}(d + \\ln \\frac{1}{\\delta})\\] Then there is a constant \\(c\\) , with probability \\(1 - \\delta\\) , the generalization error is less than \\(\\epsilon\\) . proof motivation: the curse of dimensionality (approximation). note the number of samples is linear to the dimension. (because we use about \\(e^{d}\\) functions to approximate in theory, but we usually calculate the superplane to express the function)","title":"Linear Classifiers"},{"location":"blog/2022/CS168Toolbox/#non-zero-training-error-and-the-erm-algorithm","text":"ERM (empirical risk minimization) just output the function with minimum training error. Theorem (Uniform Convergence): if \\[n \\geq \\frac{c}{\\epsilon ^2}(d + \\ln \\frac{1}{\\delta})\\] then for every linear classifier, it holds that generalization error in training error +- \\(\\epsilon\\) Theorem (PAC for non-zero training error): easy to drive from previous theorem","title":"Non-Zero Training Error and the ERM Algorithm"},{"location":"blog/2022/CS168Toolbox/#increasing-dimensionality","text":"according to the previous section, when samples are larger than (or linear to) dimension, it will lead to best-fit. but for non-zero error case, we do not know the dimension exactly. So we may need to flirt with line between overfitting and generalization. when n << d, we need to increase the dimension.","title":"Increasing Dimensionality"},{"location":"blog/2022/CS168Toolbox/#polynomial-embedding","text":"just add cross-product into the higher dimension. It is better when the dimension is meaningful.","title":"Polynomial embedding"},{"location":"blog/2022/CS168Toolbox/#jl-transform","text":"actually we need to apply some non-linear operator to each dimension. Because JL transform actually the combination of each dimension. In real world, the kernel function is a good way to implement.","title":"JL transform"},{"location":"blog/2022/CS168Toolbox/#regularization","text":"Regularization states that you have some preference of your model. There are usually two views about the effect of regularization. Bayesian view and frequentist view","title":"Regularization"},{"location":"blog/2022/CS168Toolbox/#bayesian-view","text":"Here the regularization comes naturally from the likelihood. For example, we assume the model is \\(y = \\left \\langle x, a\\right \\rangle + z\\) \\(z \\sim N(0, 1)\\) , \\(a_{i} \\sim N(0, \\sigma^2)\\) we assume that \\(x\\) 's are fixed for simplicity. The likelihood is \\[\\mathrm{Pr}(a)\\mathrm{Pr}(\\frac{data}{a}) = \\prod_{i}^{d}e^{-\\frac{a^2_{i}}{2\\sigma^2}}\\prod_{i}^{n}e^{-\\frac{(y_{i}-\\left \\langle x_{i}, a \\right \\rangle)^{2}}{2}}\\] max this likelihood means minimize \\(\\sum_{i=1}^{d}\\frac{a_{i}^{2}}{2\\sigma^2} + \\sum_{i=1}^{n} (y_{i} - \\left \\langle x_{i}, a\\right \\rangle)^2\\) The first part is regularization. Also it shows that the regularization may depend on the hypothesis of model.","title":"Bayesian view"},{"location":"blog/2022/CS168Toolbox/#frequentist-view","text":"The given example is about \\(l_{0}\\) regularization. (define \\(0^0 = 0\\) ) \\(l_{0}\\) regularization shows the sparsity.","title":"Frequentist view"},{"location":"blog/2022/CS168Toolbox/#l_1-regularization","text":"it can be a proxy of \\(l_{0}\\) regularization.","title":"\\(l_{1}\\) regularization"},{"location":"blog/2022/CS168Toolbox/#principle-component-analysis","text":"The motivation is that we want to map the data into a \\(d\\) - dimension vector space. Somehow we want to preserve the \\(|\\prod_{S}v| \\sim |v|\\) Luckily, we know that \\(d\\) - dimension space can be interpret into a span of d vectors \\(v_{1}, ..., v_{d}\\) . And the objective function is \\(\\max \\sum_{i=1}^{n} \\sqrt{\\sum_{j=1}^{d} \\left \\langle x_{i}, v_{j} \\right \\rangle ^{2}}\\) . why max? Because of the triangle inequality. Usually we compact the data as a matrix \\(A\\) whose columns states for attributes and row stand for pieces of data. We create a new matrix \\(X\\) of vectors \\(v\\) whose \\(i\\) th column is \\(v_{i}\\) , in order to model the objective function as matrix operation. The objective function is \\((AX)^{T}AX = X^{T}A^{T}AX = X^{T}U^{T}DUX\\) according to spectrum theorem. \\(U\\) is orthogonal matrix and \\(D\\) is diagonal matrix. Basically \\(X\\) is variable that we can choose. If \\(d=1\\) , \\(|Ux| = |x|\\) , denote \\(u = Ux\\) the objective function becomes \\(u^{T}Du\\) . Assume the elements of \\(D\\) are sorted as decreasing order. \\(u = e_{1}\\) . So \\(x = U^{T}e_{1}\\) or x is the first column of \\(U\\) .","title":"Principle Component Analysis"},{"location":"blog/2022/CS168Toolbox/#implementation-the-power-iteration","text":"The key problems of PCA are singular values and singular vectors. Singular polynomial is hard to find roots ... Maybe there are some ways to find reductions. But here the motivation is that we pick a vector \\(x\\) and apply to operator many times. Theorem, for any \\(\\delta, \\epsilon > 0\\) , letting \\(v_{1}\\) denote the top eigenvector of \\(A\\) , with probability at least \\(1-\\delta\\) over the choice of \\(u_{0}\\) , \\[|\\langle \\frac{A^{t}u_{0}}{|A^{t}u_{0}|}, v_{1} \\rangle| \\geq 1 - \\epsilon\\] provided \\[t > O(\\frac{\\log d + \\log \\frac{1}{\\epsilon} + \\log \\frac{1}{\\delta}}{\\log \\frac{\\lambda_{1}}{\\lambda_{2}}})\\] where \\(\\frac{\\lambda_{1}}{\\lambda_{2}}\\) is the spectral gap. proof let \\(v_{1}, \\cdots, v_{k}\\) be k orthonormal vectors. \\[ \\begin{aligned} |\\langle \\frac{A^{t}u_{0}}{|A^{t}u_{0}|}, v_{1} \\rangle | &= |\\frac{\\langle u_{0}, v_{1} \\rangle \\lambda_{1}^{t}}{\\sqrt{\\sum_{i=1}^{d}\\langle u_{0}, v_{i} \\rangle^{2} \\lambda_{i}^{2t}}}| \\\\ &\\geq |\\frac{\\langle u_{0}, v_{1}\\rangle \\lambda^{t}}{\\sqrt{\\langle u_{0}, v_{1} \\rangle^2 \\lambda_{1}^{2t} + \\lambda_{2}^{2t}}}| \\\\ &\\geq |\\frac{\\langle u_{0}, v_{i} \\rangle \\lambda^{t}}{|\\langle u_{0}, v_{1} \\rangle| \\lambda_{1}^{t} + \\lambda_{2}^{t}}|\\\\ &= |\\frac{1}{1 + \\frac{1}{\\langle u_{0}, v_{1} \\rangle } \\frac{\\lambda_{2}}{\\lambda_{1}}^{t}}| \\end{aligned} \\] So, let this < \\(\\epsilon\\) . \\[ t > \\frac{\\log |\\frac{1}{\\langle u_{0}, v_{1} \\rangle}| + \\log \\frac{1}{\\epsilon}}{\\log |\\frac{\\lambda_{1}}{\\lambda_{2}}|}\\] Someone told me that \\(\\langle u_{0}, v_{1} \\rangle > \\frac{\\delta}{2\\sqrt{d}}\\) with probability \\(1 - \\delta\\) . (I do not how to prove this.) so \\(\\log \\frac{1}{\\langle u_{0}, v_{1} \\rangle} < \\log d + \\log \\frac{1}{\\delta}\\) which completes the proof.","title":"Implementation (The Power Iteration)"},{"location":"blog/2022/CS168Toolbox/#low-rank-matrix-decomposition","text":"","title":"Low-rank Matrix Decomposition"},{"location":"blog/2022/CS168Toolbox/#svd","text":"The key method is the SVD(Singular Value Decomposition) which states that every matrix \\(A\\) can be interpreted as \\(USV^{T}\\) I do not willing to include the proof here, because that the constructive proof shows few motivation. Some motivations are here \\[A^{T}A = (USV^{T})^{T} USV^{T} = VS^{T}SV^{T}\\] According to PCA, V contains eigen-vectors of \\(A\\) . Also \\[ AA^{T} = (VS^{T}U^{T})^{T}(VS^{T}U^{T}) = USS^{T}U^{T} \\] The similarity holds for \\(U\\) . Actually SVD links the eigenvalues of \\(A\\) and \\(A^{T}\\) Also these facts help us to calculate the SVD(just use power iteration).","title":"SVD"},{"location":"blog/2022/CS168Toolbox/#low-rank-matrix","text":"Recall the matrix with rank \\(k\\) can be interpret as \\(\\sum_{i=1}^{k}\\textbf{u}_{i} \\textbf{v}_{i}^{T}\\) . under Frobenius norm, it can be shown the SVD derives the best approximation. Frobenius norm \\[||M||_{F} = \\sqrt{\\sum_{i,j}m^{2}_{i,j}}\\] for any matrix \\(A\\) and its rank-k approximation using SVD \\(A_{k}\\) . Then for any rank-k matrix \\(B\\) . Then \\[||A - A_{k}||_{F} \\leq ||A - B||_{F}\\] Although we can approximate the matrix under Frobenius norm, but the decomposition is not unique. \\[A_{k} = U_{k}V^{T}_{k} = U_{k}B^{-1}BT^{T}_{k} = (U_{k}B^{-1})(T_{k}B^{T})^{T}\\] But if we extend matrix to tensor, something will happen.","title":"Low-rank Matrix"},{"location":"blog/2022/CS168Toolbox/#low-rank-tensor-decomposition","text":"A rank-k \\(n \\times n \\times n\\) tensor \\(A\\) can be interpret as \\[A_{x,y,z} = \\sum_{i=1}^{k} u_{i}(x)v_{i}(y)w_{i}(z) \\] ATTENTION: \\((u_{1}, \\cdots, u_{k})\\) linearly independent, same for \\(v's\\) and \\(w's\\) And we can use the notation \\(\\oplus\\) . \\[A = \\sum_{i=1}^{k} u_{i} \\oplus v_{i} \\oplus w_{i}\\] Theorem: Given a 3-tensor with rank \\(k\\) , the decomposition is unique(up to scale a constant)","title":"Low-rank tensor Decomposition"},{"location":"blog/2022/CS168Toolbox/#jenrichs-algorithm","text":"random two unit vectors \\(x, y \\in \\mathbb{R}^{n}\\) define \\(A_{x}, A_{y}\\) . \\[A_{x}(a, b) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b)\\sum_{j=1}^{n}w_{i}(j)x(j) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b) \\langle w, x_{i} \\rangle\\] \\[A_{y}(a, b) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b)\\sum_{j=1}^{n}w_{i}(j)y(j) = \\sum_{i=1}^{k} u_{i}(a) v_{i}(b) \\langle w, y_{i} \\rangle\\] compute \\[A_{x}A_{y}^{-1} = QSQ^{-1}\\] \\[A_{x}^{-1}A_{y} = (Y^{T})^{-1}TY^{T}\\] with probability 1, \\(Q\\) describes \\((u_{1}, u_{2}, \\cdots, u_{k})\\) and \\(Y\\) describes \\((v_{1}, v_{2}, \\cdots, v_{k})\\) . solve the linear system to compute \\((w_{1}, w_{2}, \\cdots, w_{k})\\) . correctness: \\[A_{x} = UDV^{T}, A_{y} = UEV^{T}\\] \\[A_{x}A^{-1}_{y} = UDE^{-1}U^{-1}\\] \\[A_{x}^{-1}A_{y} = V^{T^{-1}}D^{-1}EV^{T}\\] if \\(x, y\\) pick randomly, it's likely that \\(A_{x}A_{y}^{-1}\\) and \\(A^{-1}_{x}A_{y}\\) 's eigenvalues are distinct, so we can distinguish different eigenvectors. And because of the \\(S, T\\) should be the reciprocative, so we can group correct eigenvectors.","title":"Jenrich's algorithm"},{"location":"blog/2022/CS168Toolbox/#spectral-graph-theory","text":"The magic about representing the graph as matrix. Denote rank matrix as \\(D\\) and adjacent matrix as \\(A\\) . Define Laplacian matrix as \\(L = D - A\\) . Note \\(L\\) is a symmetric matrix. now consider \\[ Lv_{i} = deg(i)v_{i} - \\sum_{j\\sim i} v_{j} = \\sum_{j \\sim i} (v_{i} - v_{j}) \\] \\[ \\begin{align} v^{T}Lv &= \\sum_{i=1}^{n} v_{i} \\sum_{j \\sim i} (v_{i} - v_{j}) \\\\ &= \\sum_{i<j: j \\sim i}(v_{i} - v_{j})^{2} \\end{align} \\] So if we put all the vertices on the real numberline. \\(v^{T}Lv\\) is the square sum of all the path.","title":"Spectral Graph Theory"},{"location":"blog/2022/CS168Toolbox/#eigenvalues-and-eigenvectors","text":"\\(L\\) has \\(n\\) non-negative real eigenvalues because \\(L\\) is a symmetric matrix and \\(v^{T}Lv \\geq 0\\) . The fact is that the minimum eigenvalue is \\(0\\) . Let \\(v = (\\frac{1}{\\sqrt{n}}, \\cdots, \\frac{1}{\\sqrt{n}})\\) . \\[Lv_{i} = \\sum_{j \\sim i} (v_{i} - v_{j}) = 0\\] Theorem: The number of zero eigenvalues of the Laplacian matrix equals the number connected components of the graph. proof we first show that # connected components < # zero eigenvalues Let \\(S_{i}\\) be a maximal connected components, construct a vector \\(v\\) , \\(v_{i} = \\frac{1}{\\sqrt{|S_{i}|}} \\mathbb{I}[x \\in S_{i}]\\) So it can form # connected component orthonormal vectors. Then about the other side, recall \\(v^{T}Lv\\) , if \\(v_{k+1}\\) is orthogonal to \\(v_{1}, \\cdots, v_{k}\\) , assume \\(v_{k+1, j} \\neq 0\\) , then for positions of the same maximal connected component must \\(\\neq 0\\) , so it must not orthogonal to all vectors. \\(\\blacksquare\\)","title":"Eigenvalues and Eigenvectors"},{"location":"blog/2022/CS168Toolbox/#conductance-and-isoperimeter","text":"Some intuitions are that \\(v^{T}Lv = \\lambda v^{T}v = \\sum_{i \\sim j} (v_{i} - v_{j})^{2}\\) , the 2nd smallest eigenvalue somehow place vertices ``near''. This fact can be used to embed vertices into a \\(d\\) -dimensional space. Map vertex \\(i\\) to \\((v_{2}(i), v_{3}(i))\\) making the adjacancy near. While choose the 2 largest eigenvector will bring them apart. This also lead to the implementation in clustering and graph coloring. Definition: isoperimeter of a cut \\(\\theta(S)\\) \\[\\theta(S) = \\frac{|\\delta(S)|}{\\min(|S|, |V - S|)}\\] The isoperimeter ratio of the graph \\(G\\) is \\[\\min_{S \\subset V(G)} \\delta(S)\\] This number interpret the connectivity of a graph. And the second smallest eigenvalue \\(\\lambda_{2}\\) (maybe \\(\\lambda_{2} = 0\\) ) will give some insight of this number like those intuitions above. Theorem: Given a graph \\(G = (V, E)\\) and any set \\(S \\subset V\\) , it holds that \\[\\delta(S) \\geq \\lambda_{2} (1 - \\frac{\\min(|S|, |V - S|)}{|V|})\\] proof: We assume that \\(|S| < |V - S|\\) . We can interpret \\(\\delta(S)\\) by \\(v^{T}Lv\\) . Define \\(v\\) as when \\(i \\notin S\\) , \\(v(i) = -\\frac{|S|}{|V|}\\) , while \\(i \\in S\\) , \\(v(i) = 1 - \\frac{|S|}{|V|}\\) . \\[v^{T}Lv = \\sum_{(i,j) \\in \\delta(S)} (v_{i} - v_{j})^{2} = |\\delta(S)|\\] Recall that if \\(\\lambda_{1}, \\cdots, \\lambda_{n}\\) and \\(v_{1}, \\cdots, v_{n}\\) are eigenvalues and eigenvectors of \\(L\\) . \\[v^{T}Lv = \\sum_{i=1}^{n} \\langle v, v_{i} \\rangle v_{i}^{T}v_{i}\\] So if we extract the eigenvalue \\(0\\) and corresponding eigenvector \\((\\frac{1}{\\sqrt{n}}, \\cdots, \\frac{1}{\\sqrt{n}})\\) . So \\[\\lambda_{2} = \\min_{x: x^{T}v_{1} = 0} \\frac{v^{T}Lv}{v^{T}v} \\leq \\frac{|\\delta(S)|}{|S|(1 - \\frac{|S|}{|v|})}\\] So \\[|\\delta(S)| \\geq \\lambda_{2} |S|(1 - \\frac{|S|}{|V|})\\] \\(\\blacksquare\\) Cheeger's Theorem If \\(\\lambda_{2}\\) is the second smallest eigenvalue of a d-regular graph, Then there exists a set \\(S \\subset V\\) such that \\[\\frac{\\lambda_{2}}{2d} \\leq \\mathrm{cond}(S) \\leq \\frac{\\sqrt{2\\lambda_{2}}}{\\sqrt{d}}\\]","title":"Conductance and isoperimeter"},{"location":"blog/2022/CS168Toolbox/#diffusion-model-and-random-walks","text":"Let \\(w: V \\rightarrow \\mathbb{R}\\) , define this process \\(w_{i+1}(x) = \\frac{1}{\\mathrm{Adj}(x)}\\sum_{x\\sim y}w_{i}(y)\\) So we know that \\(w_{i+1} = D^{-1}Aw_{i}\\) This is actually the power iteration.","title":"Diffusion model and Random walks"},{"location":"blog/2022/CS168Toolbox/#sampling-and-estimation","text":"","title":"Sampling and estimation"},{"location":"blog/2022/CS168Toolbox/#reservoir-sampling","text":"want to sample \\(k\\) data from totally \\(N\\) data uniformly. Just recall how to implement permutation in C++. uniform random swap this datum with some element existing.","title":"Reservoir Sampling"},{"location":"blog/2022/CS168Toolbox/#markov-inequality-and-chebyshevs-inequality","text":"all included by the ''counting and sampling''","title":"Markov inequality and Chebyshev's inequality"},{"location":"blog/2022/CS168Toolbox/#importance-sampling","text":"intuitions are sample more important data (long-tail distribution) or much variance data (cut down variance).","title":"Importance Sampling"},{"location":"blog/2022/CS168Toolbox/#estimating-the-missing-mass","text":"Good-Turing frequency estimation scheme. \\[\\mathbb{Pr}[next draw is something new] \\approx \\frac{\\# elements\\quad seen\\quad once}{n}\\]","title":"Estimating the missing mass"},{"location":"blog/2022/CS168Toolbox/#mcmc","text":"Theorem Fundamental theory of Markov Chain for every two states \\(s_{i}, s_{j}\\) , it is possible to eventually get to state \\(s_{j}\\) , if one starts in state \\(s_{i}\\) . The chain is aperiodic: for a pair states, \\(s_{i}\\) , \\(s_{j}\\) , consider the set of time \\(\\{t_{1}, t_{2},\\cdots \\}\\) consisting of all \\(t\\) for which \\(\\mathbb{Pr}[X_{t}=s_{j}|X_{0}=s_{i}]>0\\) . A chain is aperiodic if $gcd({t_{1}, t_{2},\\cdots })=1 $ Then for any states \\(s\\) , \\[\\lim_{t \\rightarrow \\infty}D(t,s) \\rightarrow \\pi\\] other information will be included by Counting and sampling.","title":"MCMC"},{"location":"blog/2022/CS168Toolbox/#discrete-fourier-transform-and-convolution","text":"As a mathematical tool, Fourier transform has a variety of implementations. There are also different versions to define Fourier transform.","title":"Discrete Fourier Transform and Convolution"},{"location":"blog/2022/CS168Toolbox/#matrix-form","text":"\\[\\mathcal{F}(v) = M_{n}v\\] Let \\(w_{n} = e^{-\\frac{2\\pi i}{n}}\\) . Then \\(M_{i,j} = w_{n}^{ij}\\) . NB \\(M_{n}\\) is 0-indexed. To get the inverse of \\(M\\) , first consider \\(M^{2}\\) consider \\(k\\) th column of \\(M\\) is \\((e^{-\\frac{2\\pi i 0}{n}}, e^{-\\frac{2\\pi ik}{n}}, e^{-\\frac{2\\pi i2k}{n}}, \\cdots, e^{-\\frac{2\\pi i(n-1)k}{n}})^{T}\\) \\(M\\) is a symmetric matrix. So its \\(p\\) th row is \\((e^{-\\frac{2\\pi i0}{n}}, e^{-\\frac{2\\pi ip}{n}}, e^{-\\frac{2\\pi i 2p}{n}}, \\cdots, e^{-\\frac{2\\pi i(n-1)p}{n}})\\) compute inner-product When \\(1 \\neq e^{- \\frac{2\\pi i (k+p)}{n}}\\) \\[\\sum_{j=0}^{n-1} e^{-\\frac{2\\pi ij(k+p)}{n}} = \\frac{1 - e^{-2\\pi i(k+q)}}{1 - e^{-\\frac{2\\pi i(k+q)}{n}}}\\] So \\(M^{2}\\) is analogous with the \\(\\mathbb{I}_{n}\\) Let \\(k\\) th column of \\(M\\) be \\(M^{i}\\) . Then \\[M^{-1} = \\frac{1}{n}(M^{1}, M^{n}, M^{n-1}, \\cdots, M^{2})\\] We can also use inverse representation of \\(w_{n}\\) .","title":"Matrix form"},{"location":"blog/2022/CS168Toolbox/#polynomial-evaluation-and-interpolation","text":"Matrix in that form can be view as linear polynomial evaluation on specific points set. Both the evaluation and interpolation can be done in \\(O(n\\log n)\\) time. Also the killer method is the convolution.","title":"Polynomial evaluation and interpolation"},{"location":"blog/2022/CS168Toolbox/#change-of-basis","text":"The discrete Fourier transform can be viewed as a way of basis decomposition like the continuous version of Fourier transform.","title":"Change of basis"},{"location":"blog/2022/CS168Toolbox/#the-fast-fourier-transform","text":"Discrete fourier transform can be done in \\(O(n\\log n)\\) time much faster than the matrix multiplication. Intuitively \\(M\\) are well-structured.","title":"The Fast Fourier transform"},{"location":"blog/2022/CS168Toolbox/#convolution","text":"There are many ways to define convolution. One is using polynomial multiplication. Definition: the convolution of two vectors \\(v, w\\) of respective length \\(n, m\\) is denoted \\(v*u = u*v\\) and is defined to be the vector of coefficients of the product of the polynomials associated to \\(v\\) and \\(w\\) , \\(P_{v}(x)P_{w}(x)\\) . Fact: convolution can be interpreted by Fourier transform as \\[v*w = \\mathcal{F}^{-1}(\\mathcal{F}(v) \\times \\mathcal{F}(w))\\] NB here we do not specify the dimension of Fourier transform. But with the view of polynomial multiplication, the dimension is at least \\(n + m\\) . (The continuous version of Fourier transform usually has infinite dimensions.) Also if \\(q = v*w\\) , then \\[v = \\mathcal{F}^{-1}(\\mathcal{F}(q)./\\mathcal{F}(w))\\] Another definition: Any transformation of a vector that is linear and translational invariant is a convolution. Can be used in differential equations and physical force.(?)","title":"Convolution"},{"location":"blog/2022/Counting%20and%20sampling/","tags":["tcs"],"text":"A notes for CSE 599: Counting and Sampling. What is sampling: Assume there is a giant space \\(\\Omega\\) (usually finite). There is a function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) . And the unknown partition function \\(Z = \\sum_{x \\in \\Omega} w(x)\\) . We need to generate a sample \\(x\\) with probability \\(\\frac{w(s)}{Z}\\) . Definition of \\(\\#P\\) : a function \\(f \\in \\#P\\) if and only if it counts accept paths of a NTM of a problem in \\(NP\\) . Or equally count the evidences. So #Circuit-SAT is #P-complete. And if #R is #P-complete, them R is in NP-Complete. Counting and sampling deals with some #P problems. Definition of multiplicative error: real value \\(p\\) and estimation \\(\\tilde{p}\\) with multiplicative error \\(1 + \\epsilon\\) means that \\[(1 - \\epsilon)p \\leq \\tilde{p} \\leq (1 + \\epsilon) p\\] or equally \\[ |\\tilde{p} - p| \\leq \\epsilon p\\] \\(p\\) with additive error \\(\\epsilon\\) means that \\[ |\\tilde{p} - p| \\leq p\\] Equivalence of Counting and Sampling The two basic problem is FPRAS and FPAUS. FPRAS Fully polynomial randomized approximation scheme. Definition: Given a set \\(\\Omega\\) and a weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) and a partition function \\(Z = \\sum_{x \\in \\Omega'} w(x)\\) , the FPRAS is an algorithm with given error rate \\(\\epsilon\\) and confidence interval \\(\\delta\\) that return \\(\\tilde{Z}\\) , s.t. \\[\\mathrm{Pr}[(1 - \\epsilon)Z < \\tilde{Z} < (1 + \\epsilon)Z] > 1 - \\delta\\] The algorithm must run in \\(Poly(n, \\frac{1}{\\epsilon}, \\log \\frac{1}{\\delta})\\) FPAUS Fully polynomial almost uniform sampler Before giving the formal definition, we have to define total variance. Total variance Supppose \\(\\mu, \\nu: \\Omega \\rightarrow \\mathbb{R}_{+}\\) are two probability distribution. The total variance is defined as \\[ ||\\mu - \\nu||_{TV} = \\frac{1}{2} \\sum_{x \\in \\Omega} |\\mu(x) - \\nu(x)|\\] Or equally \\[||\\mu - \\nu||_{TV} = \\max_{X \\subset \\Omega}|\\mu(X) - \\nu(X)|\\] Proof: For the second formula, we can see that if we pick \\(X = \\{x| \\mu(x) > \\nu(x) \\}\\) , RHS is maximized. \\[ \\begin{aligned} |\\mu(\\Omega - X) - \\nu(\\Omega - X)| &= |\\nu(\\Omega - X) - \\mu(\\Omega - X)| \\\\ &= | (1 - \\mu(X)) - (1 - \\nu(X)) | \\\\ &= |\\nu(X) - \\mu(X)| \\\\ &= |\\mu(X) - \\nu(X)| \\\\ \\end{aligned} \\] So \\[\\max_{X \\subset \\Omega}|\\mu(X) - \\nu(X)| = \\frac{1}{2} \\sum_{x \\in \\Omega}|\\mu(x) - \\nu(x)| \\] Definition of FPAUS: fully polynomial almost uniform sampler There is a finite space \\(\\Omega\\) and a weight functiton \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) , and a partition function \\(Z = \\sum_{x \\in \\Omega}w(x)\\) , \\(\\pi(x) = \\frac{w(x)}{Z}\\) , fully polynomial almost uniform sampler is an algorithm with given error rate \\(\\delta\\) generate a sample from distribution \\(\\nu\\) s.t. \\[||\\mu - \\nu||_{TV} < \\delta\\] running in \\(Poly(n, \\log \\frac{1}{\\delta})\\) For self-reducible problems, it can be proved that FPRAS means FPAUS. Matching counting In this example we show that for matching counting problem FPRAS <=> FPAUS. For FPAUS => FPRAS Assume we have FPAUS of matching counting problem. We mainly consider this decomposisiont Denote the matching set of graph \\(G\\) as \\(M(G)\\) \\[\\frac{1}{|M(G)|} = \\frac{|M(G_{1})|}{|M(G_{0})|} \\frac{ |M(G_{2})| }{ |M(G_{1})| } \\cdots \\frac{ |M(G_{m})| }{ |M(G_{m-1})| } \\] Lemma 1 \\[\\frac{ |M(G_{i})| }{ |M(G_{i-1})| } \\geq \\frac{1}{2}\\] proof: consider an element of \\(G_{i}\\) , it does not contain \\(e_{i}\\) . We can generate a distinctive matching by make one node of \\(e_{i}\\) in other matching set. So \\[ |M(G_{i})| \\leq |M(G_{i-1})| - |M(G_{i})| \\] \\(\\blacksquare\\) Lemma 2 given a FPAUS of matching counting problem, that \\[ ||\\mu - \\pi||_{TV} \\leq K \\] then \\[ |\\mathbb{Pr}_{x \\sim \\mu}[x \\in M(G_{i})] - \\mathbb{Pr}_{x \\sim \\pi}[x \\in M(G_{i})] |\\leq K\\] proof: Let \\(A = \\{x | x \\in M(G_{i})\\}\\) , A is a subset. From total variance's definition, it's trivial. \\(\\blacksquare\\) We have to use lemma2 to calculate the real probability because FPAUS only generates a sample. Theorem: Chernoff bound for \\(X_{1}, X_{2}, \\cdots, X_{n}\\) i.i.d. \\(0 \\leq X_{i} \\leq 1\\) . Define \\(\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\) . Then for any \\(\\alpha > 0\\) \\[\\mathbb{Pr}[ |\\bar{X} - \\mathbb{E}[X]| \\geq \\alpha \\mathbb{E}[X]] \\leq 2e^{-n\\alpha^2\\mathbb{E}[X]/3}\\] Lemma 2.5 With \\(O(\\frac{m^{2}}{\\epsilon^{2}}\\log \\frac{m}{\\delta})\\) sample, we can approximate \\(\\bar{X}\\) with additive error \\(\\frac{\\epsilon}{20m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) . Use Lemma 2 and Lemma 2.5 we can approximate \\(p_{i}\\) with additive error \\(\\frac{\\epsilon}{10m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) Lemma 3 If we approximate \\(p\\) in \\(1 + \\frac{\\epsilon}{4m}\\) with error probability \\(\\delta\\) , then we can approximate \\(\\frac{1}{p}\\) in \\(1 + \\frac{\\epsilon}{2m}\\) proof: \\[ \\mathbb{Pr}[ |\\tilde{p_{i}} - p_{i} | > \\frac{\\epsilon}{4m}p_{i}] = \\mathbb{Pr}[ (1 - \\frac{\\epsilon}{4m})p_{i} < \\tilde{p}_{i} < (1 + \\frac{\\epsilon}{4m}) p_{i} ] \\] \\[\\tilde{p}_{i} < (1 + \\frac{\\epsilon}{4m})p_{i} \\rightarrow (1 - \\frac{\\epsilon}{4m + \\epsilon})\\frac{1}{p_{i}} < \\frac{1}{\\tilde{p}_{i}}\\] \\[(1 - \\frac{\\epsilon}{4m + \\epsilon}) > (1 - \\frac{\\epsilon}{2m}) \\] similar for the other side. Lemma 4 If we approximate \\(p_{i}\\) with additive error \\(\\epsilon\\) , then we can approximate it with multiplicative error \\(1 + 2 \\epsilon\\) proof: \\[ |\\tilde{p}_{i} - p_{i}| < \\epsilon = \\epsilon 2 \\frac{1}{2} < 2\\epsilon p_{i} \\] \\(\\blacksquare\\) With lemma 2, lemma 2.5 and lemma 4, we can approximate \\(\\frac{1}{p_{i}}\\) with multiplicative error \\(1 + \\frac{\\epsilon}{5m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) Use union bound, we can prove there is an FPRAS. FPRAS => FPAUS Suppose we have a exact counter, we can derive a exact sampler by conditional probability method. Now try to extend to approximate area. Denote the \\(i\\) th graph as \\(G^{i}\\) , we can formulate the probability of a sample \\(x\\) , \\(e_{i} = (u_{i}, v_{i})\\) . \\[\\mathbb{Pr}[x] = \\prod_{i}^{|E|}\\max(\\mathbb{I}[e_{i} \\notin V(G_{i-1})], \\frac{\\mathbb{I}[e_{i} \\notin x] |M(G^{i-1} / \\{e^{i}\\})| + \\mathbb{I}[e_{i} \\in x] |M(G^{i-1}/ \\{u_{i}, v_{i}\\})|}{|M(G^{i-1})|})\\] Using FPRAS, we can approximate \\(|M(.)|\\) with multiplicative error \\(1 + \\epsilon\\) , and confidence interval \\(\\delta\\) . So, we can approximate \\(\\frac{1}{\\mathbb{Pr}[x]}\\) with multiplicative error \\((1 + \\epsilon)^{n^{2}}\\) and confidence interval \\(n^{2}\\delta\\) (union bound). I think process can end at here, but the lecture brings out rejection sampling that I do not understand. \\[ \\tilde{\\pi}(M) \\geq \\frac{(1 - \\epsilon)^{n^2}}{|M(G)|} \\geq \\frac{(1 - \\epsilon)^{n^2 + 1}}{|\\tilde{M}(G)|} := \\alpha\\] Once construct \\(M\\) , we construct \\(p_{accept}(M) = \\frac{\\alpha}{\\tilde{\\pi}(M)}\\) So every samples has the same probability. FPRAS for DNF counting Assume there are \\(n\\) variables and \\(m\\) clauses. Consider the most straight way, sample \\(N\\) samples \\(X_{1}, X_{2}, \\cdots, X_{n}\\) . \\(X_{i}\\) contains an assignment for each variable. If DNF satisfies, then \\(X_{i} = 1\\) So \\( \\(\\frac{1}{N}\\sum_{i=1}^{N}X_{i} = \\frac{ANS}{2^{n}}\\) \\) According to Chernoff Bound, if we want to sample \\(ANS\\) with multiplicative error \\(1 + \\epsilon\\) and confidence interval \\(\\delta\\) . We need to hold \\[e^{-N\\epsilon^{2}\\frac{ANS}{3\\times 2^{n}}} \\leq \\delta\\] So \\(N > \\frac{2^{n}}{\\epsilon^{2} ANS}\\) , but \\(N\\) may be exp about \\(n\\) . Karp, Luby and Madras algorithm [KLM] The motivation is that choose a small and count-efficient universe, then a estimator with good(polynomial) lower bound in order to use Chernoff Bound. This is a simple way to decrease the size of universe. We sample from the union of ground set instead of all the assignments. Let the ground set(feasible solutions) of \\(i\\) th clause be \\(S_{i}\\) . We sample from \\(\\sum_{i=1}^{m} S_{i}\\) . The estimator is \\(\\frac{|\\bigcup_{i=1}^{m}S_{i}|}{\\sum_{i=1}^{m} |S_{i}|}\\) . Obviously, \\[\\frac{1}{m} \\leq \\frac{|\\bigcup_{i=1}^{m}S_{i}|}{\\sum_{i=1}^{m}S_{i}}\\leq 1\\] This 'large' lower bound means that we can use Chernoff bound more effectively. recall that \\(\\mathbb{Pr}[|X - \\mathbb{E}[x]| > \\alpha \\mathbb{E}[x]] < e^{-\\frac{N\\alpha^{2}\\mathbb{E}[x]}{3}}\\) . To get FPRAS, we only need \\[e^{-\\frac{N\\epsilon^2 \\mathbb{E}[x]}{3}} \\leq e^{-\\frac{N\\epsilon^{2}}{3m}}\\leq \\delta\\] \\[N > 3m\\frac{1}{\\epsilon^{2}}\\log\\frac{1}{\\delta}\\] which achieves FPRAS In DNF counting problem, it is easy to sample \\(\\sum_{i=1}^{m}|S_{i}|\\) , we can use brute hash to exclude those same elements. Network Unreliability Definition: Given a graph \\(G\\) with a probability function states that a link \\(e\\) disappears independently with probability \\(p_{e}\\) . Here we assume that \\(\\forall e\\in E\\) , \\(p_{e} = p\\) . Now consider the probability that the surviving network is disconnected. Let \\(Fail(p)\\) be this problem. Network unreliability problem can be trivially expressed as a DNF problem. Let \\(C_{1}, C_{2}, \\cdots, C_{k}\\) be \\(k\\) cuts of graph \\(G\\) . \\(x_{e}\\) is the indicator variable that \\(e\\) is broken. Then \\(G\\) is disconnected iff \\[\\lor _{i=1}^{k} \\land_{e\\in C_{i}}x_{e}\\] Is it solved by the KLM algorithm? But it does not fit the standards of FPRAS because maybe \\(k = \\Theta(e^{n})\\) Karger's algorithm Motivation: divide the problem into two parts, one is small, the other is large enough. Like the tricks in calculus. Let \\(C\\) be the size of the minimum cut of \\(G\\) . \\[Fail(p) \\geq p^{C} = q\\] Case 1: \\(q > \\frac{1}{poly(n)}\\) . We can use the Chernoff Bound directly because this property actually gives a lower bound . $$$$ Case 2: \\(q < \\frac{1}{poly(n)}\\) . Theorem Karger's theorem. For any graph \\(G\\) with \\(n\\) vertices and with minimum cut \\(C\\) , and for any \\(\\alpha \\geq 1\\) , the number of cuts of size at most \\(\\alpha C\\) in is at most \\(n^{2\\alpha}\\) . proof: Karger's contraction algorithm Lemma: Let \\(C_{1}, C_{2}, \\cdots, C_{r}\\) be all the cuts of \\(G\\) and let us sort them in the order of their size \\[|C_{1}| \\leq |C_{2}| \\leq \\cdots \\leq |C_{r}|\\] For any \\(\\alpha \\geq 1\\) , and \\(q = n^{-\\beta}\\) we have \\[\\mathbb{Pr}[\\exists i \\geq n^{2\\alpha}: C_{i} fails] \\leq \\frac{n^{2\\alpha(-\\frac{\\beta}{2}+1)}}{\\frac{\\beta}{2}-1}\\] proof: recall that the theorem above actually gives the relation between the index and the cut size. Let \\(i = n^{2\\alpha}\\) , \\(\\alpha = \\frac{\\log i}{2 \\log n}\\) . So \\(|C_{i}| \\geq \\frac{\\log i}{2 \\log n}C\\) By union bound \\[ \\begin{aligned} \\mathbb{Pr}[\\exists i \\geq n^{2\\alpha}: C_{i} fails] &\\leq \\sum_{i\\geq n^{2\\alpha}} \\mathbb{Pr}[C_{i} \\quad fails] \\\\ &= \\sum_{i\\geq n^{2\\alpha}} p^{|C_{i}|} \\\\ &\\leq \\sum_{i \\geq n^{2\\alpha}} p^{\\frac{\\log i}{2\\log n}C} \\\\ &= \\sum_{i \\geq n^{2\\alpha}}q^{\\frac{\\log i}{2\\log n}} \\\\ &\\leq \\int_{n^{2\\alpha}}^{\\infty}q^{\\frac{\\log i}{2\\log n}} \\mathrm{d}i \\\\ &= \\frac{n^{2\\alpha(-\\frac{\\beta}{2} + 1)}}{\\frac{\\beta}{2} - 1} \\end{aligned} \\] With this lemma, the \"large cuts\" has few probability to fail. Markov Chains Markov chains is a stochastic process on the state \\(\\Omega\\) . Markov property \\[\\mathbb{Pr}[X_{t+1} | X_{0}, \\cdots, X_{t}] = \\mathbb{Pr}[X_{t+1} | X_{t}]\\] Markov kenel \\[\\mathbb{Pr}[X_{t+1}|X_{t}] = K(X_{t}, X_{t+1})\\] Also Markov chain can be represent as a weighted direct graph, if \\(K(x, y) = c > 0\\) then there is a edge weighted \\(c\\) from \\(x\\) to \\(y\\) . If we sample \\(X_{0} \\sim p\\) . \\[\\mathbb{Pr}[X_{1}=x] = \\sum_{y \\in \\Omega}p(y)K(y, x) = p^{T}K(x)\\] Corollery \\[\\mathbb{Pr}[X_{t} = y| X_{0} \\sim p] = p^{T}K^{t}\\] Stationary Distribution Every Markov chain has a stationery distribution(may not unique). First of all the Markov kernel must have eigenvalue \\(1\\) and corresponding eigenvector \\(v\\) . It is easy to show that \\(\\mathrm{det}(K - I) = 0\\) , as the sum of every column of \\(K\\) is exactly \\(1\\) . Now let \\(\\pi = (|v_{1}|, |v_{2}|, \\cdots, |v_{k}|)^{T}\\) . We show that \\(\\pi\\) is a stationery distribution. If \\(\\pi^{T}\\pi \\neq 1\\) , then we can normalize it into normal vector. \\[\\pi_{i} = |v_{i}| = |\\sum_{j}v_{j}K(j,i)| \\leq \\sum_{j}|v_{j}|K(j,i) \\leq \\sum_{j}\\pi_{j}K(j,i)\\] This is a trivial inequality. But the next one is somehow magic ... \\[ \\begin{aligned} \\sum_{i}\\pi_{i} &= \\sum_{i}\\pi_{i}(\\sum_{j}K(i,j)) \\\\\\ &= \\sum_{j}\\sum_{i}\\pi_{i}K(i,j) \\\\ &\\geq \\sum_{j} \\pi_{j} \\end{aligned} \\] But actually the last inequality must be tight, so the it must holds that \\(\\pi_{i} = \\sum_{j}\\pi_{j}K(j,i)\\) . NB: in lecture notes it chose relu(v), but here I modified a little bit. Definition (Reversible Markov Chains): A Markov chain is reversible iff there exists a nonnegative weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) . Such that for every \\(x, y\\) . \\[\\pi(x)K(x, y) = \\pi(y)K(y, x)\\] It follows that \\(\\frac{\\pi}{Z}\\) is the stationery distribution. Mixing of Markov Chain Definition(Irreducible Markov Chain): A Markov chain is irreducible iff for any states \\(x\\) , \\(y\\) , it exits \\(t\\) such that \\(K^{t}(x,y) > 0\\) . Definition(aperiodic): A Markov Chain is aperiodic if for all \\(x, y\\) we have \\(\\gcd\\{t|K^{t}(x,y)>0\\} = 1\\) Lemma: Let \\(K\\) be an irreducible, aperiodic Markov Chain. Then there exists \\(t>0\\) such that for all \\(x, y\\) \\[K^{t}(x,y) > 0\\] Actually I do not know how to formally prove this... Theorem (Fundamental Theorem of Markov Chains): Any irreducible and aperiodic Markov chain has a unique stationery distribution. Futhermore, for all \\(x, y\\) , \\[K^{t}(x, y) \\rightarrow \\pi(y)\\] as t goes infinity. In particular, for any \\(\\epsilon > 0\\) there exits \\(t > 0\\) such that \\(||K^{t}(x, .) - \\pi||_{TV} < \\epsilon\\) . How to make an arbitrary Markov chain ergodic: All add a self-loop with \\(\\frac{1}{2}\\) Metropolis Rule Given a finite state set and a weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) . We would like to sample from the distribution \\(\\pi(x) = \\frac{w(x)}{Z}\\) . Metropolis rule is a general tool to construct such a ergodic Markov chain. Neighborhood Structure The first requirement is a undirected connected graph \\(G = (\\Omega, E)\\) , two state are connected iff they different by some local changes. Proposal Distribution At any vertex \\(x\\) we require a proposal distribution, \\(p(x, .)\\) satisfying the following properties: \\(p(x,y) > 0\\) only if \\(y\\) is a neighbor of \\(x\\) . \\(p(x,y) = p(y,x)\\) for all \\(y\\) \\(\\sum_{y}p(x,y) = 1\\) Metropolis chain decide a propose move from \\(x\\) to \\(y\\) with probability \\(p(x, y)\\) . accept the propose move with probability \\(\\min\\{1, \\frac{\\pi(y)}{\\pi(x)}\\}\\) . else reject and stay at \\(x\\) NB: this is like the simulated annealing ideas in optimization Lemma: Metropolis chain is reversible with stationery distribution \\(\\pi\\) (But how to prove that \\(\\pi\\) is the stationery distribution?) Coupling Definition(Coupling): Let \\(\\mu, \\nu\\) be probability distributions over \\(\\Omega\\) , A coupling between \\(\\mu, \\nu\\) is a probability distribution \\(\\pi\\) on \\(\\Omega \\times \\Omega\\) that preserves the marginals of \\(\\mu, \\nu\\) . \\[\\sum_{y} \\pi(x, y) = \\mu(x)\\] \\[\\sum_{x} \\pi(x, y) = \\nu(y)\\] Lemma(Coupling Lemma): Let \\(X \\sim \\mu\\) , \\(Y \\sim \\nu\\) Then \\(\\mathbb{Pr}[X \\neq Y] \\geq ||\\mu - \\nu||_{TV}\\) There exists a coupling \\(\\pi\\) between \\(\\mu\\) and \\(\\nu\\) such that \\(\\mathbb{Pr}[X \\neq Y] = ||\\mu - \\nu||_{TV}\\) proof: A simple observation is that \\(\\mathbb{Pr}[X=Y=a] \\leq \\min\\{\\mu(a), \\nu(a)\\}\\) \\[ \\begin{aligned} \\mathbb{Pr}[X \\neq Y] &= 1 - \\sum_{a \\in \\Omega} \\mathbb{Pr}[X = Y = a]\\\\ &\\leq 1 - \\sum_{a \\in \\Omega} \\min\\{\\mu(a), \\nu(a)\\} \\\\ &= \\sum_{a \\in \\Omega} (\\mu(a) - \\min\\{\\mu(a), \\nu(a)\\}) \\\\ &= ||\\mu - \\nu||_{TV} \\end{aligned} \\] So we just need to \"properly\" set remaining probability to let the inequality be tight. \\(\\blacksquare\\) Mixing time Terminology: \\[\\Delta_{x}^{t} = ||K(x,.)^{t} - \\pi||_{TV}\\] \\[\\tau_{x}(\\epsilon) = \\min\\{t|\\Delta_{x}^{t} < \\epsilon\\}\\] \\[\\tau (\\epsilon) = \\max \\{\\tau_{x}(\\epsilon)| x\\in \\Omega \\}\\] Definition (Mixing time): \\(\\tau(\\frac{1}{2e})\\) Lemma: \\[\\Delta_{x}(t+1) \\leq \\Delta_{x}(t)\\] proof: This proof shows the power of coupling. Let \\(X_{0} = x\\) , \\(Y_{0} \\sim \\pi\\) . Suppose now we get a coupling such that \\(\\mathbb{Pr}[X_{t}\\neq Y_{t}] = \\Delta_{x}(t)\\) Now define \\(X_{t+1}\\) , \\(Y_{t+1}\\) as below If \\(X_{t} = Y_{t}\\) , then set \\(X_{t+1} = Y_{t+1}\\) else random walk independently So \\( \\(\\Delta_{x}(t+1) \\leq \\mathbb{Pr}[X_{t+1} \\neq Y_{t+1}] \\leq \\mathbb{Pr}[X_{t}\\neq Y_{t}] = \\Delta_{x}(t)\\) \\) \\(\\blacksquare\\) General bound for mixing time Lemma: \\[\\tau_{mix} \\leq \\frac{1}{|\\Omega|\\min_{x,y} K(x,y)^{2}}\\] proof: Pick the same coupling \\[ \\begin{aligned} \\Delta_{x}(t+1) &\\leq \\mathbb{Pr}[X_{t+1} \\neq Y_{t+1}] \\\\ &= \\mathbb{Pr}[X_{t+1}\\neq Y_{t+1}|X_{t} \\neq Y_{t}]\\Delta_{x}(t)\\\\ &= (1 - \\sum_{x} K(X_{t}, x) K(Y_{t}, x))\\Delta_{x}(t)\\\\ &\\leq (1 - |\\Omega|\\min_{x, y} K(x, y)^2)\\Delta_{x}(t) \\end{aligned} \\] So \\[\\Delta_{x}(t) \\leq (1 - |\\Omega|\\min_{x, y} K(x, y)^2)^{t}\\] Let \\( \\((1 - |\\Omega|\\min_{x, y} K(x, y)^2)^{t} \\leq \\frac{1}{2e}\\) \\) \\(\\blacksquare\\) The above also proves the Fundamental Theorem of Markov Chain. Theorem: For any Markov Chain, \\(\\tau(\\epsilon) \\leq O(\\tau_{mix}\\log\\frac{1}{\\epsilon})\\) Coloring Try to assign \\(q\\) colors for a graph with maximum degree \\(\\Delta\\) . We want to sample proper color assignments. Define the coupling as follows \\((X, Y)\\) . Randomly choose a vertex and a color, try to change the color in both \\(X\\) and \\(Y\\) of corresponding vertex. \\[ \\begin{aligned} \\mathbb{E}[d(X_{t+1}, Y_{t+1})] &= \\mathbb{Pr}[A](d(X_{t}, Y_{t})) + \\mathbb{Pr}[B](d(X_{t}, Y_{t}) + 1) + \\mathbb{Pr}[C](d(X_{t}, Y_{t}) - 1)\\\\ &\\leq d(X_{t}, Y_{t}) + \\mathbb{Pr}[B] - \\mathbb{Pr}[C] \\\\ &\\leq d(X_{t}, Y_{t}) + \\frac{2\\Delta d(X_{t}, Y_{t})}{nq} - \\frac{d(X_{t}, Y_{t})(q - 2\\Delta)}{nq}\\\\ &= (1 - \\frac{q - 4\\Delta}{nq})d(X_{t}, Y_{t}) \\end{aligned} \\] Also \\(d(X_{0}, Y_{0}) \\leq n\\) So \\[\\mathbb{E}[d(X_{t}, Y_{t})] \\leq n(1 - \\frac{q-4\\Delta}{nq})^{t}\\] \\[\\mathbb{Pr}[d(X_{t}, Y_{t}) \\geq 1] \\leq \\mathbb{E}[d(X_{t}, Y_{t})] \\leq n(1 - \\frac{q-4\\Delta}{nq})^{t} \\leq \\delta\\] So to achieve \\(\\frac{1}{n}\\) error, we need \\(O(nq\\log n)\\) steps. Also we need \\(q \\geq 4\\Delta + 1\\) Path coupling Path coupling is defined on the pre-metric. And it is the property that holds for adjacent vertices and can be extend to the whole \\(\\Omega\\) . Definition (pre-metric): A pre-metric defined on \\(\\Omega\\) holds that for any adjacent edge \\(uv\\) , \\(d(uv) = d(u, v)\\) . Definition (path coupling): Define \\((X', Y')\\) is a coupling define on a pre-metric graph. If for any adjacent vertices \\((x, y)\\) holds that \\[\\mathbb{E}[d(X', Y')|(x, y)] \\leq (1 - \\alpha)d(x, y)\\] Then for every pair vertices, they all hold the above inequality. insight: The original coupling is about to converge. And the uniform weighted graph is naturally holds the pre-metric. proof: For any pair of vertices \\((s, t)\\) . Chose an arbitrary shortest path \\((s=u_{0}, u_{1}, u_{2}, \\cdots, u_{k}, t=u_{k+1})\\) . Naturally extend the coupling into multi-vertices coupling \\((U_{0}, U_{1}, U_{2}, \\cdots, U_{k}, U_{k+1})\\) . \\[ \\begin{aligned} \\mathbb{E}[d(S, T)] &= \\mathbb{E}[\\sum_{i=0}^{k}d(U_{i}, U_{i+1})] \\\\ &= \\sum_{i=0}^{k}\\mathbb{E}[d(U_{i}, U_{i+1})] \\\\ &\\leq \\sum_{i=0}^{k}(1-\\alpha)d(u_{i}, u_{i+1})\\\\ &= (1-\\alpha)d(s, t) \\end{aligned} \\] \\(\\blacksquare\\) Coloring with Path coupling theorem Theorem: If \\(q \\geq 2\\Delta + 1\\) , then the metropolis rule mixes in time \\(O(n\\log n)\\) . First we need to modify the graph to let it be a pre-metric graph in order to use path coupling theorem. Consider the metric \\(d(X, Y)\\) calculating how many different colors of color configuration \\(X\\) and \\(Y\\) . Sometime we cannot find a path of proper exchange, so we need to allow improper color configuration. Such that there are total \\(q^{n}\\) vertices in the graph. We can use metropolis rules to let their probability is \\(0\\) in \\(\\pi\\) . Also if we bound the total variance, we can still bound the \"real\" total variance. Then we need to design the path coupling procedure. We can only consider \\(d(X', Y'|x, y)\\) , \\(x\\) and \\(y\\) are adjacent with path coupling. Assume the exact different color of \\(x\\) and \\(y\\) are on the vertex \\(u\\) . In general, we choose a vertex \\(v\\) and a color \\(c\\) randomly, then try to change \\(v\\) 's color into \\(c\\) . This is not the complete procedure, but we can try to analyze this. We denote \\(N(u) \\bigcup \\{u\\} = N^{*}(u)\\) . If \\(v\\) is not in \\(N^{*}(u)\\) , then \\(d(X', Y') = d(x, y)\\) . If \\(v = u\\) , then \\(\\mathbb{E}[d(X', Y')] \\leq \\frac{\\Delta}{q}d(x, y) + (1 - \\frac{\\Delta}{q})(d(x, y) - 1)\\) . If \\(v \\in N^{*}(u)\\) , but \\(u \\neq v\\) , if \\(c = c_{x}\\) or \\(c = c_{y}\\) then \\(d(X, Y) \\leq d(x, y) + 1\\) otherwise \\(d(X, Y) = d(x, y)\\) . Sum all the inequalities above, we get \\[\\mathbb{E}[(X', Y')|(x, y)] \\leq d(x, y) - \\frac{q - 3\\Delta}{nq} = 1 - \\frac{q - 3\\Delta}{nq} \\leq (1 - \\frac{1}{nq})d(x, y)\\] When \\(q \\geq 3\\Delta + 1\\) . To improve this bound, we need to specify when \\(c = c_{x}\\) or \\(c = c_{y}\\) , we can reorder the configuration. To achieve \\[\\mathbb{E}[(X', Y')|(x, y)] \\leq d(x, y) - \\frac{q - 3\\Delta}{nq} = 1 - \\frac{q - 3\\Delta}{nq} \\leq (1 - \\frac{1}{nq})d(x, y)\\] Which we only need \\(q \\geq 2\\Delta + 1\\) . Coloring with Heat bath chain The main motivation of the path of metropolis rule is that try to construct a coupling such that the probability of \\(d(x, y) + 1\\) is low. One trivial way is to increase \\(q\\) . Beyond that path coupling consider just consider vertices pairs that are adjacent in order to decrease the \"controversy\". Now let's focus on heat bath chain. Instead of metropolis rule that randomly pick a vertex and a color then change the configuration. Heat bath chain randomly chooses a vertex then samples from the proper color. (Obviously it may break the pre-metric requirement) Here is a simple way: randomly chooses a vertex \\(u\\) . Denote the proper colors for \\(u\\) under configuration \\(X\\) as \\(A(X, u)\\) . Then for configuration \\(X, Y\\) , we sample from \\(\\max(|A(X, u)|, |A(Y, u)|)\\) . With probability \\(\\frac{|A(X, u) \\bigcap A(Y, u)|}{\\max(|A(X, u)|, |A(Y, u)|)}\\) we choose the same color. Obviously we can properly assign other events. Then we analyze this coupling \\[\\mathbb{E}[d(X', Y')|(x, y)] = \\sum_{v}\\mathbb{E}[c_{X'}(v) \\neq c_{Y'}(v)]\\] \\[\\mathbb{E}[c_{X'}(v) \\neq c_{Y'}(v)] = \\mathbb{Pr}[u=v]\\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u=v] + \\mathbb{Pr}[u\\neq v]\\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u\\neq v]\\] \\[ \\begin{aligned} \\mathbb{Pr}[c_{X'}(v)\\neq c_{Y'}(v)|u=v] &= 1 - \\frac{|A(X, u) \\bigcap A(Y, u)|}{\\max(|A(X, u)|, |A(Y, u)|)} \\\\ &\\leq \\frac{1}{q - \\Delta}|u\\sim v: c_{x}(v) \\neq c_{y}(u)| \\end{aligned} \\] \\[ \\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u\\neq v] = \\frac{d(x, y)}{n} \\] Sum all these equalities and inequalities \\[ \\mathbb{E}[d(X', Y')|(x, y)] \\leq \\frac{\\Delta d(x, y)}{n(q - \\Delta)} + (1 - \\frac{1}{n})d(x, y) \\] If \\(q \\geq 2\\Delta + 1\\) , \\[ \\mathbb{E}[d(X', Y')|(x, y)] \\leq (1 - \\frac{1}{n(\\Delta + 1)})d(x, y) \\] So for heat-bath, \\(q \\geq 2\\Delta + 1\\) and trivial coupling method lead to \\(\\Theta(n \\log n)\\) mixing time. Triangle-free graph Now image that the given graph is triangle-free. Then \\(A(X, u)\\) can be very large. Maybe better than \\(q - \\Delta\\) which can leads to a better result. Now analyze the \\(A(X, u)\\) \\[A(X, u) = \\sum_{c} \\prod_{v \\sim u} (1 - X_{v, c})\\] For triangle-free graph \\(\\mathbb{E}[\\prod_{v \\sim u} (1 - X_{v, c})] = \\prod_{v \\sim u} (1 - \\mathbb{E}[X_{v, c}])\\) We denote the information about \\(V - N^{*}(u)\\) as \\(\\mathcal{F}\\) . \\[ \\begin{aligned} \\mathbb{E}[A(X, u)|\\mathcal{F}] &= \\sum_{c}\\prod_{v\\sim u}(1 - \\mathbb{E}[X_{v, c}]) \\\\ &= \\sum_{c}\\prod_{v\\sim u}(1 - \\frac{1}{|A(X, v)|}) \\\\ &\\leq q\\prod_{c}\\prod_{v\\sim u}(1 - \\frac{1}{|A(X, v)|})^{\\frac{1}{q}} \\\\ &= q \\prod_{v\\sim u}\\prod_{c\\in A(X, v)} (1 - \\frac{1}{|A(X, v)|})^{\\frac{1}{q}} \\\\ &\\leq q e^{-\\frac{\\Delta}{q}} \\end{aligned} \\] Recall the McDiarmid's inequality. Let \\(X_{v,c}\\) s be the variables (NB: here are actually \\(d(u)\\) variables), \\(f(.) = |A(X, u)|\\) . \\(f\\) is 1-Lipschitz function. So \\[\\mathbb{Pr}[|f(x_{1}, \\cdots, x_{n}) - \\mathbb{E}f(x_{1}, \\cdots, x_{n})| \\geq t ] \\leq 2e^{-\\frac{t^{2}}{2\\Delta}}\\] So \\[\\mathbb{Pr}[|A(X, u)| \\leq q e^{-\\frac{\\Delta}{q}}(1 - \\epsilon)] \\leq 2e^{-\\epsilon^{2}q}\\] By union bound, \\[\\mathbb{Pr}[\\exists u:|A(X, u)| \\leq q e^{-\\frac{\\Delta}{q}}(1 - \\epsilon)] \\leq 2ne^{-\\epsilon^{2}q}\\] \\(\\blacksquare\\) Mixing time using eigenvalues Here we consider reversible Markov Chains . Although","title":"Counting and sampling notes"},{"location":"blog/2022/Counting%20and%20sampling/#equivalence-of-counting-and-sampling","text":"The two basic problem is FPRAS and FPAUS.","title":"Equivalence of Counting and Sampling"},{"location":"blog/2022/Counting%20and%20sampling/#fpras","text":"Fully polynomial randomized approximation scheme. Definition: Given a set \\(\\Omega\\) and a weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) and a partition function \\(Z = \\sum_{x \\in \\Omega'} w(x)\\) , the FPRAS is an algorithm with given error rate \\(\\epsilon\\) and confidence interval \\(\\delta\\) that return \\(\\tilde{Z}\\) , s.t. \\[\\mathrm{Pr}[(1 - \\epsilon)Z < \\tilde{Z} < (1 + \\epsilon)Z] > 1 - \\delta\\] The algorithm must run in \\(Poly(n, \\frac{1}{\\epsilon}, \\log \\frac{1}{\\delta})\\)","title":"FPRAS"},{"location":"blog/2022/Counting%20and%20sampling/#fpaus","text":"Fully polynomial almost uniform sampler Before giving the formal definition, we have to define total variance.","title":"FPAUS"},{"location":"blog/2022/Counting%20and%20sampling/#total-variance","text":"Supppose \\(\\mu, \\nu: \\Omega \\rightarrow \\mathbb{R}_{+}\\) are two probability distribution. The total variance is defined as \\[ ||\\mu - \\nu||_{TV} = \\frac{1}{2} \\sum_{x \\in \\Omega} |\\mu(x) - \\nu(x)|\\] Or equally \\[||\\mu - \\nu||_{TV} = \\max_{X \\subset \\Omega}|\\mu(X) - \\nu(X)|\\] Proof: For the second formula, we can see that if we pick \\(X = \\{x| \\mu(x) > \\nu(x) \\}\\) , RHS is maximized. \\[ \\begin{aligned} |\\mu(\\Omega - X) - \\nu(\\Omega - X)| &= |\\nu(\\Omega - X) - \\mu(\\Omega - X)| \\\\ &= | (1 - \\mu(X)) - (1 - \\nu(X)) | \\\\ &= |\\nu(X) - \\mu(X)| \\\\ &= |\\mu(X) - \\nu(X)| \\\\ \\end{aligned} \\] So \\[\\max_{X \\subset \\Omega}|\\mu(X) - \\nu(X)| = \\frac{1}{2} \\sum_{x \\in \\Omega}|\\mu(x) - \\nu(x)| \\] Definition of FPAUS: fully polynomial almost uniform sampler There is a finite space \\(\\Omega\\) and a weight functiton \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) , and a partition function \\(Z = \\sum_{x \\in \\Omega}w(x)\\) , \\(\\pi(x) = \\frac{w(x)}{Z}\\) , fully polynomial almost uniform sampler is an algorithm with given error rate \\(\\delta\\) generate a sample from distribution \\(\\nu\\) s.t. \\[||\\mu - \\nu||_{TV} < \\delta\\] running in \\(Poly(n, \\log \\frac{1}{\\delta})\\) For self-reducible problems, it can be proved that FPRAS means FPAUS.","title":"Total variance"},{"location":"blog/2022/Counting%20and%20sampling/#matching-counting","text":"In this example we show that for matching counting problem FPRAS <=> FPAUS. For FPAUS => FPRAS Assume we have FPAUS of matching counting problem. We mainly consider this decomposisiont Denote the matching set of graph \\(G\\) as \\(M(G)\\) \\[\\frac{1}{|M(G)|} = \\frac{|M(G_{1})|}{|M(G_{0})|} \\frac{ |M(G_{2})| }{ |M(G_{1})| } \\cdots \\frac{ |M(G_{m})| }{ |M(G_{m-1})| } \\] Lemma 1 \\[\\frac{ |M(G_{i})| }{ |M(G_{i-1})| } \\geq \\frac{1}{2}\\] proof: consider an element of \\(G_{i}\\) , it does not contain \\(e_{i}\\) . We can generate a distinctive matching by make one node of \\(e_{i}\\) in other matching set. So \\[ |M(G_{i})| \\leq |M(G_{i-1})| - |M(G_{i})| \\] \\(\\blacksquare\\) Lemma 2 given a FPAUS of matching counting problem, that \\[ ||\\mu - \\pi||_{TV} \\leq K \\] then \\[ |\\mathbb{Pr}_{x \\sim \\mu}[x \\in M(G_{i})] - \\mathbb{Pr}_{x \\sim \\pi}[x \\in M(G_{i})] |\\leq K\\] proof: Let \\(A = \\{x | x \\in M(G_{i})\\}\\) , A is a subset. From total variance's definition, it's trivial. \\(\\blacksquare\\) We have to use lemma2 to calculate the real probability because FPAUS only generates a sample. Theorem: Chernoff bound for \\(X_{1}, X_{2}, \\cdots, X_{n}\\) i.i.d. \\(0 \\leq X_{i} \\leq 1\\) . Define \\(\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\) . Then for any \\(\\alpha > 0\\) \\[\\mathbb{Pr}[ |\\bar{X} - \\mathbb{E}[X]| \\geq \\alpha \\mathbb{E}[X]] \\leq 2e^{-n\\alpha^2\\mathbb{E}[X]/3}\\] Lemma 2.5 With \\(O(\\frac{m^{2}}{\\epsilon^{2}}\\log \\frac{m}{\\delta})\\) sample, we can approximate \\(\\bar{X}\\) with additive error \\(\\frac{\\epsilon}{20m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) . Use Lemma 2 and Lemma 2.5 we can approximate \\(p_{i}\\) with additive error \\(\\frac{\\epsilon}{10m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) Lemma 3 If we approximate \\(p\\) in \\(1 + \\frac{\\epsilon}{4m}\\) with error probability \\(\\delta\\) , then we can approximate \\(\\frac{1}{p}\\) in \\(1 + \\frac{\\epsilon}{2m}\\) proof: \\[ \\mathbb{Pr}[ |\\tilde{p_{i}} - p_{i} | > \\frac{\\epsilon}{4m}p_{i}] = \\mathbb{Pr}[ (1 - \\frac{\\epsilon}{4m})p_{i} < \\tilde{p}_{i} < (1 + \\frac{\\epsilon}{4m}) p_{i} ] \\] \\[\\tilde{p}_{i} < (1 + \\frac{\\epsilon}{4m})p_{i} \\rightarrow (1 - \\frac{\\epsilon}{4m + \\epsilon})\\frac{1}{p_{i}} < \\frac{1}{\\tilde{p}_{i}}\\] \\[(1 - \\frac{\\epsilon}{4m + \\epsilon}) > (1 - \\frac{\\epsilon}{2m}) \\] similar for the other side. Lemma 4 If we approximate \\(p_{i}\\) with additive error \\(\\epsilon\\) , then we can approximate it with multiplicative error \\(1 + 2 \\epsilon\\) proof: \\[ |\\tilde{p}_{i} - p_{i}| < \\epsilon = \\epsilon 2 \\frac{1}{2} < 2\\epsilon p_{i} \\] \\(\\blacksquare\\) With lemma 2, lemma 2.5 and lemma 4, we can approximate \\(\\frac{1}{p_{i}}\\) with multiplicative error \\(1 + \\frac{\\epsilon}{5m}\\) and confidence interval \\(\\frac{\\delta}{m}\\) Use union bound, we can prove there is an FPRAS. FPRAS => FPAUS Suppose we have a exact counter, we can derive a exact sampler by conditional probability method. Now try to extend to approximate area. Denote the \\(i\\) th graph as \\(G^{i}\\) , we can formulate the probability of a sample \\(x\\) , \\(e_{i} = (u_{i}, v_{i})\\) . \\[\\mathbb{Pr}[x] = \\prod_{i}^{|E|}\\max(\\mathbb{I}[e_{i} \\notin V(G_{i-1})], \\frac{\\mathbb{I}[e_{i} \\notin x] |M(G^{i-1} / \\{e^{i}\\})| + \\mathbb{I}[e_{i} \\in x] |M(G^{i-1}/ \\{u_{i}, v_{i}\\})|}{|M(G^{i-1})|})\\] Using FPRAS, we can approximate \\(|M(.)|\\) with multiplicative error \\(1 + \\epsilon\\) , and confidence interval \\(\\delta\\) . So, we can approximate \\(\\frac{1}{\\mathbb{Pr}[x]}\\) with multiplicative error \\((1 + \\epsilon)^{n^{2}}\\) and confidence interval \\(n^{2}\\delta\\) (union bound). I think process can end at here, but the lecture brings out rejection sampling that I do not understand. \\[ \\tilde{\\pi}(M) \\geq \\frac{(1 - \\epsilon)^{n^2}}{|M(G)|} \\geq \\frac{(1 - \\epsilon)^{n^2 + 1}}{|\\tilde{M}(G)|} := \\alpha\\] Once construct \\(M\\) , we construct \\(p_{accept}(M) = \\frac{\\alpha}{\\tilde{\\pi}(M)}\\) So every samples has the same probability.","title":"Matching counting"},{"location":"blog/2022/Counting%20and%20sampling/#fpras-for-dnf-counting","text":"Assume there are \\(n\\) variables and \\(m\\) clauses. Consider the most straight way, sample \\(N\\) samples \\(X_{1}, X_{2}, \\cdots, X_{n}\\) . \\(X_{i}\\) contains an assignment for each variable. If DNF satisfies, then \\(X_{i} = 1\\) So \\( \\(\\frac{1}{N}\\sum_{i=1}^{N}X_{i} = \\frac{ANS}{2^{n}}\\) \\) According to Chernoff Bound, if we want to sample \\(ANS\\) with multiplicative error \\(1 + \\epsilon\\) and confidence interval \\(\\delta\\) . We need to hold \\[e^{-N\\epsilon^{2}\\frac{ANS}{3\\times 2^{n}}} \\leq \\delta\\] So \\(N > \\frac{2^{n}}{\\epsilon^{2} ANS}\\) , but \\(N\\) may be exp about \\(n\\) .","title":"FPRAS for DNF counting"},{"location":"blog/2022/Counting%20and%20sampling/#karp-luby-and-madras-algorithm-klm","text":"The motivation is that choose a small and count-efficient universe, then a estimator with good(polynomial) lower bound in order to use Chernoff Bound. This is a simple way to decrease the size of universe. We sample from the union of ground set instead of all the assignments. Let the ground set(feasible solutions) of \\(i\\) th clause be \\(S_{i}\\) . We sample from \\(\\sum_{i=1}^{m} S_{i}\\) . The estimator is \\(\\frac{|\\bigcup_{i=1}^{m}S_{i}|}{\\sum_{i=1}^{m} |S_{i}|}\\) . Obviously, \\[\\frac{1}{m} \\leq \\frac{|\\bigcup_{i=1}^{m}S_{i}|}{\\sum_{i=1}^{m}S_{i}}\\leq 1\\] This 'large' lower bound means that we can use Chernoff bound more effectively. recall that \\(\\mathbb{Pr}[|X - \\mathbb{E}[x]| > \\alpha \\mathbb{E}[x]] < e^{-\\frac{N\\alpha^{2}\\mathbb{E}[x]}{3}}\\) . To get FPRAS, we only need \\[e^{-\\frac{N\\epsilon^2 \\mathbb{E}[x]}{3}} \\leq e^{-\\frac{N\\epsilon^{2}}{3m}}\\leq \\delta\\] \\[N > 3m\\frac{1}{\\epsilon^{2}}\\log\\frac{1}{\\delta}\\] which achieves FPRAS In DNF counting problem, it is easy to sample \\(\\sum_{i=1}^{m}|S_{i}|\\) , we can use brute hash to exclude those same elements.","title":"Karp, Luby and Madras algorithm [KLM]"},{"location":"blog/2022/Counting%20and%20sampling/#network-unreliability","text":"Definition: Given a graph \\(G\\) with a probability function states that a link \\(e\\) disappears independently with probability \\(p_{e}\\) . Here we assume that \\(\\forall e\\in E\\) , \\(p_{e} = p\\) . Now consider the probability that the surviving network is disconnected. Let \\(Fail(p)\\) be this problem. Network unreliability problem can be trivially expressed as a DNF problem. Let \\(C_{1}, C_{2}, \\cdots, C_{k}\\) be \\(k\\) cuts of graph \\(G\\) . \\(x_{e}\\) is the indicator variable that \\(e\\) is broken. Then \\(G\\) is disconnected iff \\[\\lor _{i=1}^{k} \\land_{e\\in C_{i}}x_{e}\\] Is it solved by the KLM algorithm? But it does not fit the standards of FPRAS because maybe \\(k = \\Theta(e^{n})\\)","title":"Network Unreliability"},{"location":"blog/2022/Counting%20and%20sampling/#kargers-algorithm","text":"Motivation: divide the problem into two parts, one is small, the other is large enough. Like the tricks in calculus. Let \\(C\\) be the size of the minimum cut of \\(G\\) . \\[Fail(p) \\geq p^{C} = q\\] Case 1: \\(q > \\frac{1}{poly(n)}\\) . We can use the Chernoff Bound directly because this property actually gives a lower bound . $$$$ Case 2: \\(q < \\frac{1}{poly(n)}\\) . Theorem Karger's theorem. For any graph \\(G\\) with \\(n\\) vertices and with minimum cut \\(C\\) , and for any \\(\\alpha \\geq 1\\) , the number of cuts of size at most \\(\\alpha C\\) in is at most \\(n^{2\\alpha}\\) . proof: Karger's contraction algorithm Lemma: Let \\(C_{1}, C_{2}, \\cdots, C_{r}\\) be all the cuts of \\(G\\) and let us sort them in the order of their size \\[|C_{1}| \\leq |C_{2}| \\leq \\cdots \\leq |C_{r}|\\] For any \\(\\alpha \\geq 1\\) , and \\(q = n^{-\\beta}\\) we have \\[\\mathbb{Pr}[\\exists i \\geq n^{2\\alpha}: C_{i} fails] \\leq \\frac{n^{2\\alpha(-\\frac{\\beta}{2}+1)}}{\\frac{\\beta}{2}-1}\\] proof: recall that the theorem above actually gives the relation between the index and the cut size. Let \\(i = n^{2\\alpha}\\) , \\(\\alpha = \\frac{\\log i}{2 \\log n}\\) . So \\(|C_{i}| \\geq \\frac{\\log i}{2 \\log n}C\\) By union bound \\[ \\begin{aligned} \\mathbb{Pr}[\\exists i \\geq n^{2\\alpha}: C_{i} fails] &\\leq \\sum_{i\\geq n^{2\\alpha}} \\mathbb{Pr}[C_{i} \\quad fails] \\\\ &= \\sum_{i\\geq n^{2\\alpha}} p^{|C_{i}|} \\\\ &\\leq \\sum_{i \\geq n^{2\\alpha}} p^{\\frac{\\log i}{2\\log n}C} \\\\ &= \\sum_{i \\geq n^{2\\alpha}}q^{\\frac{\\log i}{2\\log n}} \\\\ &\\leq \\int_{n^{2\\alpha}}^{\\infty}q^{\\frac{\\log i}{2\\log n}} \\mathrm{d}i \\\\ &= \\frac{n^{2\\alpha(-\\frac{\\beta}{2} + 1)}}{\\frac{\\beta}{2} - 1} \\end{aligned} \\] With this lemma, the \"large cuts\" has few probability to fail.","title":"Karger's algorithm"},{"location":"blog/2022/Counting%20and%20sampling/#markov-chains","text":"Markov chains is a stochastic process on the state \\(\\Omega\\) . Markov property \\[\\mathbb{Pr}[X_{t+1} | X_{0}, \\cdots, X_{t}] = \\mathbb{Pr}[X_{t+1} | X_{t}]\\] Markov kenel \\[\\mathbb{Pr}[X_{t+1}|X_{t}] = K(X_{t}, X_{t+1})\\] Also Markov chain can be represent as a weighted direct graph, if \\(K(x, y) = c > 0\\) then there is a edge weighted \\(c\\) from \\(x\\) to \\(y\\) . If we sample \\(X_{0} \\sim p\\) . \\[\\mathbb{Pr}[X_{1}=x] = \\sum_{y \\in \\Omega}p(y)K(y, x) = p^{T}K(x)\\] Corollery \\[\\mathbb{Pr}[X_{t} = y| X_{0} \\sim p] = p^{T}K^{t}\\]","title":"Markov Chains"},{"location":"blog/2022/Counting%20and%20sampling/#stationary-distribution","text":"Every Markov chain has a stationery distribution(may not unique). First of all the Markov kernel must have eigenvalue \\(1\\) and corresponding eigenvector \\(v\\) . It is easy to show that \\(\\mathrm{det}(K - I) = 0\\) , as the sum of every column of \\(K\\) is exactly \\(1\\) . Now let \\(\\pi = (|v_{1}|, |v_{2}|, \\cdots, |v_{k}|)^{T}\\) . We show that \\(\\pi\\) is a stationery distribution. If \\(\\pi^{T}\\pi \\neq 1\\) , then we can normalize it into normal vector. \\[\\pi_{i} = |v_{i}| = |\\sum_{j}v_{j}K(j,i)| \\leq \\sum_{j}|v_{j}|K(j,i) \\leq \\sum_{j}\\pi_{j}K(j,i)\\] This is a trivial inequality. But the next one is somehow magic ... \\[ \\begin{aligned} \\sum_{i}\\pi_{i} &= \\sum_{i}\\pi_{i}(\\sum_{j}K(i,j)) \\\\\\ &= \\sum_{j}\\sum_{i}\\pi_{i}K(i,j) \\\\ &\\geq \\sum_{j} \\pi_{j} \\end{aligned} \\] But actually the last inequality must be tight, so the it must holds that \\(\\pi_{i} = \\sum_{j}\\pi_{j}K(j,i)\\) . NB: in lecture notes it chose relu(v), but here I modified a little bit. Definition (Reversible Markov Chains): A Markov chain is reversible iff there exists a nonnegative weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) . Such that for every \\(x, y\\) . \\[\\pi(x)K(x, y) = \\pi(y)K(y, x)\\] It follows that \\(\\frac{\\pi}{Z}\\) is the stationery distribution.","title":"Stationary Distribution"},{"location":"blog/2022/Counting%20and%20sampling/#mixing-of-markov-chain","text":"Definition(Irreducible Markov Chain): A Markov chain is irreducible iff for any states \\(x\\) , \\(y\\) , it exits \\(t\\) such that \\(K^{t}(x,y) > 0\\) . Definition(aperiodic): A Markov Chain is aperiodic if for all \\(x, y\\) we have \\(\\gcd\\{t|K^{t}(x,y)>0\\} = 1\\) Lemma: Let \\(K\\) be an irreducible, aperiodic Markov Chain. Then there exists \\(t>0\\) such that for all \\(x, y\\) \\[K^{t}(x,y) > 0\\] Actually I do not know how to formally prove this... Theorem (Fundamental Theorem of Markov Chains): Any irreducible and aperiodic Markov chain has a unique stationery distribution. Futhermore, for all \\(x, y\\) , \\[K^{t}(x, y) \\rightarrow \\pi(y)\\] as t goes infinity. In particular, for any \\(\\epsilon > 0\\) there exits \\(t > 0\\) such that \\(||K^{t}(x, .) - \\pi||_{TV} < \\epsilon\\) . How to make an arbitrary Markov chain ergodic: All add a self-loop with \\(\\frac{1}{2}\\)","title":"Mixing of Markov Chain"},{"location":"blog/2022/Counting%20and%20sampling/#metropolis-rule","text":"Given a finite state set and a weight function \\(w: \\Omega \\rightarrow \\mathbb{R}_{+}\\) . We would like to sample from the distribution \\(\\pi(x) = \\frac{w(x)}{Z}\\) . Metropolis rule is a general tool to construct such a ergodic Markov chain.","title":"Metropolis Rule"},{"location":"blog/2022/Counting%20and%20sampling/#neighborhood-structure","text":"The first requirement is a undirected connected graph \\(G = (\\Omega, E)\\) , two state are connected iff they different by some local changes.","title":"Neighborhood Structure"},{"location":"blog/2022/Counting%20and%20sampling/#proposal-distribution","text":"At any vertex \\(x\\) we require a proposal distribution, \\(p(x, .)\\) satisfying the following properties: \\(p(x,y) > 0\\) only if \\(y\\) is a neighbor of \\(x\\) . \\(p(x,y) = p(y,x)\\) for all \\(y\\) \\(\\sum_{y}p(x,y) = 1\\)","title":"Proposal Distribution"},{"location":"blog/2022/Counting%20and%20sampling/#metropolis-chain","text":"decide a propose move from \\(x\\) to \\(y\\) with probability \\(p(x, y)\\) . accept the propose move with probability \\(\\min\\{1, \\frac{\\pi(y)}{\\pi(x)}\\}\\) . else reject and stay at \\(x\\) NB: this is like the simulated annealing ideas in optimization Lemma: Metropolis chain is reversible with stationery distribution \\(\\pi\\) (But how to prove that \\(\\pi\\) is the stationery distribution?)","title":"Metropolis chain"},{"location":"blog/2022/Counting%20and%20sampling/#coupling","text":"Definition(Coupling): Let \\(\\mu, \\nu\\) be probability distributions over \\(\\Omega\\) , A coupling between \\(\\mu, \\nu\\) is a probability distribution \\(\\pi\\) on \\(\\Omega \\times \\Omega\\) that preserves the marginals of \\(\\mu, \\nu\\) . \\[\\sum_{y} \\pi(x, y) = \\mu(x)\\] \\[\\sum_{x} \\pi(x, y) = \\nu(y)\\] Lemma(Coupling Lemma): Let \\(X \\sim \\mu\\) , \\(Y \\sim \\nu\\) Then \\(\\mathbb{Pr}[X \\neq Y] \\geq ||\\mu - \\nu||_{TV}\\) There exists a coupling \\(\\pi\\) between \\(\\mu\\) and \\(\\nu\\) such that \\(\\mathbb{Pr}[X \\neq Y] = ||\\mu - \\nu||_{TV}\\) proof: A simple observation is that \\(\\mathbb{Pr}[X=Y=a] \\leq \\min\\{\\mu(a), \\nu(a)\\}\\) \\[ \\begin{aligned} \\mathbb{Pr}[X \\neq Y] &= 1 - \\sum_{a \\in \\Omega} \\mathbb{Pr}[X = Y = a]\\\\ &\\leq 1 - \\sum_{a \\in \\Omega} \\min\\{\\mu(a), \\nu(a)\\} \\\\ &= \\sum_{a \\in \\Omega} (\\mu(a) - \\min\\{\\mu(a), \\nu(a)\\}) \\\\ &= ||\\mu - \\nu||_{TV} \\end{aligned} \\] So we just need to \"properly\" set remaining probability to let the inequality be tight. \\(\\blacksquare\\)","title":"Coupling"},{"location":"blog/2022/Counting%20and%20sampling/#mixing-time","text":"Terminology: \\[\\Delta_{x}^{t} = ||K(x,.)^{t} - \\pi||_{TV}\\] \\[\\tau_{x}(\\epsilon) = \\min\\{t|\\Delta_{x}^{t} < \\epsilon\\}\\] \\[\\tau (\\epsilon) = \\max \\{\\tau_{x}(\\epsilon)| x\\in \\Omega \\}\\] Definition (Mixing time): \\(\\tau(\\frac{1}{2e})\\) Lemma: \\[\\Delta_{x}(t+1) \\leq \\Delta_{x}(t)\\] proof: This proof shows the power of coupling. Let \\(X_{0} = x\\) , \\(Y_{0} \\sim \\pi\\) . Suppose now we get a coupling such that \\(\\mathbb{Pr}[X_{t}\\neq Y_{t}] = \\Delta_{x}(t)\\) Now define \\(X_{t+1}\\) , \\(Y_{t+1}\\) as below If \\(X_{t} = Y_{t}\\) , then set \\(X_{t+1} = Y_{t+1}\\) else random walk independently So \\( \\(\\Delta_{x}(t+1) \\leq \\mathbb{Pr}[X_{t+1} \\neq Y_{t+1}] \\leq \\mathbb{Pr}[X_{t}\\neq Y_{t}] = \\Delta_{x}(t)\\) \\) \\(\\blacksquare\\) General bound for mixing time Lemma: \\[\\tau_{mix} \\leq \\frac{1}{|\\Omega|\\min_{x,y} K(x,y)^{2}}\\] proof: Pick the same coupling \\[ \\begin{aligned} \\Delta_{x}(t+1) &\\leq \\mathbb{Pr}[X_{t+1} \\neq Y_{t+1}] \\\\ &= \\mathbb{Pr}[X_{t+1}\\neq Y_{t+1}|X_{t} \\neq Y_{t}]\\Delta_{x}(t)\\\\ &= (1 - \\sum_{x} K(X_{t}, x) K(Y_{t}, x))\\Delta_{x}(t)\\\\ &\\leq (1 - |\\Omega|\\min_{x, y} K(x, y)^2)\\Delta_{x}(t) \\end{aligned} \\] So \\[\\Delta_{x}(t) \\leq (1 - |\\Omega|\\min_{x, y} K(x, y)^2)^{t}\\] Let \\( \\((1 - |\\Omega|\\min_{x, y} K(x, y)^2)^{t} \\leq \\frac{1}{2e}\\) \\) \\(\\blacksquare\\) The above also proves the Fundamental Theorem of Markov Chain. Theorem: For any Markov Chain, \\(\\tau(\\epsilon) \\leq O(\\tau_{mix}\\log\\frac{1}{\\epsilon})\\)","title":"Mixing time"},{"location":"blog/2022/Counting%20and%20sampling/#coloring","text":"Try to assign \\(q\\) colors for a graph with maximum degree \\(\\Delta\\) . We want to sample proper color assignments. Define the coupling as follows \\((X, Y)\\) . Randomly choose a vertex and a color, try to change the color in both \\(X\\) and \\(Y\\) of corresponding vertex. \\[ \\begin{aligned} \\mathbb{E}[d(X_{t+1}, Y_{t+1})] &= \\mathbb{Pr}[A](d(X_{t}, Y_{t})) + \\mathbb{Pr}[B](d(X_{t}, Y_{t}) + 1) + \\mathbb{Pr}[C](d(X_{t}, Y_{t}) - 1)\\\\ &\\leq d(X_{t}, Y_{t}) + \\mathbb{Pr}[B] - \\mathbb{Pr}[C] \\\\ &\\leq d(X_{t}, Y_{t}) + \\frac{2\\Delta d(X_{t}, Y_{t})}{nq} - \\frac{d(X_{t}, Y_{t})(q - 2\\Delta)}{nq}\\\\ &= (1 - \\frac{q - 4\\Delta}{nq})d(X_{t}, Y_{t}) \\end{aligned} \\] Also \\(d(X_{0}, Y_{0}) \\leq n\\) So \\[\\mathbb{E}[d(X_{t}, Y_{t})] \\leq n(1 - \\frac{q-4\\Delta}{nq})^{t}\\] \\[\\mathbb{Pr}[d(X_{t}, Y_{t}) \\geq 1] \\leq \\mathbb{E}[d(X_{t}, Y_{t})] \\leq n(1 - \\frac{q-4\\Delta}{nq})^{t} \\leq \\delta\\] So to achieve \\(\\frac{1}{n}\\) error, we need \\(O(nq\\log n)\\) steps. Also we need \\(q \\geq 4\\Delta + 1\\)","title":"Coloring"},{"location":"blog/2022/Counting%20and%20sampling/#path-coupling","text":"Path coupling is defined on the pre-metric. And it is the property that holds for adjacent vertices and can be extend to the whole \\(\\Omega\\) . Definition (pre-metric): A pre-metric defined on \\(\\Omega\\) holds that for any adjacent edge \\(uv\\) , \\(d(uv) = d(u, v)\\) . Definition (path coupling): Define \\((X', Y')\\) is a coupling define on a pre-metric graph. If for any adjacent vertices \\((x, y)\\) holds that \\[\\mathbb{E}[d(X', Y')|(x, y)] \\leq (1 - \\alpha)d(x, y)\\] Then for every pair vertices, they all hold the above inequality. insight: The original coupling is about to converge. And the uniform weighted graph is naturally holds the pre-metric. proof: For any pair of vertices \\((s, t)\\) . Chose an arbitrary shortest path \\((s=u_{0}, u_{1}, u_{2}, \\cdots, u_{k}, t=u_{k+1})\\) . Naturally extend the coupling into multi-vertices coupling \\((U_{0}, U_{1}, U_{2}, \\cdots, U_{k}, U_{k+1})\\) . \\[ \\begin{aligned} \\mathbb{E}[d(S, T)] &= \\mathbb{E}[\\sum_{i=0}^{k}d(U_{i}, U_{i+1})] \\\\ &= \\sum_{i=0}^{k}\\mathbb{E}[d(U_{i}, U_{i+1})] \\\\ &\\leq \\sum_{i=0}^{k}(1-\\alpha)d(u_{i}, u_{i+1})\\\\ &= (1-\\alpha)d(s, t) \\end{aligned} \\] \\(\\blacksquare\\)","title":"Path coupling"},{"location":"blog/2022/Counting%20and%20sampling/#coloring-with-path-coupling-theorem","text":"Theorem: If \\(q \\geq 2\\Delta + 1\\) , then the metropolis rule mixes in time \\(O(n\\log n)\\) . First we need to modify the graph to let it be a pre-metric graph in order to use path coupling theorem. Consider the metric \\(d(X, Y)\\) calculating how many different colors of color configuration \\(X\\) and \\(Y\\) . Sometime we cannot find a path of proper exchange, so we need to allow improper color configuration. Such that there are total \\(q^{n}\\) vertices in the graph. We can use metropolis rules to let their probability is \\(0\\) in \\(\\pi\\) . Also if we bound the total variance, we can still bound the \"real\" total variance. Then we need to design the path coupling procedure. We can only consider \\(d(X', Y'|x, y)\\) , \\(x\\) and \\(y\\) are adjacent with path coupling. Assume the exact different color of \\(x\\) and \\(y\\) are on the vertex \\(u\\) . In general, we choose a vertex \\(v\\) and a color \\(c\\) randomly, then try to change \\(v\\) 's color into \\(c\\) . This is not the complete procedure, but we can try to analyze this. We denote \\(N(u) \\bigcup \\{u\\} = N^{*}(u)\\) . If \\(v\\) is not in \\(N^{*}(u)\\) , then \\(d(X', Y') = d(x, y)\\) . If \\(v = u\\) , then \\(\\mathbb{E}[d(X', Y')] \\leq \\frac{\\Delta}{q}d(x, y) + (1 - \\frac{\\Delta}{q})(d(x, y) - 1)\\) . If \\(v \\in N^{*}(u)\\) , but \\(u \\neq v\\) , if \\(c = c_{x}\\) or \\(c = c_{y}\\) then \\(d(X, Y) \\leq d(x, y) + 1\\) otherwise \\(d(X, Y) = d(x, y)\\) . Sum all the inequalities above, we get \\[\\mathbb{E}[(X', Y')|(x, y)] \\leq d(x, y) - \\frac{q - 3\\Delta}{nq} = 1 - \\frac{q - 3\\Delta}{nq} \\leq (1 - \\frac{1}{nq})d(x, y)\\] When \\(q \\geq 3\\Delta + 1\\) . To improve this bound, we need to specify when \\(c = c_{x}\\) or \\(c = c_{y}\\) , we can reorder the configuration. To achieve \\[\\mathbb{E}[(X', Y')|(x, y)] \\leq d(x, y) - \\frac{q - 3\\Delta}{nq} = 1 - \\frac{q - 3\\Delta}{nq} \\leq (1 - \\frac{1}{nq})d(x, y)\\] Which we only need \\(q \\geq 2\\Delta + 1\\) .","title":"Coloring with Path coupling theorem"},{"location":"blog/2022/Counting%20and%20sampling/#coloring-with-heat-bath-chain","text":"The main motivation of the path of metropolis rule is that try to construct a coupling such that the probability of \\(d(x, y) + 1\\) is low. One trivial way is to increase \\(q\\) . Beyond that path coupling consider just consider vertices pairs that are adjacent in order to decrease the \"controversy\". Now let's focus on heat bath chain. Instead of metropolis rule that randomly pick a vertex and a color then change the configuration. Heat bath chain randomly chooses a vertex then samples from the proper color. (Obviously it may break the pre-metric requirement) Here is a simple way: randomly chooses a vertex \\(u\\) . Denote the proper colors for \\(u\\) under configuration \\(X\\) as \\(A(X, u)\\) . Then for configuration \\(X, Y\\) , we sample from \\(\\max(|A(X, u)|, |A(Y, u)|)\\) . With probability \\(\\frac{|A(X, u) \\bigcap A(Y, u)|}{\\max(|A(X, u)|, |A(Y, u)|)}\\) we choose the same color. Obviously we can properly assign other events. Then we analyze this coupling \\[\\mathbb{E}[d(X', Y')|(x, y)] = \\sum_{v}\\mathbb{E}[c_{X'}(v) \\neq c_{Y'}(v)]\\] \\[\\mathbb{E}[c_{X'}(v) \\neq c_{Y'}(v)] = \\mathbb{Pr}[u=v]\\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u=v] + \\mathbb{Pr}[u\\neq v]\\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u\\neq v]\\] \\[ \\begin{aligned} \\mathbb{Pr}[c_{X'}(v)\\neq c_{Y'}(v)|u=v] &= 1 - \\frac{|A(X, u) \\bigcap A(Y, u)|}{\\max(|A(X, u)|, |A(Y, u)|)} \\\\ &\\leq \\frac{1}{q - \\Delta}|u\\sim v: c_{x}(v) \\neq c_{y}(u)| \\end{aligned} \\] \\[ \\mathbb{Pr}[c_{X'}(v) \\neq c_{Y'}(v)|u\\neq v] = \\frac{d(x, y)}{n} \\] Sum all these equalities and inequalities \\[ \\mathbb{E}[d(X', Y')|(x, y)] \\leq \\frac{\\Delta d(x, y)}{n(q - \\Delta)} + (1 - \\frac{1}{n})d(x, y) \\] If \\(q \\geq 2\\Delta + 1\\) , \\[ \\mathbb{E}[d(X', Y')|(x, y)] \\leq (1 - \\frac{1}{n(\\Delta + 1)})d(x, y) \\] So for heat-bath, \\(q \\geq 2\\Delta + 1\\) and trivial coupling method lead to \\(\\Theta(n \\log n)\\) mixing time.","title":"Coloring with Heat bath chain"},{"location":"blog/2022/Counting%20and%20sampling/#triangle-free-graph","text":"Now image that the given graph is triangle-free. Then \\(A(X, u)\\) can be very large. Maybe better than \\(q - \\Delta\\) which can leads to a better result. Now analyze the \\(A(X, u)\\) \\[A(X, u) = \\sum_{c} \\prod_{v \\sim u} (1 - X_{v, c})\\] For triangle-free graph \\(\\mathbb{E}[\\prod_{v \\sim u} (1 - X_{v, c})] = \\prod_{v \\sim u} (1 - \\mathbb{E}[X_{v, c}])\\) We denote the information about \\(V - N^{*}(u)\\) as \\(\\mathcal{F}\\) . \\[ \\begin{aligned} \\mathbb{E}[A(X, u)|\\mathcal{F}] &= \\sum_{c}\\prod_{v\\sim u}(1 - \\mathbb{E}[X_{v, c}]) \\\\ &= \\sum_{c}\\prod_{v\\sim u}(1 - \\frac{1}{|A(X, v)|}) \\\\ &\\leq q\\prod_{c}\\prod_{v\\sim u}(1 - \\frac{1}{|A(X, v)|})^{\\frac{1}{q}} \\\\ &= q \\prod_{v\\sim u}\\prod_{c\\in A(X, v)} (1 - \\frac{1}{|A(X, v)|})^{\\frac{1}{q}} \\\\ &\\leq q e^{-\\frac{\\Delta}{q}} \\end{aligned} \\] Recall the McDiarmid's inequality. Let \\(X_{v,c}\\) s be the variables (NB: here are actually \\(d(u)\\) variables), \\(f(.) = |A(X, u)|\\) . \\(f\\) is 1-Lipschitz function. So \\[\\mathbb{Pr}[|f(x_{1}, \\cdots, x_{n}) - \\mathbb{E}f(x_{1}, \\cdots, x_{n})| \\geq t ] \\leq 2e^{-\\frac{t^{2}}{2\\Delta}}\\] So \\[\\mathbb{Pr}[|A(X, u)| \\leq q e^{-\\frac{\\Delta}{q}}(1 - \\epsilon)] \\leq 2e^{-\\epsilon^{2}q}\\] By union bound, \\[\\mathbb{Pr}[\\exists u:|A(X, u)| \\leq q e^{-\\frac{\\Delta}{q}}(1 - \\epsilon)] \\leq 2ne^{-\\epsilon^{2}q}\\] \\(\\blacksquare\\)","title":"Triangle-free graph"},{"location":"blog/2022/Counting%20and%20sampling/#mixing-time-using-eigenvalues","text":"Here we consider reversible Markov Chains . Although","title":"Mixing time using eigenvalues"},{"location":"blog/2022/LinearAlgebraDownRight%E9%98%85%E8%AF%BB/","tags":["math"],"text":"\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u6807\u9898\u4e0d\u80fd\u6709\u7a7a\u683c\uff0c\u53ea\u80fd\u6362\u6210\u9a7c\u5cf0\u547d\u540d\u6cd5\u4e86\u3002 \u8bfb\u4e86\u524d7\u7ae0\uff0c\u5c31\u5f53\u590d\u4e60\u4e86\u4e00\u4e0b\u7ebf\u6027\u4ee3\u6570\u5427\uff0c\u4f46\u8fd9\u4e66\u51e0\u4e4e\u53ea\u5173\u6ce8\u4e86 operator \u7684\u5185\u5bb9\uff0c\u5bfc\u81f4\u5927\u90e8\u5206\u8bfe\u7a0b\u4e2d\u7ebf\u6027\u4ee3\u6570\u7684\u5185\u5bb9\u548c\u5b83\u4ea4\u96c6\u4e0d\u662f\u5f88\u5927\uff0c\u4e5f\u53ef\u80fd\u662f\u6211\u8fd8\u6ca1\u9886\u609f\u5230\u600e\u4e48\u81ea\u7136\u5730\u6269\u5c55\u5b83\u3002 \u4e0d\u8fc7\u4ee4\u4eba\u9ad8\u5174\u7684\u662f\uff0c\u6211\u4f1a\u6c42\u6295\u5f71\u7b97\u5b50\u4e86\uff08 \u5e0c\u671b\u80fd\u6709\u673a\u4f1a\u628a\u540e\u97623\u7ae0\u8bfb\u5b8c\u3002 \u8fd9\u6b21\u903c\u7740\u81ea\u5df1\u5728\u8bfb\u7684\u65f6\u5019\u8bb0\u4e86\u70b9\u7b14\u8bb0\uff08\u6284\u4e86\u6284\u4e66\uff09\uff0c\u653e\u5728\u4e0b\u9762\uff0c\u514d\u5f97\u4e22\u4e86... pdf {% pdf ./lg.pdf %}","title":"LinearAlgebraDownRight\u9605\u8bfb"}]}